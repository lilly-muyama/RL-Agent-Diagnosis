{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6544c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Invalid MIT-MAGIC-COOKIE-1 key/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections \n",
    "import itertools\n",
    "import pickle\n",
    "import math\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import ast\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from modules import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c80434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamline_frequency_dict(frequency_dict):\n",
    "    frequency_dict_list = [] #will hold dictonaries with 2 keys i.e. 'set' and 'value'\n",
    "    for path_dict, value in frequency_dict.items():\n",
    "        all_set_list = [i['set'] for i in frequency_dict_list] #get all the sets so far in the list \n",
    "        path_set = set(ast.literal_eval(path_dict)) #get the set of current path dict to check if its already in list\n",
    "        if path_set in all_set_list: #increase value else insert it - work on this!!!!!!!!!!!!!!!\n",
    "            for elem in frequency_dict_list: #look for if path_set is already in frequency_dict_list \n",
    "                if elem['set'] == path_set: #find the matching path_set in the frequency_dict_list\n",
    "                    elem['value'] += value #increase the value for that set\n",
    "        else:\n",
    "            frequency_dict_list.append({'set':path_set, 'value':value}) #introdue the new set in the list\n",
    "    \n",
    "    all_list = [list(path_dict['set']) for path_dict in frequency_dict_list] # list of all the set(pathways)\n",
    "    flat_list = [item for sublist in all_list for item in sublist] #flatten list to get commonest items\n",
    "    commonest_elements = dict(collections.Counter(flat_list)) #the most frequent items in the list\n",
    "    commonest_elements = {k: v for k, v in sorted(commonest_elements.items(), reverse=True, key=lambda item: item[1])}\n",
    "    commonest_elements_list = list(commonest_elements.keys())\n",
    "    commonest_elements_list = [i for i in commonest_elements_list if i not in ['Lupus', 'No lupus', 'Inconclusive diagnosis']] + ['Lupus', 'No lupus', 'Inconclusive diagnosis']\n",
    "    \n",
    "    for item in frequency_dict_list:\n",
    "        item['set'] = sorted(list(item['set']), key=lambda x: commonest_elements_list.index(x))\n",
    "    \n",
    "    keys = [str(i['set']) for i in frequency_dict_list]\n",
    "    values = [i['value'] for i in frequency_dict_list]\n",
    "    final_frequency_dict = {k:v for (k,v) in zip(keys, values)}\n",
    "    \n",
    "    return final_frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8ae5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tuple_dict(df):\n",
    "    frequency_dict = {}\n",
    "    for traj in df.trajectory:\n",
    "        if traj in frequency_dict.keys():\n",
    "            frequency_dict[traj] += 1\n",
    "        else:\n",
    "            frequency_dict[traj] = 1\n",
    "    streamlined_frequency_dict = streamline_frequency_dict(frequency_dict)\n",
    "    overall_tup_dict = {}\n",
    "    for key, value in frequency_dict.items():\n",
    "        new_key = ast.literal_eval(key)\n",
    "        for tup in zip(new_key, new_key[1:]):\n",
    "            if tup in overall_tup_dict.keys():\n",
    "                overall_tup_dict[tup] += value\n",
    "            else:\n",
    "                overall_tup_dict[tup] = value\n",
    "    return overall_tup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1fe801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sankey_df(df):\n",
    "    overall_tup_dict = generate_tuple_dict(df)\n",
    "    sankey_df = pd.DataFrame()\n",
    "    sankey_df['source'] = [i[0] for i in overall_tup_dict.keys()]\n",
    "    sankey_df['target'] = [i[1] for i in overall_tup_dict.keys()]\n",
    "    sankey_df['value'] = list(overall_tup_dict.values())\n",
    "    sankey_df['link_type'] = sankey_df['target'].apply(lambda i: 'terminal' if i in ['No lupus', 'Lupus', 'Inconclusive diagnosis'] else 'non_terminal')\n",
    "    return sankey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0313f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_value(row):\n",
    "    substring = f\"'{row.source}', '{row.target}'\"\n",
    "    substring_df = pd.DataFrame()\n",
    "    for i, test_row in test_df.iterrows():\n",
    "        if substring in test_row.trajectory:\n",
    "            substring_df = substring_df.append(test_row)\n",
    "    substring_testing_df = testing_df.loc[substring_df.index]\n",
    "    \n",
    "    threshold_values = substring_testing_df[row.source].unique().tolist()\n",
    "    if len(threshold_values) == 1:\n",
    "        return int(threshold_values[0])\n",
    "    else:\n",
    "#         print(f'There is {len(threshold_values)} threshold values for the edge between {row.source} and {row.target}')\n",
    "        return str(threshold_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56c76eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pyvis_network(pathways_df):\n",
    "#     pathways_df = create_sankey_df(test_df)\n",
    "    pathways_df['type'] = 'directed'\n",
    "#     start_node = 'No lupus'\n",
    "    got_net = Network(notebook=True, height='750px', width='100%', directed=True, cdn_resources='in_line')\n",
    "    got_net.add_node(start_node, color='purple', size=20)\n",
    "    got_net.add_nodes(non_terminal_nodes, size=[15]*len(non_terminal_nodes), color=['blue']*len(non_terminal_nodes))\n",
    "    got_net.add_nodes(terminal_nodes, color=['green']*len(terminal_nodes), size=[20]*len(terminal_nodes))\n",
    "    for src, target, value in zip(pathways_df.source, pathways_df.target, pathways_df.value):\n",
    "        if value > threshold:\n",
    "            got_net.add_edge(src, target, value=value, color='red')\n",
    "        else:\n",
    "            got_net.add_edge(src, target, value=value, color='blue')\n",
    "    return got_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce98c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labelled_pyvis_network(pathways_df, pathway_type='network'): #second type is trajectory \n",
    "    pathways_df['type'] = 'directed'\n",
    "    pathways_df['edge_threshold'] = pathways_df.apply(lambda row: get_threshold_value(row), axis=1)\n",
    "    \n",
    "    #change get_net to something else since it satnds for Game of Thrones\n",
    "    got_net = Network(notebook=True, height='750px', width='100%', directed=True, cdn_resources='in_line')\n",
    "    got_net.add_node(start_node, color='purple', size=20)\n",
    "    got_net.add_nodes(non_terminal_nodes, size=[15]*len(non_terminal_nodes), color=['blue']*len(non_terminal_nodes))\n",
    "    got_net.add_nodes(terminal_nodes, color=['green']*len(terminal_nodes), size=[20]*len(terminal_nodes))\n",
    "    for src, target, value, edge_thresh in zip(pathways_df.source, pathways_df.target, pathways_df.value, pathways_df.edge_threshold):\n",
    "        if value > threshold: #this is what mainly changes\n",
    "            if isinstance(edge_thresh, str):\n",
    "                got_net.add_edge(src, target, value=value, color='red', label=edge_thresh)\n",
    "            else:\n",
    "                got_net.add_edge(src, target, value=value, color='red', label=str(int(edge_thresh)))\n",
    "        else:\n",
    "            got_net.add_edge(src, target, value=value, color='blue')\n",
    "    return got_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af3a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_value_path(df, source): #source e.g. 'ana'\n",
    "    threshold_values = df[source].unique().tolist()\n",
    "    if len(threshold_values) == 1:\n",
    "        return int(threshold_values[0])\n",
    "    else:\n",
    "        return str(threshold_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f2755ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_networkx_graph(test_df, testing_df, save=False, filename=None):\n",
    "    sankey_df = create_sankey_df(test_df)\n",
    "    sankey_df['edge_threshold'] = sankey_df.apply(lambda row: get_threshold_value(row), axis=1)\n",
    "    test_df_graph = nx.from_pandas_edgelist(sankey_df, 'source', 'target', 'edge_threshold')\n",
    "    if save:\n",
    "        pickle.dump(test_df_graph, open(f'{filename}.pickle', 'wb'))\n",
    "    return test_df_graph, sankey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e76df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_one_trajectory(pred_df, trajectory): #pred_df = pred_no_lupus par exemple\n",
    "    trajectory_df = pred_df[pred_df.trajectory == trajectory]\n",
    "    trajectory_testing_df = testing_df.loc[trajectory_df.index]\n",
    "    trajectory_pathways_df = create_sankey_df(trajectory_df)\n",
    "    trajectory_pathways_df['edge_threshold'] = [get_threshold_value(trajectory_testing_df, source) for source in trajectory_pathways_df.source]\n",
    "    trajectory_net = draw_pyvis_network(trajectory_pathways_df, 'trajectory')   \n",
    "    return trajectory_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afbb70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_networkx_graph_path(pathway, test_df, save=False, filename=None):\n",
    "    pathway_df = test_df[test_df.trajectory==pathway]\n",
    "    pathway_testing_df = testing_df.loc[pathway_df.index]\n",
    "    sankey_df = create_sankey_df(pathway_df)\n",
    "    sankey_df['edge_threshold'] = [get_threshold_value_path(pathway_testing_df, source) for source in sankey_df.source]\n",
    "    pathway_graph = nx.from_pandas_edgelist(sankey_df, 'source', 'target', 'edge_threshold')\n",
    "    if save:\n",
    "        pickle.dump(test_df_graph, open(f'{filename}.pickle', 'wb'))\n",
    "#     return pathway_graph, sankey_df\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa56e233",
   "metadata": {},
   "source": [
    "#### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73862409",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dueling_dqn_per'\n",
    "seed = 126\n",
    "steps = int(10e7)\n",
    "folder_name = f'../graphs/risk_factor/seed_{seed}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b437f033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_involvement</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ana  fever  leukopenia  thrombocytopenia  auto_immune_hemolysis  delirium  \\\n",
       "0    1      0           0                 0                      0         0   \n",
       "1    1      1           0                 0                      0         0   \n",
       "2    1      0           0                 0                      0         0   \n",
       "3    1      1           0                 0                      0         0   \n",
       "4    1      0           0                 0                      0         0   \n",
       "\n",
       "   psychosis  seizure  non_scarring_alopecia  oral_ulcers  ...  \\\n",
       "0          0        0                      0            0  ...   \n",
       "1          0        0                      0            0  ...   \n",
       "2          1        0                      0            0  ...   \n",
       "3          0        0                      1            0  ...   \n",
       "4          0        0                      1            0  ...   \n",
       "\n",
       "   joint_involvement  proteinuria  anti_cardioliphin_antibodies  \\\n",
       "0                  1            0                             0   \n",
       "1                  0            1                             0   \n",
       "2                  1            0                             0   \n",
       "3                  0            0                             0   \n",
       "4                  1            0                             0   \n",
       "\n",
       "   anti_β2gp1_antibodies  lupus_anti_coagulant  low_c3  low_c4  \\\n",
       "0                      0                     0       0       0   \n",
       "1                      0                     0       0       0   \n",
       "2                      0                     1       1       0   \n",
       "3                      0                     1       0       0   \n",
       "4                      0                     0       1       0   \n",
       "\n",
       "   anti_dsdna_antibody  anti_smith_antibody  label  \n",
       "0                    0                    0      1  \n",
       "1                    1                    0      1  \n",
       "2                    0                    0      1  \n",
       "3                    1                    0      1  \n",
       "4                    0                    0      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df = pd.read_csv('../data/test_set_constant.csv')\n",
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a4edfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>episode_length</th>\n",
       "      <th>reward</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_actual</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>terminated</th>\n",
       "      <th>is_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.574529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'pericardial_effusion', 'joint_involve...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'pericardial_effusion', 'cutaneous_lup...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.296348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'pericardial_effusion', 'joint_involve...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.304535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'pericardial_effusion', 'cutaneous_lup...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.390528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'pericardial_effusion', 'joint_involve...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  episode_length    reward  y_pred  y_actual  \\\n",
       "0    0.0            10.0  0.574529     1.0       1.0   \n",
       "1    1.0            17.0  0.306122     1.0       1.0   \n",
       "2    2.0            17.0  0.296348     1.0       1.0   \n",
       "3    3.0            17.0  0.304535     1.0       1.0   \n",
       "4    4.0            15.0  0.390528     1.0       1.0   \n",
       "\n",
       "                                          trajectory  terminated  is_success  \n",
       "0  ['ana', 'pericardial_effusion', 'joint_involve...         0.0         1.0  \n",
       "1  ['ana', 'pericardial_effusion', 'cutaneous_lup...         0.0         1.0  \n",
       "2  ['ana', 'pericardial_effusion', 'joint_involve...         0.0         1.0  \n",
       "3  ['ana', 'pericardial_effusion', 'cutaneous_lup...         0.0         1.0  \n",
       "4  ['ana', 'pericardial_effusion', 'joint_involve...         0.0         1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(f'../test_dfs/{model_name}_risk_factor_{seed}_{steps}.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db609b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1*len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948d18d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.74285714285715"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.test(test_df.y_actual, test_df.y_pred)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1954a5",
   "metadata": {},
   "source": [
    "#### Creating graph for entire test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "096a36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filename = f'{folder_name}/{model_name}_test_df'\n",
    "test_df_graph, test_sankey_df = create_networkx_graph(test_df, testing_df, True, test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1c835",
   "metadata": {},
   "source": [
    "#### Creating graph for no lupus test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9b1218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7487, 7487)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_no_lupus = test_df[test_df.y_pred==0]\n",
    "no_lupus_testing_df = testing_df.loc[pred_no_lupus.index]\n",
    "len(pred_no_lupus), len(no_lupus_testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec23d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_lupus_filename = f'{folder_name}/{model_name}_no_lupus'\n",
    "no_lupus_df_graph, no_lupus_sankey_df = create_networkx_graph(pred_no_lupus, no_lupus_testing_df, True, no_lupus_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cdd9e1",
   "metadata": {},
   "source": [
    "#### Creating graph for lupus test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85e767f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6513, 6513)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lupus = test_df[test_df.y_pred==1]\n",
    "lupus_testing_df = testing_df.loc[pred_lupus.index]\n",
    "len(pred_lupus), len(lupus_testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a175ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_filename = f'{folder_name}/{model_name}_lupus'\n",
    "lupus_df_graph, lupus_sankey_df = create_networkx_graph(pred_lupus, lupus_testing_df, True, lupus_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d52dc6",
   "metadata": {},
   "source": [
    "#### Shortest paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4cc54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_lupus_path = pred_lupus[pred_lupus.episode_length==pred_lupus.episode_length.min()].trajectory.value_counts().index[0]\n",
    "short_lupus_filename = f'{folder_name}/{model_name}_lupus_shortest'\n",
    "create_networkx_graph_path(short_lupus_path, pred_lupus, True, short_lupus_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23212372",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_no_lupus_path = pred_no_lupus[pred_no_lupus.episode_length == pred_no_lupus.episode_length.min()].trajectory.value_counts().index[0]\n",
    "short_no_lupus_filename = f'{folder_name}/{model_name}_no_lupus_shortest'\n",
    "create_networkx_graph_path(short_no_lupus_path, pred_no_lupus, True, short_no_lupus_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57e7be",
   "metadata": {},
   "source": [
    "#### Longest paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d010f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_lupus_path = pred_lupus[pred_lupus.episode_length==pred_lupus.episode_length.max()].trajectory.value_counts().index[0]\n",
    "long_lupus_filename = f'{folder_name}/{model_name}_lupus_longest'\n",
    "create_networkx_graph_path(long_lupus_path, pred_lupus, True, long_lupus_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98fb99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_no_lupus_path = pred_no_lupus[pred_no_lupus.episode_length == pred_no_lupus.episode_length.max()].trajectory.value_counts().index[0]\n",
    "long_no_lupus_filename = f'{folder_name}/{model_name}_no_lupus_longest'\n",
    "create_networkx_graph_path(long_no_lupus_path, pred_no_lupus, True, long_no_lupus_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73878ef1",
   "metadata": {},
   "source": [
    "#### Commonest paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0eb2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_lupus_path = pred_lupus.trajectory.value_counts().index[0]\n",
    "common_lupus_filename = f'{folder_name}/{model_name}_lupus_commonest'\n",
    "create_networkx_graph_path(common_lupus_path, pred_lupus, True, common_lupus_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d217f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_no_lupus_path = pred_no_lupus.trajectory.value_counts().index[0]\n",
    "common_no_lupus_filename = short_no_lupus_filename = f'{folder_name}/{model_name}_no_lupus_commonest'\n",
    "create_networkx_graph_path(common_no_lupus_path, pred_no_lupus, True, common_no_lupus_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6e785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
