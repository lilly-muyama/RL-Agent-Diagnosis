{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce50672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from modules import utils, constants\n",
    "from stable_baselines import DQN\n",
    "# from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.deepq.policies import FeedForwardPolicy\n",
    "from stable_baselines.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886dbf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = constants.SEED\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d820f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_architecture(input_tensor, num_actions, net_arch):\n",
    "    \n",
    "#     with tf.variable_scope('custom_net', reuse=tf.AUTO_REUSE):\n",
    "#         layer_1 = tf.layers.dense(input_tensor, units=net_arch[0], activation=tf.nn.relu)\n",
    "#         layer_2 = tf.layers.dense(layer_1, units=net_arch[1], activation=tf.nn.relu)\n",
    "#         layer_3 = tf.layers.dense(layer_2, units=net_arch[2], activation=tf.nn.relu)\n",
    "#         layer_4 = tf.layers.dense(layer_3, units=net_arch[3], activation=tf.nn.relu)\n",
    "#         output_layer = tf.layers.dense(layer_3, units=num_actions, activation=None)\n",
    "\n",
    "#     return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9d7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom MLP policy of three layers of size 256, 128, 64 and 32 each\n",
    "class CustomDQNPolicy(FeedForwardPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomDQNPolicy, self).__init__(*args, **kwargs,\n",
    "                                           layers=[128, 64, 32],\n",
    "                                           layer_norm=False,\n",
    "                                           feature_extraction='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0518d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_kwargs = {'net_arch': [256, 128, 64]}\n",
    "# policy_kwargs = dict(net_arch=[256, 128, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca43ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_dueling_dqn(X_train, y_train, timesteps, save=False, log_path=None, log_prefix='dueling_dqn', filename=None, per=False):\n",
    "    '''\n",
    "    Creates and trains a dueling DQN model\n",
    "    '''\n",
    "    if per:\n",
    "        log_prefix = 'dueling_dqn_per'\n",
    "    training_env = utils.create_env(X_train, y_train)\n",
    "    model = DQN(CustomDQNPolicy, training_env, verbose=1, seed=constants.SEED, learning_rate=0.0001, \n",
    "                buffer_size=1000000, learning_starts=50000, train_freq=4, target_network_update_freq=10000, \n",
    "                exploration_final_eps=0.05, n_cpu_tf_sess=1, double_q=False, prioritized_replay=per)\n",
    "    \n",
    "    checkpoint_callback = CheckpointCallback(save_freq=constants.CHECKPOINT_FREQ, save_path=log_path, \n",
    "                                             name_prefix=log_prefix)\n",
    "    model.learn(total_timesteps=timesteps, log_interval=100000, callback=checkpoint_callback)\n",
    "    if save:\n",
    "        model.save(f'{log_path}/{filename}.pkl')\n",
    "    training_env.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6bb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_dueling_ddqn(X_train, y_train, timesteps, save=False, log_path=None, log_prefix='dueling_ddqn', filename=None, per=False):\n",
    "    '''\n",
    "    Creates and trains a dueling double DQN model\n",
    "    '''\n",
    "    if per:\n",
    "        log_prefix = 'dueling_ddqn_per'\n",
    "    training_env = utils.create_env(X_train, y_train)\n",
    "    model = DQN(CustomDQNPolicy, training_env, verbose=1, seed=constants.SEED, learning_rate=0.0001, \n",
    "                buffer_size=1000000, learning_starts=50000, train_freq=4, target_network_update_freq=10000, \n",
    "                exploration_final_eps=0.05, n_cpu_tf_sess=1, prioritized_replay=per)\n",
    "    \n",
    "    checkpoint_callback = CheckpointCallback(save_freq=constants.CHECKPOINT_FREQ, save_path=log_path, \n",
    "                                             name_prefix=log_prefix)\n",
    "    model.learn(total_timesteps=timesteps, log_interval=100000, callback=checkpoint_callback)\n",
    "    if save:\n",
    "        model.save(f'{log_path}/{filename}.pkl')\n",
    "    training_env.close()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944d299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dqn_model(model_type, steps):\n",
    "    dir_name = f'seed_{SEED}_{steps}'\n",
    "    parent_dir = f'../models/logs/{model_type}/arch_3_layers'\n",
    "    path = os.path.join(parent_dir, dir_name)\n",
    "  \n",
    "    if model_type == 'dueling_dqn_per':\n",
    "        model = stable_dueling_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_dqn_per', filename=f'dueling_dqn_pre_{steps}', per=True)\n",
    "    elif model_type == 'dueling_ddqn_per':\n",
    "        model = stable_dueling_ddqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_ddqn_per', filename=f'dueling_ddqn_per_{steps}', per=True)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model type - {model_type}!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d8fb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_involvement</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_Î²2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ana  fever  leukopenia  thrombocytopenia  auto_immune_hemolysis  delirium  \\\n",
       "0    0      1           0                 0                      0         0   \n",
       "1    0      0           0                 0                      0         1   \n",
       "2    1      0           0                 0                      0         1   \n",
       "3    1      0           0                 0                      0         0   \n",
       "4    1      0           0                 1                      1         1   \n",
       "\n",
       "   psychosis  seizure  non_scarring_alopecia  oral_ulcers  ...  \\\n",
       "0          0        0                      0            0  ...   \n",
       "1          0        0                      0            0  ...   \n",
       "2          0        0                      0            0  ...   \n",
       "3          0        1                      1            0  ...   \n",
       "4          0        0                      0            0  ...   \n",
       "\n",
       "   joint_involvement  proteinuria  anti_cardioliphin_antibodies  \\\n",
       "0                  1            0                             0   \n",
       "1                  0            0                             0   \n",
       "2                  0            0                             0   \n",
       "3                  0            1                             0   \n",
       "4                  0            1                             0   \n",
       "\n",
       "   anti_Î²2gp1_antibodies  lupus_anti_coagulant  low_c3  low_c4  \\\n",
       "0                      0                     0       0       0   \n",
       "1                      0                     0       0       0   \n",
       "2                      0                     0       0       0   \n",
       "3                      0                     0       0       0   \n",
       "4                      0                     0       1       0   \n",
       "\n",
       "   anti_dsdna_antibody  anti_smith_antibody  label  \n",
       "0                    0                    0      0  \n",
       "1                    0                    0      0  \n",
       "2                    1                    0      1  \n",
       "3                    1                    1      1  \n",
       "4                    0                    1      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train_set_basic.csv')\n",
    "train_df = train_df.fillna(-1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ba2ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26203\n",
       "1    24197\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69937a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50400, 23), (50400,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:, 0:-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57ad4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['dqn', 'ddqn', 'dueling_dqn', 'dueling_ddqn', 'dqn_per', 'ddqn_per', 'dueling_dqn_per', \n",
    "#                'dueling_ddqn_per']\n",
    "model_names = ['dueling_dqn_per', 'dueling_ddqn_per']\n",
    "procs = []\n",
    "steps = int(10e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd793fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 469657   |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 469738   |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 954605   |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 954529   |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1455041  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1454566  |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1975289  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1975392  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 2515499  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2515613  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 3079980  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3080664  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3672036  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3672908  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4295247  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4296980  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4959944  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4961589  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5676528  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5679054  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6464306  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6468184  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7348071  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 7355003  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 23       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8002151  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8384281  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8482749  |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8731199  |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8971136  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 9187900  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 9403385  |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 9688420  |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 9607972  |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 9809424  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 10011812 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 10209541 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 10409616 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 10609620 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 10807258 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 11291677 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 11004406 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 11204480 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 11402278 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 11602124 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 11802123 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 12000885 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 12201194 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 12400133 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 12944646 |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 12601369 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 12802180 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 13001615 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 13204540 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 13405169 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 13605840 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 13812859 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 14013916 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 14633286 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 14217768 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 14421216 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 14622869 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 14826115 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 15028459 |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 15232277 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 15436259 |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 15642812 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 16325487 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 15853002 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 16059742 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 16265826 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 16474806 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 16683095 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 16889739 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 17098326 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 17304378 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 17986062 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 17510618 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 17722307 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 17937497 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 18144870 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 18355633 |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 18566313 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 18779159 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 18991883 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 19646394 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 19201496 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 19411124 |\n",
      "| success rate            | 0.25     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 19625740 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 19836390 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 20049746 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 20262794 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 20474431 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 21275201 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 20685718 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7400000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 20907567 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 21127856 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7600000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 21343620 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7700000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 21557537 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 21773228 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7900000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 21983682 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 22876380 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 22199201 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 22418925 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 22635038 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 22855152 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 23070930 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8500000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 23290126 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 23508564 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 24455075 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 23729353 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8800000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 23944972 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8900000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 24166742 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 24389714 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 24605457 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 24824625 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 25037881 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 26035092 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 25254837 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9500000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 25466786 |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 25691327 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 25918277 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9800000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 26134986 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 26356267 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 26571864 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 27576143 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10100000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 26789848 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10200000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 27015490 |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 27241910 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10400000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 27462282 |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10500000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 27688320 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 27907444 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10700000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 28127252 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 29147505 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10800000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 28349586 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10900000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 28574627 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 28804255 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11100000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 29033458 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 29254780 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 29479896 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11400000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 29706923 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 30728463 |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11500000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 29931655 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 30157841 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11700000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 30389217 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11800000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 30612389 |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11900000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 30833356 |\n",
      "| success rate            | 0.24     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 31054727 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 32306406 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12100000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 31290955 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12200000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 31520154 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12300000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 31751544 |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12400000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 31980440 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12500000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 32200879 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12600000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 32424605 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12700000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 32658007 |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 33867156 |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12800000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 32870179 |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12900000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 33105558 |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 33344950 |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13100000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 33584296 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13200000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 33813794 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13300000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 34037356 |\n",
      "| success rate            | 0.32     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13400000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 34273590 |\n",
      "| success rate            | 0.23     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 35438575 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13500000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 34493462 |\n",
      "| success rate            | 0.27     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13600000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 34740175 |\n",
      "| success rate            | 0.3      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13700000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 34980157 |\n",
      "| success rate            | 0.32     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13800000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 35214845 |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13900000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 35464754 |\n",
      "| success rate            | 0.28     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 35689465 |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 37042897 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14100000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 35948959 |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14200000 |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 36211780 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14300000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 36491913 |\n",
      "| success rate            | 0.27     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14400000 |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 36794650 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14500000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 37078878 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14600000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 37377866 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 38590790 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14700000 |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 37686383 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14800000 |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 37977860 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14900000 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 38297294 |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000000 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 38658966 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 40158477 |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15100000 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 39027306 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39421197 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15300000 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 39785573 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15400000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40169061 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 41646610 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15500000 |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 40555836 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15600000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40919132 |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15700000 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 41282984 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15800000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41665020 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 43179850 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15900000 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 42087579 |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42560077 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16100000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43079082 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 44680670 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43576792 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16300000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44069258 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16400000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44543374 |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 46206835 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16500000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45077052 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16600000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 45669049 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 47690269 |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16700000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46289852 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16800000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 46918739 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16900000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47555222 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 49215518 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 48241069 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17100000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 48933336 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 50699336 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17200000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49663517 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17300000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50355676 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 52192656 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17400000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 51071551 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17500000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 51759982 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 53662257 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17600000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 52435537 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17700000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 53134326 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 55135898 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17800000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 53884640 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17900000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 54639655 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 56571719 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55370651 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18100000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56108731 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 58036292 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56840648 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18300000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57549349 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 59497448 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18400000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58258764 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18500000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58980935 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 60968192 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18600000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59716570 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18700000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 60470442 |\n",
      "| success rate            | 0.91     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 62429331 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18800000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61166266 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18900000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61808146 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 63832479 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62478563 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19100000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 63183556 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 65255286 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63847085 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19300000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64522256 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 66681395 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19400000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65180301 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19500000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65860058 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 68095257 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19600000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 66525865 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19700000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 67168091 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 69525019 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19800000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67835788 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19900000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68488755 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 70940863 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69153454 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20100000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69723391 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 72365456 |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20200000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 70359644 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20300000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70990200 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20400000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 71603901 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 73776357 |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20500000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 72247057 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20600000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 72871715 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 75171512 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20700000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73443769 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20800000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74000030 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 76570661 |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20900000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74576380 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75132993 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21100000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75721164 |\n",
      "| success rate            | 0.9      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 78003612 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 76289550 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21300000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 76885457 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 79392072 |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21400000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77448538 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21500000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 78045414 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 80792286 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21600000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 78640895 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21700000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 79172127 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21800000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 79728418 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 82177335 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21900000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80245511 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80818815 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 83572601 |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22100000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 81334912 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22200000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 81866635 |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22300000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82416045 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 84994103 |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22400000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82988588 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22500000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 83495893 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 86416084 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22600000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 84060327 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22700000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84601555 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22800000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 85133457 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 87811795 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22900000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 85686835 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 86211696 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 89220648 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23100000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86753317 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 87249614 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23300000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 87766322 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 90613466 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23400000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88295927 |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23500000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 88847449 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23600000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89395496 |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 92072190 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23700000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89951270 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23800000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90463522 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7000000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 93477734 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23900000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90975488 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 91502167 |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24100000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92001017 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7100000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 94881135 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 92521742 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24300000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93047308 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24400000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93542448 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7200000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 96224128 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24500000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94032399 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24600000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94494778 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7300000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 97567270 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24700000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94966795 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24800000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95460983 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24900000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95985088 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7400000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 98901003 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 96502841 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25100000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 96991510 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25200000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 97510041 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25300000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98037966 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25400000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98529948 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25500000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99013169 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25600000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99464582 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25700000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99940600 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name in model_names:\n",
    "    proc = Process(target=run_dqn_model, args=(name, steps))\n",
    "    procs.append(proc)\n",
    "    proc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b771124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All jobs completed and terminated successfully\n"
     ]
    }
   ],
   "source": [
    "for proc in procs:\n",
    "    proc.join()\n",
    "print('All jobs completed and terminated successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a6f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
