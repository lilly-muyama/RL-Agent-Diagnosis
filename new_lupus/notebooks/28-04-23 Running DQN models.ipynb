{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce50672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../modules/utils.py:33: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from modules import utils, constants\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886dbf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = constants.SEED\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c76483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_data(X_train):\n",
    "    imputer = KNNImputer(n_neighbors=10)\n",
    "    X_imputed = imputer.fit_transform(X_train)\n",
    "    return X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab05958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1000000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants.BETA, constants.CHECKPOINT_FREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944d299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dqn_model(model_type, steps):\n",
    "    dir_name = f'seed_{SEED}_{steps}'\n",
    "    parent_dir = f'../models/logs/{model_type}/missingness/0.1/no_step_penalty/knn_imputer'\n",
    "    path = os.path.join(parent_dir, dir_name)\n",
    "    os.mkdir(path)\n",
    "  \n",
    "    if model_type=='dqn':\n",
    "        model = utils.stable_vanilla_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dqn', filename=f'dqn_{steps}')\n",
    "    elif model_type=='ddqn':\n",
    "        model = utils.stable_double_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='ddqn', filename=f'ddqn_{steps}')\n",
    "    elif model_type== 'dueling_dqn':\n",
    "        model = utils.stable_dueling_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_dqn', filename=f'dueling_dqn_{steps}')\n",
    "    elif model_type == 'dueling_ddqn':\n",
    "        model = utils.stable_dueling_ddqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_ddqn', filename=f'dueling_ddqn_{steps}')\n",
    "    elif model_type =='dqn_per':\n",
    "        model = utils.stable_vanilla_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dqn_per', filename=f'dqn_per_{steps}', per=True)\n",
    "    elif model_type == 'ddqn_per':\n",
    "        model = utils.stable_double_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='ddqn_per', filename=f'ddqn_per_{steps}', per=True)\n",
    "    elif model_type == 'dueling_dqn_per':\n",
    "        model = utils.stable_dueling_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_dqn_per', filename=f'dueling_dqn_per_{steps}', per=True)\n",
    "    elif model_type == 'dueling_ddqn_per':\n",
    "        model = utils.stable_dueling_ddqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_ddqn_per', filename=f'dueling_ddqn_per_{steps}', per=True)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model type - {model_type}!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d8fb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>biopsy_proven_lupus_nephritis</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ana  fever  leukopenia  thrombocytopenia  auto_immune_hemolysis  delirium  \\\n",
       "0    1    1.0         0.0               0.0                    NaN       0.0   \n",
       "1    1    0.0         1.0               0.0                    0.0       0.0   \n",
       "2    0    0.0         0.0               NaN                    0.0       0.0   \n",
       "3    0    0.0         0.0               0.0                    0.0       NaN   \n",
       "4    1    0.0         0.0               0.0                    0.0       1.0   \n",
       "\n",
       "   psychosis  seizure  non_scarring_alopecia  oral_ulcers  ...  proteinuria  \\\n",
       "0        0.0      0.0                    0.0          0.0  ...          1.0   \n",
       "1        0.0      0.0                    1.0          0.0  ...          0.0   \n",
       "2        0.0      0.0                    0.0          0.0  ...          0.0   \n",
       "3        0.0      0.0                    NaN          0.0  ...          1.0   \n",
       "4        0.0      0.0                    1.0          0.0  ...          1.0   \n",
       "\n",
       "   biopsy_proven_lupus_nephritis  anti_cardioliphin_antibodies  \\\n",
       "0                            0.0                           0.0   \n",
       "1                            0.0                           0.0   \n",
       "2                            0.0                           0.0   \n",
       "3                            0.0                           NaN   \n",
       "4                            3.0                           0.0   \n",
       "\n",
       "   anti_β2gp1_antibodies  lupus_anti_coagulant  low_c3  low_c4  \\\n",
       "0                    0.0                   0.0     0.0     1.0   \n",
       "1                    1.0                   0.0     0.0     0.0   \n",
       "2                    0.0                   0.0     0.0     0.0   \n",
       "3                    0.0                   0.0     0.0     0.0   \n",
       "4                    NaN                   0.0     0.0     NaN   \n",
       "\n",
       "   anti_dsdna_antibody  anti_smith_antibody  label  \n",
       "0                  0.0                  0.0      1  \n",
       "1                  1.0                  0.0      1  \n",
       "2                  0.0                  0.0      0  \n",
       "3                  0.0                  0.0      0  \n",
       "4                  0.0                  0.0      1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../new_data/train_set_missingness_0.1.csv')\n",
    "# train_df = train_df.fillna(-1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ba2ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25240\n",
       "1    25160\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34198c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ana                              0.0\n",
       "fever                            0.0\n",
       "leukopenia                       0.0\n",
       "thrombocytopenia                 0.0\n",
       "auto_immune_hemolysis            0.0\n",
       "delirium                         0.0\n",
       "psychosis                        0.0\n",
       "seizure                          0.0\n",
       "non_scarring_alopecia            0.0\n",
       "oral_ulcers                      0.0\n",
       "cutaneous_lupus                  0.0\n",
       "pleural_effusion                 0.0\n",
       "pericardial_effusion             0.0\n",
       "acute_pericarditis               0.0\n",
       "joint_involvement                0.0\n",
       "proteinuria                      0.0\n",
       "biopsy_proven_lupus_nephritis    0.0\n",
       "anti_cardioliphin_antibodies     0.0\n",
       "anti_β2gp1_antibodies            0.0\n",
       "lupus_anti_coagulant             0.0\n",
       "low_c3                           1.0\n",
       "low_c4                           0.0\n",
       "anti_dsdna_antibody              0.0\n",
       "anti_smith_antibody              NaN\n",
       "label                            0.0\n",
       "Name: 90, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69937a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50400, 24), (50400,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:, 0:-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "X_train = impute_missing_data(X_train)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ad4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['dqn', 'ddqn', 'dueling_dqn', 'dueling_ddqn', 'dqn_per', 'ddqn_per', 'dueling_dqn_per', \n",
    "#                'dueling_ddqn_per']\n",
    "model_names = ['dueling_dqn_per', 'dueling_ddqn_per']\n",
    "procs = []\n",
    "steps = int(100e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4648b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_dqn_model(model_names[0],steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd793fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The environment seed is [42]\n",
      "The environment seed is [42]\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:147: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:241: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:242: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:322: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:147: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:241: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:242: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:322: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 482493   |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 482398   |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 980196   |\n",
      "| success rate            | 0.23     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 979978   |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1495016  |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1494482  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2029925  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 2028868  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2585866  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2584376  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3166155  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 3165243  |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 3777427  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3776827  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4424626  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4423402  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5118017  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 5115613  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5868617  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5868983  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 36       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6697669  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 36       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6697919  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 7212732  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7649238  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 28       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 7521042  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7767754  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 7999058  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 21       |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8223131  |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8442577  |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8804506  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8657074  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 15       |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8868450  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 13       |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 9077583  |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 11       |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 9283199  |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 9485335  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 9684520  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 9880117  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 10072669 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 10326991 |\n",
      "| success rate            | 0.29     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 10265531 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 10458587 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 10652699 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 10846994 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 11040499 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 11235353 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 11432244 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 11629220 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 11991135 |\n",
      "| success rate            | 0.24     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 11826866 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 12024042 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 12220236 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 12416530 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 12613202 |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 12810026 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 13006992 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 13203789 |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 13615223 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 13399798 |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 13595917 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 13792044 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 13989750 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 14186258 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 14382195 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 14580256 |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 14779174 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 15212035 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 14978034 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 15177272 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 15375592 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 15572692 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 15770925 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 15967958 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 16165118 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 16361664 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 16787603 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 16561205 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 16759721 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 16959935 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 17158006 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 17358128 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 17558991 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 17763246 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 18354586 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 17966985 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 18167306 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 18367710 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 18566456 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 18771356 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 18972740 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7100000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 19172007 |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 19374470 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 19905883 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 19578486 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7400000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 19781904 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7500000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 19985967 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7600000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 20189204 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 20388320 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 20589446 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7900000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 20791405 |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 21457171 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 20994763 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8100000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 21194908 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 21397720 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 21599546 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 21802247 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8500000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 22001937 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 22204754 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8700000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 22406588 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 23035791 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8800000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 22609763 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8900000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 22810782 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9000000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 23014911 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 23219236 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 23420101 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 23620695 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9400000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 23823512 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 24024300 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 24625461 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 24230020 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 24432440 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 24634075 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 24836939 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 25039871 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10100000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 25244246 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 25447329 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 26236975 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10300000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 25651352 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10400000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 25854994 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10500000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 26060451 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 26266860 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10700000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 26473286 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10800000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 26677600 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10900000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 26881636 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 27087330 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 27857162 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11100000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 27290378 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 27496670 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11300000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 27702938 |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11400000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 27906943 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11500000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 28112522 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 28317407 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11700000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 28525007 |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11800000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 28730154 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 29499539 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11900000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 28933033 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 29137134 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12100000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 29342206 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 29546738 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 29749499 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12400000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 29951235 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12500000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 30154904 |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12600000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 30363021 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 31156916 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12700000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 30569627 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12800000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 30776853 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12900000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 30985805 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 31188933 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13100000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 31394695 |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 31599834 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 31804542 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 32822646 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13400000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 32010014 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13500000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 32217830 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 32425036 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13700000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 32633524 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13800000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 32840898 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13900000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 33046689 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 33253104 |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14100000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 33459824 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 34484914 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 33665210 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 33871420 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14400000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 34078264 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14500000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 34286009 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 34494491 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14700000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 34701430 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14800000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 34910699 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14900000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 35118172 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 36135051 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 35326492 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15100000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 35533112 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 35741413 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15300000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 35949954 |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15400000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 36157689 |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15500000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 36366096 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15600000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 36577106 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15700000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 36784536 |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 37798839 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15800000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 36992698 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15900000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 37200027 |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 37408286 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16100000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 37616530 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 37824994 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 38034964 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16400000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 38244219 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 39462662 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16500000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 38457865 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16600000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 38667628 |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16700000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 38881862 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16800000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 39092629 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16900000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 39300511 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 39511924 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17100000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 39723735 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 39939193 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 41132648 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17300000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 40152440 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17400000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 40366212 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17500000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 40578383 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 40789226 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17700000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 40999926 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17800000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 41214278 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17900000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 41429208 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 42791699 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 41640165 |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18100000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 41853158 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 42068872 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 42286271 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18400000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 42502507 |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18500000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 42720891 |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 42935919 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18700000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 43154696 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 44428758 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18800000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 43369268 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18900000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 43578981 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 43798280 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19100000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 44019351 |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19200000 |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 44232107 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 44458485 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19400000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 44674680 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 46055067 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19500000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 44904879 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 45120372 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19700000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 45342128 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19800000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 45556384 |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19900000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 45775962 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 45997648 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20100000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 46221720 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 47671460 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 46444018 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 46663370 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20400000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 46887172 |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20500000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 47109069 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 47330631 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20700000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 47555357 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20800000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 47782138 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 49273581 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20900000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 48009000 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 48236250 |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21100000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 48464207 |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 48704057 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 48933288 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21400000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 49168148 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21500000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 49402617 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 50866496 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21600000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 49632703 |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21700000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 49865906 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21800000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 50098754 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21900000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 50337818 |\n",
      "| success rate            | 0.27     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 50571340 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22100000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 50805011 |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 52447897 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 51045720 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 51278334 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22400000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 51520372 |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22500000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 51790724 |\n",
      "| success rate            | 0.24     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 52029014 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22700000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 52268044 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22800000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 52506251 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 54068246 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22900000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 52756170 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 53027720 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23100000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 53299942 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23200000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 53580462 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23300000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 53872194 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23400000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 54150006 |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 55717088 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23500000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 54463928 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23600000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 54758190 |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23700000 |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 55036754 |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23800000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 55558966 |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 57299540 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23900000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 56268491 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 57124824 |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 58871777 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24100000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 58036181 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 60430698 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24200000 |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 59086532 |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24300000 |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 60224337 |\n",
      "| success rate            | 0.27     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 61986445 |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24400000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 61456274 |\n",
      "| success rate            | 0.39     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 63544900 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24500000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 62710224 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 65115894 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24600000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 64027224 |\n",
      "| success rate            | 0.28     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 66721255 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24700000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 65373114 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 68318557 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24800000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 66766207 |\n",
      "| success rate            | 0.39     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24900000 |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 68185462 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 70005384 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000000 |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 69633973 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 71660657 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25100000 |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 71106578 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 73314696 |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25200000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 72618081 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 75009172 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25300000 |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 74159309 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 76687605 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25400000 |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 75704111 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 78361410 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25500000 |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 77293216 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 80019370 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25600000 |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 78915610 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 81644657 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25700000 |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 80563170 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 83262651 |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25800000 |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 82222117 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 84865765 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25900000 |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 83913337 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 86449207 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26000000 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 85624893 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 88052625 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26100000 |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 87325476 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 89600217 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 91115927 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26200000 |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 89017245 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 92646671 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26300000 |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 90669095 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 94161596 |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26400000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 92278763 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 95656816 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26500000 |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 93856358 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 97139466 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26600000 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 95403635 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 98632672 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26700000 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 96941788 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26800000 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 98477615 |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name in model_names:\n",
    "#     run_dqn_model(name, steps)\n",
    "    proc = Process(target=run_dqn_model, args=(name, steps))\n",
    "    procs.append(proc)\n",
    "    proc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b771124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All jobs completed and terminated successfully\n"
     ]
    }
   ],
   "source": [
    "for proc in procs:\n",
    "    proc.join()\n",
    "print('All jobs completed and terminated successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mylist = [{'name':30, 'list_feature': np.array([1,2,3]), 'label':0}, {'name':50, 'list_feature': np.array\n",
    "#                                                                       ([4,5,6]), 'label':1}]\n",
    "# a = pd.DataFrame(mylist)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a87b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.iloc[0]['list_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bdceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# X = a[['name', 'list_feature']]\n",
    "# y = a['label']\n",
    "# rf = RandomForestClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2283f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
