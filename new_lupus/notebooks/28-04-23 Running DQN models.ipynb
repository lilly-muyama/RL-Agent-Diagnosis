{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce50672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../modules/utils.py:33: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from modules import utils, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886dbf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = constants.SEED\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab05958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants.BETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944d299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dqn_model(model_type, steps):\n",
    "    dir_name = f'seed_{SEED}_{steps}'\n",
    "    parent_dir = f'../models/logs/{model_type}/noisiness/0.3/biopsy_3'\n",
    "    path = os.path.join(parent_dir, dir_name)\n",
    "    os.mkdir(path)\n",
    "  \n",
    "    if model_type=='dqn':\n",
    "        model = utils.stable_vanilla_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dqn', filename=f'dqn_{steps}')\n",
    "    elif model_type=='ddqn':\n",
    "        model = utils.stable_double_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='ddqn', filename=f'ddqn_{steps}')\n",
    "    elif model_type== 'dueling_dqn':\n",
    "        model = utils.stable_dueling_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_dqn', filename=f'dueling_dqn_{steps}')\n",
    "    elif model_type == 'dueling_ddqn':\n",
    "        model = utils.stable_dueling_ddqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_ddqn', filename=f'dueling_ddqn_{steps}')\n",
    "    elif model_type =='dqn_per':\n",
    "        model = utils.stable_vanilla_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dqn_per', filename=f'dqn_per_{steps}', per=True)\n",
    "    elif model_type == 'ddqn_per':\n",
    "        model = utils.stable_double_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='ddqn_per', filename=f'ddqn_per_{steps}', per=True)\n",
    "    elif model_type == 'dueling_dqn_per':\n",
    "        model = utils.stable_dueling_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_dqn_per', filename=f'dueling_dqn_per_{steps}', per=True)\n",
    "    elif model_type == 'dueling_ddqn_per':\n",
    "        model = utils.stable_dueling_ddqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_ddqn_per', filename=f'dueling_ddqn_per_{steps}', per=True)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model type - {model_type}!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d8fb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>biopsy_proven_lupus_nephritis</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ana  fever  leukopenia  thrombocytopenia  auto_immune_hemolysis  delirium  \\\n",
       "0    1      1           0                 0                      0         0   \n",
       "1    1      0           1                 0                      0         0   \n",
       "2    0      0           0                 0                      0         0   \n",
       "3    0      0           0                 0                      0         0   \n",
       "4    1      0           0                 0                      0         1   \n",
       "\n",
       "   psychosis  seizure  non_scarring_alopecia  oral_ulcers  ...  proteinuria  \\\n",
       "0          0        0                      0            0  ...            1   \n",
       "1          0        0                      1            0  ...            0   \n",
       "2          0        0                      0            0  ...            0   \n",
       "3          0        0                      0            0  ...            1   \n",
       "4          0        0                      1            0  ...            1   \n",
       "\n",
       "   biopsy_proven_lupus_nephritis  anti_cardioliphin_antibodies  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              0                             0   \n",
       "4                              3                             0   \n",
       "\n",
       "   anti_β2gp1_antibodies  lupus_anti_coagulant  low_c3  low_c4  \\\n",
       "0                      0                     0       0       1   \n",
       "1                      1                     0       0       0   \n",
       "2                      0                     0       0       0   \n",
       "3                      0                     0       0       0   \n",
       "4                      0                     0       0       0   \n",
       "\n",
       "   anti_dsdna_antibody  anti_smith_antibody  label  \n",
       "0                    0                    0      0  \n",
       "1                    1                    0      0  \n",
       "2                    0                    0      0  \n",
       "3                    0                    0      0  \n",
       "4                    0                    0      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../new_data/train_set_noisiness_0.3.csv')\n",
    "train_df = train_df.fillna(-1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ba2ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25330\n",
       "0    25070\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b34198c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ana                              0\n",
       "fever                            0\n",
       "leukopenia                       0\n",
       "thrombocytopenia                 0\n",
       "auto_immune_hemolysis            0\n",
       "delirium                         0\n",
       "psychosis                        0\n",
       "seizure                          0\n",
       "non_scarring_alopecia            0\n",
       "oral_ulcers                      0\n",
       "cutaneous_lupus                  0\n",
       "pleural_effusion                 0\n",
       "pericardial_effusion             0\n",
       "acute_pericarditis               0\n",
       "joint_involvement                0\n",
       "proteinuria                      0\n",
       "biopsy_proven_lupus_nephritis    0\n",
       "anti_cardioliphin_antibodies     0\n",
       "anti_β2gp1_antibodies            0\n",
       "lupus_anti_coagulant             0\n",
       "low_c3                           1\n",
       "low_c4                           0\n",
       "anti_dsdna_antibody              0\n",
       "anti_smith_antibody              0\n",
       "label                            1\n",
       "Name: 90, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69937a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50400, 24), (50400,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:, 0:-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ad4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['dqn', 'ddqn', 'dueling_dqn', 'dueling_ddqn', 'dqn_per', 'ddqn_per', 'dueling_dqn_per', \n",
    "#                'dueling_ddqn_per']\n",
    "model_names = ['dueling_dqn_per', 'dueling_ddqn_per']\n",
    "procs = []\n",
    "steps = int(10e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4648b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_dqn_model(model_names[0],steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd793fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The environment seed is [42]\n",
      "The environment seed is [42]WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:147: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:241: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:242: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:322: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:147: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:241: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:242: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:322: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 482677   |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 482520   |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 980209   |\n",
      "| success rate            | 0.26     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 979984   |\n",
      "| success rate            | 0.23     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1495273  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1494857  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2030397  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 2030020  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2585773  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2585247  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3166306  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 3165209  |\n",
      "| success rate            | 0.23     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3777945  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3777586  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4424331  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4424348  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5116923  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5116580  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 5868024  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5868869  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 6511048  |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 36       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6700903  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6789915  |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 7086803  |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 7429508  |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1.2     |\n",
      "| steps                   | 7653663  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 25       |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 7802105  |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 8157899  |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 18       |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 8601204  |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8809173  |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 8996442  |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 9445766  |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 9933977  |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 10328067 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 10422108 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 10961626 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 11452537 |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 12002887 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 11929178 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 12422052 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 12892601 |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 13340172 |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 13671251 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 13847535 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 14330532 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 14830640 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 15325450 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 15359914 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 15882656 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 16390077 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 16973112 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 16915983 |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 17411882 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 17839720 |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 18283423 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 18610158 |\n",
      "| success rate            | 0.48     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 18829387 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 19403631 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 20196108 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 19872731 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 20402156 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20930857 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 21722433 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 21479482 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 22044790 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 22671356 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 23225153 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 23196737 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 23689537 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 24215140 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 24725543 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 24749873 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 25300284 |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 25794092 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 26236034 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 26400122 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 26999927 |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 27708974 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 27561638 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 28107855 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 28603481 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 29187116 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 29163178 |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 29691924 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 30650817 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 30318727 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 30878909 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 31451296 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 32114456 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 32045696 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 32666024 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 33566622 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 33285698 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 33840835 |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 34368406 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 35044244 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 34943397 |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 35498865 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 36509296 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 36029064 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7000000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 36611394 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7100000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 37159529 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 37996629 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7200000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 37688635 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7300000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 38234024 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name in model_names:\n",
    "#     run_dqn_model(name, steps)\n",
    "    proc = Process(target=run_dqn_model, args=(name, steps))\n",
    "    procs.append(proc)\n",
    "    proc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b771124",
   "metadata": {},
   "outputs": [],
   "source": [
    "for proc in procs:\n",
    "    proc.join()\n",
    "print('All jobs completed and terminated successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a6f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5cd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
