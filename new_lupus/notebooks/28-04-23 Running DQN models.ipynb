{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce50672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from modules import utils, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886dbf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = constants.SEED\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944d299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dqn_model(model_type, steps):\n",
    "    dir_name = f'seed_{SEED}_{steps}'\n",
    "    parent_dir = f'../models/logs/{model_type}/ana_just'\n",
    "    path = os.path.join(parent_dir, dir_name)\n",
    "    os.mkdir(path)\n",
    "  \n",
    "    if model_type=='dqn':\n",
    "        model = utils.stable_vanilla_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dqn', filename=f'dqn_{steps}')\n",
    "    elif model_type=='ddqn':\n",
    "        model = utils.stable_double_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='ddqn', filename=f'ddqn_{steps}')\n",
    "    elif model_type== 'dueling_dqn':\n",
    "        model = utils.stable_dueling_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_dqn', filename=f'dueling_dqn_{steps}')\n",
    "    elif model_type == 'dueling_ddqn':\n",
    "        model = utils.stable_dueling_ddqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_ddqn', filename=f'dueling_ddqn_{steps}')\n",
    "    elif model_type =='dqn_per':\n",
    "        model = utils.stable_vanilla_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dqn_per', filename=f'dqn_per_{steps}', per=True)\n",
    "    elif model_type == 'ddqn_per':\n",
    "        model = utils.stable_double_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='ddqn_per', filename=f'ddqn_per_{steps}', per=True)\n",
    "    elif model_type == 'dueling_dqn_per':\n",
    "        model = utils.stable_dueling_dqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_dqn_per', filename=f'dueling_dqn_pre_{steps}', per=True)\n",
    "    elif model_type == 'dueling_ddqn_per':\n",
    "        model = utils.stable_dueling_ddqn(X_train, y_train, steps, save=True, log_path=path, log_prefix='dueling_ddqn_per', filename=f'dueling_ddqn_per_{steps}', per=True)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model type - {model_type}!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d8fb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_involvement</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ana  fever  leukopenia  thrombocytopenia  auto_immune_hemolysis  delirium  \\\n",
       "0    0      1           0                 0                      0         0   \n",
       "1    0      0           0                 0                      0         1   \n",
       "2    1      0           0                 0                      0         1   \n",
       "3    1      0           0                 0                      0         0   \n",
       "4    1      0           0                 1                      1         1   \n",
       "\n",
       "   psychosis  seizure  non_scarring_alopecia  oral_ulcers  ...  \\\n",
       "0          0        0                      0            0  ...   \n",
       "1          0        0                      0            0  ...   \n",
       "2          0        0                      0            0  ...   \n",
       "3          0        1                      1            0  ...   \n",
       "4          0        0                      0            0  ...   \n",
       "\n",
       "   joint_involvement  proteinuria  anti_cardioliphin_antibodies  \\\n",
       "0                  1            0                             0   \n",
       "1                  0            0                             0   \n",
       "2                  0            0                             0   \n",
       "3                  0            1                             0   \n",
       "4                  0            1                             0   \n",
       "\n",
       "   anti_β2gp1_antibodies  lupus_anti_coagulant  low_c3  low_c4  \\\n",
       "0                      0                     0       0       0   \n",
       "1                      0                     0       0       0   \n",
       "2                      0                     0       0       0   \n",
       "3                      0                     0       0       0   \n",
       "4                      0                     0       1       0   \n",
       "\n",
       "   anti_dsdna_antibody  anti_smith_antibody  label  \n",
       "0                    0                    0      0  \n",
       "1                    0                    0      0  \n",
       "2                    1                    0      1  \n",
       "3                    1                    1      1  \n",
       "4                    0                    1      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train_set_basic.csv')\n",
    "train_df = train_df.fillna(-1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ba2ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26203\n",
       "1    24197\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69937a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50400, 23), (50400,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:, 0:-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57ad4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['dqn', 'ddqn', 'dueling_dqn', 'dueling_ddqn', 'dqn_per', 'ddqn_per', 'dueling_dqn_per', \n",
    "               'dueling_ddqn_per']\n",
    "# model_names = ['dqn']\n",
    "procs = []\n",
    "steps = int(10e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4648b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_dqn_model(model_names[0],steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd793fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 470071   |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 470065   |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 470325   |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 470352   |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 470179   |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 470170   |\n",
      "| success rate            | 0.23     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 470550   |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 953062   |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 470244   |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 952971   |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 955447   |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 955285   |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1453688  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1452989  |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 1455829  |\n",
      "| success rate            | 0.24     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 953467   |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1455293  |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 953000   |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 955394   |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1972772  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 954975   |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1972722  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1974828  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1973545  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2512494  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2513081  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1454038  |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1453550  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 2515561  |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1455521  |\n",
      "| success rate            | 0.23     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2514567  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1455168  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3075151  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 3076278  |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3079407  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1973181  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3664948  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1973111  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3077893  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3667026  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1974219  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1972753  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3670491  |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4290710  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4291137  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3668022  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2513161  |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2513501  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 4955639  |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4295824  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 4958234  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2515171  |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4293133  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2512894  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3076411  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5672727  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3076799  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4963941  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5677506  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 4962618  |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 3079122  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6461737  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3076775  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 5683976  |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 6466574  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3666295  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 5684926  |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3666958  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7352522  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 6473362  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7358738  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3670516  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 3667529  |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6477717  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4292420  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4291198  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8351431  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7361653  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1.3     |\n",
      "| steps                   | 8421116  |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4296254  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 7371826  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 4292819  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 4958293  |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4955412  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 9528115  |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1.2     |\n",
      "| steps                   | 8420259  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -1.2     |\n",
      "| steps                   | 9739708  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 8431659  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4965921  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4962276  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5675774  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5673430  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 10952874 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -1.3     |\n",
      "| steps                   | 9815690  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 11183573 |\n",
      "| success rate            | 0.24     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 9731227  |\n",
      "| success rate            | 0.32     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5687181  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6463366  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 5684024  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 11741377 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6461697  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 12145070 |\n",
      "| success rate            | 0.26     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 12495868 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 10600680 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 12504520 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 12845181 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 11092644 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6477623  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 13097439 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -1.2     |\n",
      "| steps                   | 11604773 |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 7354829  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6475287  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 13407281 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7352026  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 11490824 |\n",
      "| success rate            | 0.39     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 13961026 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 13730403 |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 11714511 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 13987152 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 12039754 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 14275793 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 14536396 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 12514331 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 14743945 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 7193675  |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7372407  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 15425016 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 12783603 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 15043719 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 8411867  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 13373784 |\n",
      "| success rate            | 0.26     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 13020362 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 15286994 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 8405783  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 15558670 |\n",
      "| success rate            | 0.23     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 13302135 |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 13482917 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 15880371 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 16186697 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 13815384 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 7931900  |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 16899209 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 14033037 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 16546154 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 14234060 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 16846218 |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 9230756  |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8436997  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 14481622 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 17114604 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 15122400 |\n",
      "| success rate            | 0.3      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 14764473 |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 17337971 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 9746939  |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 14980501 |\n",
      "| success rate            | 0.27     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 17662865 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 9680169  |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 18355977 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 8710107  |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 15304074 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 18028356 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 15594582 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 18353609 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 10048744 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 15802850 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 18675963 |\n",
      "| success rate            | 0.32     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 16034619 |\n",
      "| success rate            | 0.26     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 18990737 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 10392893 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 16212903 |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 16845102 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 19758805 |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 16436429 |\n",
      "| success rate            | 0.27     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 19382271 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 16631208 |\n",
      "| success rate            | 0.32     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 9516120  |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 19694833 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 9818557  |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 16862601 |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 10864775 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 17075663 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 20132362 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 17282046 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 11335646 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 20386427 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 21150639 |\n",
      "| success rate            | 0.48     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 17495759 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 11246077 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 20756557 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 17730479 |\n",
      "| success rate            | 0.29     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 18590548 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 21064998 |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 17951900 |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 21377487 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 18210112 |\n",
      "| success rate            | 0.24     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 11716817 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 10426458 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 18436988 |\n",
      "| success rate            | 0.23     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 21699804 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 22556876 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 18654815 |\n",
      "| success rate            | 0.29     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 12109853 |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 22167455 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 18866461 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 22455810 |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 19145457 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 19376518 |\n",
      "| success rate            | 0.28     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 22789429 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 12567672 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 20314122 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 23079577 |\n",
      "| success rate            | 0.48     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 19712295 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 12894200 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 11527341 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11317909 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 24008929 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 23389538 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 20136310 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 23757469 |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 13052568 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 20354934 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 24098580 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 24459620 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 21010700 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 25553528 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 24834681 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 13585626 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 22042442 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12189308 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 21380952 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 25345822 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 21706004 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 14047280 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 25743961 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 14415108 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 22041368 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 26231243 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 27066500 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 22451679 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 13213450 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 26662394 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 14617772 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13033646 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 22859195 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 23762007 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 27142712 |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 23286310 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 27598955 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15095552 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 28562857 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 23754802 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 28066900 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 24215225 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 28551138 |\n",
      "| success rate            | 0.48     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 15908170 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13917091 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15654756 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 25483615 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 29075751 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 24761888 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 30055003 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 29447619 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16186781 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 29979339 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 25522125 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 14884972 |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14780637 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 16654611 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 30525814 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 31550462 |\n",
      "| success rate            | 0.48     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 26108010 |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 27200322 |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7000000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 30944023 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 17343436 |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 26561970 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17202260 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7100000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 31539696 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 27172320 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 33076822 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7200000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 32131424 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 15630811 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 17730193 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7300000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 32588648 |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 27784298 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 28931457 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7400000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 33213951 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 16546972 |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18301669 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 28551236 |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 34625371 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 18720577 |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7500000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33903803 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16511916 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 29296114 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7600000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 34488356 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18858451 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 30643412 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7000000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 29717413 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7700000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 35065480 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 36145111 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7100000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 30231956 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7800000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35699061 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 19469965 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 17381915 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 20041218 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7900000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 36241349 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7200000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 31066687 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 37699225 |\n",
      "| success rate            | 0.48     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 32348876 |\n",
      "| success rate            | 0.48     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 18202588 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8000000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 36828147 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 20227138 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8100000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37395874 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7300000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 31975941 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18267734 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37980280 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 39285240 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 21323183 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 20918781 |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8300000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 38537701 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 34064955 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7400000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 32873354 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8400000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39105426 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19175644 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7500000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 33651273 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 21611814 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 40826398 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8500000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39662650 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 19850371 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8600000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 40187015 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7600000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 34357671 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 35777718 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 22562251 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8700000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40767420 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 22342207 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 42361470 |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20061732 |\n",
      "| success rate            | 0.91     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7700000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 35134622 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8800000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 41345252 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8900000  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 41871720 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7800000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35885686 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23031662 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9000000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42403282 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 37487509 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 43870563 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 23775337 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9100000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42933832 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7900000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 36651630 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20953374 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 21486245 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43500193 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23749713 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 45364986 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9300000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44064300 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8000000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 37517169 |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 39190158 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9400000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44627904 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24443116 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 24965252 |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21823132 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9500000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45207966 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8100000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 38531642 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 46843571 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9600000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45783000 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25133320 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8200000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 39352037 |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 40902123 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9700000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46329642 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 23090162 |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22715123 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9800000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46919296 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 48388024 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 26137028 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8300000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 40192749 |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25859432 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9900000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 47504494 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 48090128 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8400000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 40932616 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 42624408 |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 49946287 |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23591801 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10100000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 48658716 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26596112 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8500000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 41708703 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 27273034 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10200000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49237046 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name in model_names:\n",
    "#     run_dqn_model(name, steps)\n",
    "    proc = Process(target=run_dqn_model, args=(name, steps))\n",
    "    procs.append(proc)\n",
    "    proc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b771124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All jobs completed and terminated successfully\n"
     ]
    }
   ],
   "source": [
    "for proc in procs:\n",
    "    proc.join()\n",
    "print('All jobs completed and terminated successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a6f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5cd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
