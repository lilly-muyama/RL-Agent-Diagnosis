{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947dbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from modules import constants\n",
    "from modules.env import LupusEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "import torch as th\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1fd836",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "th.manual_seed(SEED)\n",
    "th.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85551a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants.BETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffffd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class robustDQN(DQN):\n",
    "    def __init__(self, *args, beta, al_r, al_p, p_proxy, **kwargs):\n",
    "        self.beta = beta #(from fig 2)\n",
    "        self.al_r = al_r\n",
    "        self.al_p = al_p\n",
    "        self.p_proxy = p_proxy\n",
    "        self.norm_estimate = 0\n",
    "        super(robustDQN, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    \n",
    "    def estimate_norm_r2(self, four_tuple_batch, q_net, q_net_target):\n",
    "        state = four_tuple_batch[0]  # (batch, state)\n",
    "        q_net_val = q_net(state)  # (batch, actions)\n",
    "        q_net_argmax = q_net_val.argmax(dim=1)  # (batch, )\n",
    "        q_target_val = q_net_target(state)  # (batch, actions)\n",
    "        qmax = q_target_val.gather(dim=1, index=q_net_argmax.unsqueeze(-1))  # (batch, )\n",
    "\n",
    "        # calculate norm p for qmax\n",
    "        if self.p_proxy == 'inner_product':\n",
    "            norm_estimate = (sum(qmax ** 2)) ** (1/2)  # dual norm (itself)\n",
    "        elif self.p_proxy == 'l1-norm':\n",
    "            norm_estimate = max(abs(qmax))  # dual norm (l_infinity)\n",
    "        elif self.p_proxy == 'other': #change this \n",
    "            norm_estimate = np.var(qmax)^(1/2) #XOR\n",
    "        return norm_estimate, q_net_argmax\n",
    "\n",
    "        \n",
    "    \n",
    "    def train(self, gradient_steps: int, batch_size: int = 100) -> None:\n",
    "        self.policy.set_training_mode(True)\n",
    "        self._update_learning_rate(self.policy.optimizer)\n",
    "\n",
    "        losses = []\n",
    "        for _ in range(gradient_steps):\n",
    "            replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)  # type: ignore[union-attr]\n",
    "            s = replay_data.observations\n",
    "            a = replay_data.actions\n",
    "            r = replay_data.rewards\n",
    "            s_prime = replay_data.next_observations\n",
    "            d = replay_data.dones\n",
    "            \n",
    "            with th.no_grad():\n",
    "                next_q_values = self.q_net_target(s_prime)\n",
    "                next_q_values, _ = next_q_values.max(dim=1)\n",
    "                next_q_values = next_q_values.reshape(-1, 1) #max_q_prime\n",
    "                \n",
    "                #added\n",
    "                current_norm_estimate, _ = self.estimate_norm_r2((s, a, r, s_prime), self.q_net, self.q_net_target)\n",
    "                norm_estimate = self.beta * self.norm_estimate + (1 - self.beta) * current_norm_estimate  # moving avg\n",
    "                self.norm_estimate = norm_estimate  # update last norm\n",
    "                \n",
    "                #changed this\n",
    "                # try also without the 1-d. check github for reference\n",
    "                target_q_values = r - self.al_r + (1 - d) * self.gamma * (next_q_values - self.al_p * norm_estimate)\n",
    "                \n",
    "\n",
    "            # Get current Q-values estimates\n",
    "            current_q_values = self.q_net(s)\n",
    "\n",
    "            # Retrieve the q-values for the actions from the replay buffer\n",
    "            current_q_values = th.gather(current_q_values, dim=1, index=a.long())\n",
    "\n",
    "            # Compute Huber loss (less sensitive to outliers)\n",
    "            loss = F.smooth_l1_loss(current_q_values, target_q_values)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Optimize the policy\n",
    "            self.policy.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # Clip gradient norm\n",
    "            th.nn.utils.clip_grad_norm_(self.policy.parameters(), self.max_grad_norm)\n",
    "            self.policy.optimizer.step()\n",
    "\n",
    "        # Increase update counter\n",
    "        self._n_updates += gradient_steps\n",
    "\n",
    "        self.logger.record(\"train/n_updates\", self._n_updates, exclude=\"tensorboard\")\n",
    "        self.logger.record(\"train/loss\", np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bbf1ab",
   "metadata": {},
   "source": [
    "#### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ce5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(X, y, random=True):\n",
    "    '''\n",
    "    Creates and environment using the given data\n",
    "    '''\n",
    "    env = LupusEnv(X, y, random)\n",
    "    print(f'The environment seed is {env.seed()}') #to delete\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "938f3ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants.CHECKPOINT_FREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934fb6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_baselines3_robust_dqn(X_train, y_train, steps, save, log_path, log_prefix, filename, beta, al_r, al_p, \n",
    "                                 p_proxy):\n",
    "    training_env = create_env(X_train, y_train)\n",
    "    model = robustDQN('MlpPolicy', training_env, verbose=1, seed=constants.SEED, beta=beta, al_r=al_r, al_p=al_p,\n",
    "                     p_proxy=p_proxy)\n",
    "    checkpoint_callback = CheckpointCallback(save_freq=constants.CHECKPOINT_FREQ, save_path=log_path, \n",
    "                                            name_prefix=log_prefix)\n",
    "    model.learn(total_timesteps=steps, log_interval=100000, callback=checkpoint_callback)\n",
    "    if save:\n",
    "#         model.save(f'{log_path}/{filename}.pkl')\n",
    "        model.save(f'{log_path}/{filename}_full_model')\n",
    "    training_env.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaac1ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_robust_dqn_model(steps, beta, al_r, al_p, p_proxy):\n",
    "    dir_name = f'seed_{SEED}_{steps}'\n",
    "    parent_dir = f'../models/logs/robust_dqn3/noisiness/0.1/biopsy_9/inner_pdt'\n",
    "    path = os.path.join(parent_dir, dir_name)\n",
    "#     os.mkdir(path)\n",
    "    model = stable_baselines3_robust_dqn(X_train, y_train, steps, True, log_path=path, log_prefix='robust_dqn3', \n",
    "                                  filename=f'robust_dqn3_{steps}', beta=beta, al_r=al_r, al_p=al_p, p_proxy=p_proxy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d1ec76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>biopsy_proven_lupus_nephritis</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ana  fever  leukopenia  thrombocytopenia  auto_immune_hemolysis  delirium  \\\n",
       "0    1      1           0                 0                      0         0   \n",
       "1    1      0           1                 0                      0         0   \n",
       "2    0      0           0                 0                      0         0   \n",
       "3    0      0           0                 0                      0         0   \n",
       "4    1      0           0                 0                      0         1   \n",
       "\n",
       "   psychosis  seizure  non_scarring_alopecia  oral_ulcers  ...  proteinuria  \\\n",
       "0          0        0                      0            0  ...            1   \n",
       "1          0        0                      1            0  ...            0   \n",
       "2          0        0                      0            0  ...            0   \n",
       "3          0        0                      0            0  ...            1   \n",
       "4          0        0                      1            0  ...            1   \n",
       "\n",
       "   biopsy_proven_lupus_nephritis  anti_cardioliphin_antibodies  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              0                             0   \n",
       "4                              3                             0   \n",
       "\n",
       "   anti_β2gp1_antibodies  lupus_anti_coagulant  low_c3  low_c4  \\\n",
       "0                      0                     0       0       1   \n",
       "1                      1                     0       0       0   \n",
       "2                      0                     0       0       0   \n",
       "3                      0                     0       0       0   \n",
       "4                      0                     0       0       0   \n",
       "\n",
       "   anti_dsdna_antibody  anti_smith_antibody  label  \n",
       "0                    0                    0      1  \n",
       "1                    1                    0      1  \n",
       "2                    0                    0      0  \n",
       "3                    0                    0      0  \n",
       "4                    0                    0      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../new_data/train_set_noisiness_0.1.csv')\n",
    "train_df = train_df.fillna(-1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6139ddf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25204\n",
       "0    25196\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6127d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50400, 24), (50400,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:, 0:-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf650c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 100000000\n",
    "beta = 0.1 #(from fig 2)\n",
    "al_r = 0.01\n",
    "al_p = 0.01\n",
    "p_proxy = 'inner_product'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad03da15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The environment seed is [42]\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132624/997284591.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_robust_dqn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mal_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mal_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_proxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_132624/4283311245.py\u001b[0m in \u001b[0;36mrun_robust_dqn_model\u001b[0;34m(steps, beta, al_r, al_p, p_proxy)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     os.mkdir(path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     model = stable_baselines3_robust_dqn(X_train, y_train, steps, True, log_path=path, log_prefix='robust_dqn3', \n\u001b[0;32m----> 7\u001b[0;31m                                   filename=f'robust_dqn3_{steps}', beta=beta, al_r=al_r, al_p=al_p, p_proxy=p_proxy)\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_132624/2058535067.py\u001b[0m in \u001b[0;36mstable_baselines3_robust_dqn\u001b[0;34m(X_train, y_train, steps, save, log_path, log_prefix, filename, beta, al_r, al_p, p_proxy)\u001b[0m\n\u001b[1;32m      6\u001b[0m     checkpoint_callback = CheckpointCallback(save_freq=constants.CHECKPOINT_FREQ, save_path=log_path, \n\u001b[1;32m      7\u001b[0m                                             name_prefix=log_prefix)\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#         model.save(f'{log_path}/{filename}.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_3_env/lib/python3.7/site-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_3_env/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_132624/2353890531.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Optimize the policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Clip gradient norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_3_env/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_3_env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = run_robust_dqn_model(steps, beta, al_r, al_p, p_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaadae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
