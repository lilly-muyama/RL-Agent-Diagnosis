{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35968dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import ast\n",
    "from stable_baselines3 import DQN\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from modules import former_constants as constants\n",
    "from modules.env import LupusEnv\n",
    "from multiprocessing import Process\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from modules.env import LupusEnv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = constants.SEED\n",
    "SEED = constants.SEED\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "SEED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b028e69",
   "metadata": {},
   "source": [
    "#### Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dqn(filename, env=None):\n",
    "    '''\n",
    "    Loads a previously saved DQN model\n",
    "    '''\n",
    "    model = DQN.load(filename, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770039a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(X, y, random=True):\n",
    "    '''\n",
    "    Creates and environment using the given data\n",
    "    '''\n",
    "    env = LupusEnv(X, y, random)\n",
    "    print(f'The environment seed is {env.seed()}') #to delete\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b1898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dqn(dqn_model, X_test, y_test):\n",
    "    test_df = pd.DataFrame()\n",
    "    env = create_env(X_test, y_test, random=False)\n",
    "    count=0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            count+=1\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                action, _states = dqn_model.predict(obs, deterministic=True)\n",
    "                obs, rew, done, info = env.step(action)\n",
    "                if done == True:\n",
    "                    test_df = test_df.append(info, ignore_index=True)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c680ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_metrics(model, X_val, y_val):\n",
    "    val_df = evaluate_dqn(model, X_val, y_val)\n",
    "    acc, f1, roc_auc, = test(val_df['y_actual'], val_df['y_pred'])\n",
    "    min_path_length = val_df.episode_length.min()\n",
    "    average_path_length = val_df.episode_length.mean()\n",
    "    max_path_length = val_df.episode_length.max()\n",
    "    min_sample_pathway = val_df[val_df.episode_length==min_path_length].trajectory.iloc[0]\n",
    "    max_sample_pathway = val_df[val_df.episode_length==max_path_length].trajectory.iloc[0]\n",
    "    return acc, f1, roc_auc, min_path_length, average_path_length, max_path_length, min_sample_pathway, max_sample_pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c47b6",
   "metadata": {},
   "source": [
    "#### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('../new_data/val_set_constant.csv')\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_df.iloc[:, 0:-1]\n",
    "y_val = val_df.iloc[:, -1]\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(filename, prefix):\n",
    "    try:\n",
    "        return int(filename[len(prefix)+1:][:-10])\n",
    "    except Exception as e:\n",
    "        print(f'Filename: {filename}')\n",
    "        print(f'Exception: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model_name, seed, steps, X_val, y_val, prefix):\n",
    "    best_f1, best_acc, best_roc_auc, best_pathway_score, best_pahm_score, best_wpahm_score = -1, -1, -1, -1, -1, -1\n",
    "    perf_list = []\n",
    "    count = 0\n",
    "    \n",
    "    folder = f'../models/logs/robust_dqn3/noisiness/0.0/biopsy_9/l2_norm/seed_{seed}_{steps}'    \n",
    "    for item in os.listdir(folder):        \n",
    "        if item.startswith(prefix): # & (get_steps(item, prefix) > 20000000:\n",
    "            path = join(folder, item)\n",
    "            if (isfile(path)) & (path.endswith('.zip')):\n",
    "                count+=1\n",
    "                if count%10 == 0:\n",
    "                    print(count)\n",
    "                model = load_dqn(path)\n",
    "#                     wpahm_score = utils.get_val_metrics(model, X_val, y_val)\n",
    "                pathway_score, pahm_score, wpahm_score, acc, f1, roc_auc, min_length, avg_length, max_length, min_path, max_path = utils.get_val_metrics(model, X_val, y_val)\n",
    "                perf_dict = {'steps': get_steps(item, prefix), 'pathway_score':pathway_score, \n",
    "                             'pahm_score':pahm_score, 'weighted_pahm_score':wpahm_score, 'acc':acc, 'f1':f1, \n",
    "                             'roc_auc':roc_auc, 'min_path_length':min_length, 'avg_length':avg_length, \n",
    "                             'max_length':max_length, 'min_path':min_path, 'max_path':max_path} \n",
    "                perf_list.append(perf_dict)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    model.save(f'{folder}/best_acc_model')\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    model.save(f'{folder}/best_f1_model')\n",
    "                if roc_auc > best_roc_auc:\n",
    "                    best_roc_auc = roc_auc\n",
    "                    model.save(f'{folder}/best_roc_auc_model')\n",
    "\n",
    "    val_df = pd.DataFrame.from_dict(perf_list) \n",
    "    try:\n",
    "        val_df = val_df.sort_values(by=['steps'])\n",
    "    except:\n",
    "        pass\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    val_df.to_csv(f'{folder}/validation_results.csv', index=False)\n",
    "    return val_df          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in models:\n",
    "    proc = Process(target=validate_model, args=(name, SEED, steps, X_val, y_val, name))\n",
    "    procs.append(proc)\n",
    "    proc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for proc in procs:\n",
    "    proc.join()\n",
    "print('All jobs completed and terminated successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a427da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70c421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82049acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
