{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fada2763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from modules import utils, constants\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines import bench, logger\n",
    "# from stable_baselines.common.vec_env import DummyVecEnv, VecNormalize\n",
    "import tensorflow\n",
    "from stable_baselines.common.callbacks import CheckpointCallback\n",
    "# from modules.env import LupusEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97bbcffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = constants.SEED\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tensorflow.set_random_seed(constants.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a78a04",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7da045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_involvement</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ana  fever  leukopenia  thrombocytopenia  auto_immune_hemolysis  delirium  \\\n",
       "0    0      1           0                 0                      0         0   \n",
       "1    0      0           0                 0                      0         1   \n",
       "2    1      0           0                 0                      0         1   \n",
       "3    1      0           0                 0                      0         0   \n",
       "4    1      0           0                 1                      1         1   \n",
       "\n",
       "   psychosis  seizure  non_scarring_alopecia  oral_ulcers  ...  \\\n",
       "0          0        0                      0            0  ...   \n",
       "1          0        0                      0            0  ...   \n",
       "2          0        0                      0            0  ...   \n",
       "3          0        1                      1            0  ...   \n",
       "4          0        0                      0            0  ...   \n",
       "\n",
       "   joint_involvement  proteinuria  anti_cardioliphin_antibodies  \\\n",
       "0                  1            0                             0   \n",
       "1                  0            0                             0   \n",
       "2                  0            0                             0   \n",
       "3                  0            1                             0   \n",
       "4                  0            1                             0   \n",
       "\n",
       "   anti_β2gp1_antibodies  lupus_anti_coagulant  low_c3  low_c4  \\\n",
       "0                      0                     0       0       0   \n",
       "1                      0                     0       0       0   \n",
       "2                      0                     0       0       0   \n",
       "3                      0                     0       0       0   \n",
       "4                      0                     0       1       0   \n",
       "\n",
       "   anti_dsdna_antibody  anti_smith_antibody  label  \n",
       "0                    0                    0      0  \n",
       "1                    0                    0      0  \n",
       "2                    1                    0      1  \n",
       "3                    1                    1      1  \n",
       "4                    0                    1      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = pd.read_csv('../data/25_jan/train_set_basic.csv')\n",
    "train_df = pd.read_csv('../data/missingness/0/training_set.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d2ee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44200\n",
       "3     3120\n",
       "1     2246\n",
       "2      834\n",
       "Name: cutaneous_lupus, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.cutaneous_lupus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2cca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_involvement</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ana, fever, leukopenia, thrombocytopenia, auto_immune_hemolysis, delirium, psychosis, seizure, non_scarring_alopecia, oral_ulcers, cutaneous_lupus, pleural_effusion, pericardial_effusion, acute_pericarditis, joint_involvement, proteinuria, anti_cardioliphin_antibodies, anti_β2gp1_antibodies, lupus_anti_coagulant, low_c3, low_c4, anti_dsdna_antibody, anti_smith_antibody, label]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.ana==0) & (train_df.label==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "433bb55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ana                             0\n",
       "fever                           0\n",
       "leukopenia                      0\n",
       "thrombocytopenia                0\n",
       "auto_immune_hemolysis           0\n",
       "delirium                        0\n",
       "psychosis                       0\n",
       "seizure                         0\n",
       "non_scarring_alopecia           0\n",
       "oral_ulcers                     0\n",
       "cutaneous_lupus                 0\n",
       "pleural_effusion                0\n",
       "pericardial_effusion            0\n",
       "acute_pericarditis              0\n",
       "joint_involvement               0\n",
       "proteinuria                     0\n",
       "anti_cardioliphin_antibodies    0\n",
       "anti_β2gp1_antibodies           0\n",
       "lupus_anti_coagulant            0\n",
       "low_c3                          0\n",
       "low_c4                          0\n",
       "anti_dsdna_antibody             0\n",
       "anti_smith_antibody             0\n",
       "label                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab40074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c493a363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50400, 23), (50400,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:, 0:-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86478146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No lupus',\n",
       " 'Lupus',\n",
       " 'Inconclusive diagnosis',\n",
       " 'ana',\n",
       " 'fever',\n",
       " 'leukopenia',\n",
       " 'thrombocytopenia',\n",
       " 'auto_immune_hemolysis',\n",
       " 'delirium',\n",
       " 'psychosis',\n",
       " 'seizure',\n",
       " 'non_scarring_alopecia',\n",
       " 'oral_ulcers',\n",
       " 'cutaneous_lupus',\n",
       " 'pleural_effusion',\n",
       " 'pericardial_effusion',\n",
       " 'acute_pericarditis',\n",
       " 'joint_involvement',\n",
       " 'proteinuria',\n",
       " 'anti_cardioliphin_antibodies',\n",
       " 'anti_β2gp1_antibodies',\n",
       " 'lupus_anti_coagulant',\n",
       " 'low_c3',\n",
       " 'low_c4',\n",
       " 'anti_dsdna_antibody',\n",
       " 'anti_smith_antibody']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list = list(constants.CLASS_DICT.keys()) + [col  for col in train_df.columns if col!='label']\n",
    "action_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aaed4c",
   "metadata": {},
   "source": [
    "#### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "437fc880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 97       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 467494   |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 940237   |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1422864  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1911300  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 88       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2407399  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 2911750  |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3426522  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3950734  |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 4485240  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 5029756  |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 73       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 5586915  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6155496  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6737965  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7335259  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7952204  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8586939  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 56       |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 9241034  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 9919484  |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 10623380 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 11359130 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 42       |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 12127965 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 12940510 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 13801654 |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 14727016 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 25       |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 15728323 |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 16717870 |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 15       |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 17755912 |\n",
      "| success rate            | 0.26     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 18825008 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 19965982 |\n",
      "| success rate            | 0.24     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 21145868 |\n",
      "| success rate            | 0.3      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 22325062 |\n",
      "| success rate            | 0.26     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 23488452 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 24681134 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 25867767 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 27046479 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 28240832 |\n",
      "| success rate            | 0.3      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 29431495 |\n",
      "| success rate            | 0.32     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 30632329 |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 31851563 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 33085867 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 34323048 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 35547751 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 36771688 |\n",
      "| success rate            | 0.39     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 38009067 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 39275164 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 40538098 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 41791065 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 43038589 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 44290813 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 45552514 |\n",
      "| success rate            | 0.32     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 46796484 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 48046710 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 49293382 |\n",
      "| success rate            | 0.27     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 50565827 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 51816385 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 53062889 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 54316750 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 55542800 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 56780701 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 58027519 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 59292999 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 60562996 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 61861129 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 63156207 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 64436628 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 65728156 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 67023694 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 68343015 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 69653050 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7000000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 70962260 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7100000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 72290094 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7200000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 73613905 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7300000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 74948336 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7400000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 76283039 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7500000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 77629051 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7600000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 78982827 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7700000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 80343358 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7800000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 81693810 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7900000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 83050401 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8000000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 84404179 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8100000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 85767637 |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8200000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 87122874 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8300000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 88494450 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8400000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 89855573 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8500000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 91206782 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8600000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 92596097 |\n",
      "| success rate            | 0.47     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8700000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 94020985 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8800000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 95450516 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8900000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 96876721 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9000000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 98300174 |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9100000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 99735305 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 9200000   |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 101160844 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 9300000   |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 102583899 |\n",
      "| success rate            | 0.5       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 9400000   |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 104017199 |\n",
      "| success rate            | 0.5       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 9500000   |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 105472938 |\n",
      "| success rate            | 0.47      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 9600000   |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 106917980 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 9700000   |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 108374622 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 9800000   |\n",
      "| mean 100 episode reward | -0.6      |\n",
      "| steps                   | 109847070 |\n",
      "| success rate            | 0.44      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 9900000   |\n",
      "| mean 100 episode reward | -0.6      |\n",
      "| steps                   | 111322057 |\n",
      "| success rate            | 0.41      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10000000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 112797122 |\n",
      "| success rate            | 0.54      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10100000  |\n",
      "| mean 100 episode reward | -0.6      |\n",
      "| steps                   | 114293081 |\n",
      "| success rate            | 0.46      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10200000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 115799040 |\n",
      "| success rate            | 0.55      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10300000  |\n",
      "| mean 100 episode reward | -0.7      |\n",
      "| steps                   | 117308881 |\n",
      "| success rate            | 0.41      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10400000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 118822892 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10500000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 120347385 |\n",
      "| success rate            | 0.6       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10600000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 121883824 |\n",
      "| success rate            | 0.57      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10700000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 123457492 |\n",
      "| success rate            | 0.54      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10800000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 125039038 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 10900000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 126621947 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11000000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 128205434 |\n",
      "| success rate            | 0.49      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11100000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 129776289 |\n",
      "| success rate            | 0.54      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11200000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 131342900 |\n",
      "| success rate            | 0.6       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11300000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 132893490 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11400000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 134438230 |\n",
      "| success rate            | 0.48      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11500000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 135975611 |\n",
      "| success rate            | 0.49      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11600000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 137521729 |\n",
      "| success rate            | 0.51      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11700000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 139075715 |\n",
      "| success rate            | 0.49      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11800000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 140617138 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11900000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 142123269 |\n",
      "| success rate            | 0.62      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12000000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 143626806 |\n",
      "| success rate            | 0.6       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12100000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 145146003 |\n",
      "| success rate            | 0.54      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12200000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 146684977 |\n",
      "| success rate            | 0.55      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12300000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 148241870 |\n",
      "| success rate            | 0.54      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12400000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 149815394 |\n",
      "| success rate            | 0.48      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12500000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 151402620 |\n",
      "| success rate            | 0.57      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12600000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 153007890 |\n",
      "| success rate            | 0.57      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_410456/3089206856.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                          name_prefix='dqn_vanilla_basic')\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Save the trained DQN agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, replay_wrapper)\u001b[0m\n\u001b[1;32m    294\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                         _, td_errors = self._train_step(obses_t, actions, rewards, obses_tp1, obses_tp1, dones, weights,\n\u001b[0;32m--> 296\u001b[0;31m                                                         sess=self.sess)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprioritized_replay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sess, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgivens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgivens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_env = utils.create_env(X_train, y_train)\n",
    "training_env = bench.Monitor(training_env, logger.get_dir())\n",
    "\n",
    "model = DQN('MlpPolicy', training_env, verbose=1, seed=constants.SEED, learning_rate=0.0001, buffer_size=1000000, \n",
    "            learning_starts=50000, train_freq=4, target_network_update_freq=10000, exploration_final_eps=0.05, \n",
    "            n_cpu_tf_sess=1, policy_kwargs=dict(dueling=False), double_q=False)\n",
    "\n",
    "    \n",
    "checkpoint_callback = CheckpointCallback(save_freq=100000, save_path='../models/logs/sb/dqn_seed_84', \n",
    "                                         name_prefix='dqn_vanilla_basic')\n",
    "\n",
    "model.learn(total_timesteps=200000000, log_interval=100000, callback=checkpoint_callback)\n",
    "\n",
    "# Save the trained DQN agent\n",
    "model.save('../models/22_mar/vanilla_dqn_seed_84_lupus_diagnosis')\n",
    "# training_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6c9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169bafa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
