{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fada2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from modules import utils, constants\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from stable_baselines3 import DQN\n",
    "# # from stable_baselines import bench, logger\n",
    "# from stable_baselines.common.vec_env import DummyVecEnv, VecNormalize\n",
    "import tensorflow\n",
    "from stable_baselines.common.callbacks import CheckpointCallback\n",
    "# from modules.env import LupusEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bbcffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tensorflow.set_random_seed(constants.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a78a04",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7da045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_involvement</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ana  fever  leukopenia  thrombocytopenia  auto_immune_hemolysis  delirium  \\\n",
       "0    0      1           0                 0                      0         0   \n",
       "1    0      0           0                 0                      0         1   \n",
       "2    1      0           0                 0                      0         1   \n",
       "3    1      0           0                 0                      0         0   \n",
       "4    1      0           0                 1                      1         1   \n",
       "\n",
       "   psychosis  seizure  non_scarring_alopecia  oral_ulcers  ...  \\\n",
       "0          0        0                      0            0  ...   \n",
       "1          0        0                      0            0  ...   \n",
       "2          0        0                      0            0  ...   \n",
       "3          0        1                      1            0  ...   \n",
       "4          0        0                      0            0  ...   \n",
       "\n",
       "   joint_involvement  proteinuria  anti_cardioliphin_antibodies  \\\n",
       "0                  1            0                             0   \n",
       "1                  0            0                             0   \n",
       "2                  0            0                             0   \n",
       "3                  0            1                             0   \n",
       "4                  0            1                             0   \n",
       "\n",
       "   anti_β2gp1_antibodies  lupus_anti_coagulant  low_c3  low_c4  \\\n",
       "0                      0                     0       0       0   \n",
       "1                      0                     0       0       0   \n",
       "2                      0                     0       0       0   \n",
       "3                      0                     0       0       0   \n",
       "4                      0                     0       1       0   \n",
       "\n",
       "   anti_dsdna_antibody  anti_smith_antibody  label  \n",
       "0                    0                    0      0  \n",
       "1                    0                    0      0  \n",
       "2                    1                    0      1  \n",
       "3                    1                    1      1  \n",
       "4                    0                    1      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = pd.read_csv('../data/25_jan/train_set_basic.csv')\n",
    "train_df = pd.read_csv('../data/missingness/0/training_set.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d2ee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44200\n",
       "3     3120\n",
       "1     2246\n",
       "2      834\n",
       "Name: cutaneous_lupus, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.cutaneous_lupus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2cca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_involvement</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ana, fever, leukopenia, thrombocytopenia, auto_immune_hemolysis, delirium, psychosis, seizure, non_scarring_alopecia, oral_ulcers, cutaneous_lupus, pleural_effusion, pericardial_effusion, acute_pericarditis, joint_involvement, proteinuria, anti_cardioliphin_antibodies, anti_β2gp1_antibodies, lupus_anti_coagulant, low_c3, low_c4, anti_dsdna_antibody, anti_smith_antibody, label]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.ana==0) & (train_df.label==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "433bb55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ana                             0\n",
       "fever                           0\n",
       "leukopenia                      0\n",
       "thrombocytopenia                0\n",
       "auto_immune_hemolysis           0\n",
       "delirium                        0\n",
       "psychosis                       0\n",
       "seizure                         0\n",
       "non_scarring_alopecia           0\n",
       "oral_ulcers                     0\n",
       "cutaneous_lupus                 0\n",
       "pleural_effusion                0\n",
       "pericardial_effusion            0\n",
       "acute_pericarditis              0\n",
       "joint_involvement               0\n",
       "proteinuria                     0\n",
       "anti_cardioliphin_antibodies    0\n",
       "anti_β2gp1_antibodies           0\n",
       "lupus_anti_coagulant            0\n",
       "low_c3                          0\n",
       "low_c4                          0\n",
       "anti_dsdna_antibody             0\n",
       "anti_smith_antibody             0\n",
       "label                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ab40074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50400"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c493a363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50400, 23), (50400,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:, 0:-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86478146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No lupus',\n",
       " 'Lupus',\n",
       " 'Inconclusive diagnosis',\n",
       " 'ana',\n",
       " 'fever',\n",
       " 'leukopenia',\n",
       " 'thrombocytopenia',\n",
       " 'auto_immune_hemolysis',\n",
       " 'delirium',\n",
       " 'psychosis',\n",
       " 'seizure',\n",
       " 'non_scarring_alopecia',\n",
       " 'oral_ulcers',\n",
       " 'cutaneous_lupus',\n",
       " 'pleural_effusion',\n",
       " 'pericardial_effusion',\n",
       " 'acute_pericarditis',\n",
       " 'joint_involvement',\n",
       " 'proteinuria',\n",
       " 'anti_cardioliphin_antibodies',\n",
       " 'anti_β2gp1_antibodies',\n",
       " 'lupus_anti_coagulant',\n",
       " 'low_c3',\n",
       " 'low_c4',\n",
       " 'anti_dsdna_antibody',\n",
       " 'anti_smith_antibody']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list = list(constants.CLASS_DICT.keys()) + [col  for col in train_df.columns if col!='label']\n",
    "action_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aaed4c",
   "metadata": {},
   "source": [
    "#### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437fc880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new DQN\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 97       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 466779   |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 940480   |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1420834  |\n",
      "| success rate            | 0.24     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 1909194  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 88       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2406480  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 2911500  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3427042  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3950587  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4485052  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5033310  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 73       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 5592386  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6164079  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 6747851  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 7348488  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 7965652  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8599469  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 56       |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 9253789  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 9932764  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 10638623 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 11373207 |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 11986574 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 12525574 |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 37       |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 13079521 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 13662390 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 14239066 |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 14826005 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 15445366 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 23       |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 16098166 |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 16805476 |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 17499524 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 13       |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 18215793 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18977521 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19756465 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 20603772 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21418960 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22226619 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 23071580 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 23940052 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 24857119 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 25750453 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26660016 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 27559138 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28428975 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29332533 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 30235061 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31128726 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32031937 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32927369 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 33824619 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 34741007 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35646350 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 36554646 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37471303 |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 38396554 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39264898 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40157702 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 41047362 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 41914647 |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42798858 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43663296 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44544500 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45437158 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46314459 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 47182160 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48058963 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48932674 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 49786428 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50629644 |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51509536 |\n",
      "| success rate            | 0.9      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7000000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 52358307 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7100000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 53222366 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7200000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54081489 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7300000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54931015 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7400000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55806933 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7500000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 56652837 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7600000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57507320 |\n",
      "| success rate            | 0.9      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7700000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58366886 |\n",
      "| success rate            | 0.9      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7800000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 59207911 |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7900000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 60059982 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8000000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60868869 |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8100000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61693355 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62532909 |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8300000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63367999 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8400000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64194081 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8500000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64995474 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8600000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 65789686 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8700000  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 66563107 |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8800000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67376817 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8900000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68175420 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9000000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 68948398 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9100000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69757967 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9200000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 70550104 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9300000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71334286 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9400000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 72091384 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9500000  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 72861747 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9600000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73683933 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9700000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74469268 |\n",
      "| success rate            | 0.91     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9800000  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 75263831 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9900000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76083338 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76877220 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10100000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77653876 |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78435115 |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10300000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79211681 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10400000 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 79995542 |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10500000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80743989 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10600000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81505876 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10700000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82263371 |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10800000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83048249 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10900000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83841004 |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000000 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 84603693 |\n",
      "| success rate            | 0.94     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11100000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85337297 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86124372 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11300000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86873743 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11400000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87625722 |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11500000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 88375845 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11600000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89155497 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11700000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 89954501 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11800000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90750043 |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11900000 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 91499193 |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 92266856 |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12100000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93020981 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12200000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93785510 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12300000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94504930 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12400000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95241230 |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12500000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96001719 |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12600000 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 96743139 |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12700000 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 97487629 |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12800000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98211591 |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12900000 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98919018 |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000000 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 99630625 |\n",
      "| success rate            | 0.92     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13100000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 100374452 |\n",
      "| success rate            | 0.88      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13200000  |\n",
      "| mean 100 episode reward | 0.2       |\n",
      "| steps                   | 101097572 |\n",
      "| success rate            | 0.76      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13300000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 101831700 |\n",
      "| success rate            | 0.87      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13400000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 102571184 |\n",
      "| success rate            | 0.82      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13500000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 103309845 |\n",
      "| success rate            | 0.93      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13600000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 104040864 |\n",
      "| success rate            | 0.81      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13700000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 104765600 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13800000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 105494204 |\n",
      "| success rate            | 0.83      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13900000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 106195557 |\n",
      "| success rate            | 0.92      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14000000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 106928001 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14100000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 107627600 |\n",
      "| success rate            | 0.91      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14200000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 108347636 |\n",
      "| success rate            | 0.87      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14300000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 109066428 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14400000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 109768987 |\n",
      "| success rate            | 0.88      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14500000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 110452433 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14600000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 111176978 |\n",
      "| success rate            | 0.83      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14700000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 111861906 |\n",
      "| success rate            | 0.88      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14800000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 112593666 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14900000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 113306379 |\n",
      "| success rate            | 0.87      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15000000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 113995121 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15100000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 114705670 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15200000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 115415330 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15300000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 116125812 |\n",
      "| success rate            | 0.92      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15400000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 116841727 |\n",
      "| success rate            | 0.83      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15500000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 117527959 |\n",
      "| success rate            | 0.9       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15600000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 118225166 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15700000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 118904763 |\n",
      "| success rate            | 0.82      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15800000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 119594381 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15900000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 120244543 |\n",
      "| success rate            | 0.88      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16000000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 120941167 |\n",
      "| success rate            | 0.83      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16100000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 121637674 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16200000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 122308564 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16300000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 122998254 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16400000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 123643387 |\n",
      "| success rate            | 0.81      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16500000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 124302201 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16600000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 124955749 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16700000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 125630664 |\n",
      "| success rate            | 0.87      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16800000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 126264120 |\n",
      "| success rate            | 0.82      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16900000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 126921957 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17000000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 127599987 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17100000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 128266372 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17200000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 128958697 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17300000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 129646439 |\n",
      "| success rate            | 0.83      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17400000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 130322877 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17500000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 130981278 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17600000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 131605968 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17700000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 132262796 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17800000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 132913996 |\n",
      "| success rate            | 0.9       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17900000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 133582691 |\n",
      "| success rate            | 0.87      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18000000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 134229021 |\n",
      "| success rate            | 0.9       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18100000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 134868685 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18200000  |\n",
      "| mean 100 episode reward | 0.3       |\n",
      "| steps                   | 135510454 |\n",
      "| success rate            | 0.76      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18300000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 136157581 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18400000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 136809537 |\n",
      "| success rate            | 0.8       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18500000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 137470343 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18600000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 138145913 |\n",
      "| success rate            | 0.79      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18700000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 138795336 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18800000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 139453226 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18900000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 140105879 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19000000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 140738678 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19100000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 141364079 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19200000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 141995579 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19300000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 142613631 |\n",
      "| success rate            | 0.88      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19400000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 143240278 |\n",
      "| success rate            | 0.92      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19500000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 143844389 |\n",
      "| success rate            | 0.87      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19600000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 144488753 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19700000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 145107617 |\n",
      "| success rate            | 0.81      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19800000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 145718967 |\n",
      "| success rate            | 0.83      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 19900000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 146347932 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20000000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 146927238 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20100000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 147552102 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20200000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 148172578 |\n",
      "| success rate            | 0.8       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20300000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 148790217 |\n",
      "| success rate            | 0.8       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20400000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 149387887 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20500000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 150010178 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20600000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 150609810 |\n",
      "| success rate            | 0.91      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20700000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 151213258 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20800000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 151798600 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 20900000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 152416420 |\n",
      "| success rate            | 0.91      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21000000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 153000462 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21100000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 153595318 |\n",
      "| success rate            | 0.81      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21200000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 154189784 |\n",
      "| success rate            | 0.81      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21300000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 154775094 |\n",
      "| success rate            | 0.8       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21400000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 155336530 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21500000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 155915722 |\n",
      "| success rate            | 0.9       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21600000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 156480092 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21700000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 157074354 |\n",
      "| success rate            | 0.82      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21800000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 157677258 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 21900000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 158275385 |\n",
      "| success rate            | 0.82      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22000000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 158852567 |\n",
      "| success rate            | 0.82      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22100000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 159441324 |\n",
      "| success rate            | 0.87      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22200000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 160021090 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22300000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 160601875 |\n",
      "| success rate            | 0.88      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22400000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 161171088 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22500000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 161759057 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22600000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 162346537 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22700000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 162947725 |\n",
      "| success rate            | 0.88      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22800000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 163539673 |\n",
      "| success rate            | 0.89      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 22900000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 164107010 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23000000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 164706405 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23100000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 165273429 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23200000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 165825817 |\n",
      "| success rate            | 0.81      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23300000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 166399634 |\n",
      "| success rate            | 0.93      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23400000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 166963618 |\n",
      "| success rate            | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23500000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 167534117 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23600000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 168103536 |\n",
      "| success rate            | 0.9       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23700000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 168689593 |\n",
      "| success rate            | 0.86      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23800000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 169292554 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 23900000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 169867916 |\n",
      "| success rate            | 0.82      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 24000000  |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| steps                   | 170420501 |\n",
      "| success rate            | 0.9       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 24100000  |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| steps                   | 170992850 |\n",
      "| success rate            | 0.9       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 24200000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 171548820 |\n",
      "| success rate            | 0.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 24300000  |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| steps                   | 172112424 |\n",
      "| success rate            | 0.83      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 24400000  |\n",
      "| mean 100 episode reward | 0.4       |\n",
      "| steps                   | 172639918 |\n",
      "| success rate            | 0.8       |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# training_env = LupusEnv(X_train, y_train)\n",
    "# training_env = DummyVecEnv([lambda: training_env])\n",
    "# # training_env = VecNormalize(training_env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
    "\n",
    "# # Define and train the DQN agent\n",
    "# model = DQN('MlpPolicy', training_env, verbose=1, seed = constants.SEED)\n",
    "model = utils.create_stable_dqn(X_train, y_train)\n",
    "checkpoint_callback = CheckpointCallback(save_freq=100000, \n",
    "                                         save_path='../models/logs/sb/dueling_ddqn_prioritized_replay', \n",
    "                                         name_prefix='dueling_ddqn_pr_basic')\n",
    "\n",
    "model.learn(total_timesteps=200000000, log_interval=100000, callback=checkpoint_callback)\n",
    "\n",
    "# Save the trained DQN agent\n",
    "model.save('../models/22_mar/dueling_ddqn_PR_lupus_diagnosis')\n",
    "# training_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6c9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
