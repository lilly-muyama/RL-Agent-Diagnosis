{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fada2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from modules import utils, constants\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines import bench, logger\n",
    "# from stable_baselines.common.vec_env import DummyVecEnv, VecNormalize\n",
    "import tensorflow\n",
    "from stable_baselines.common.callbacks import CheckpointCallback\n",
    "# from modules.env import LupusEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97bbcffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = constants.SEED\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tensorflow.set_random_seed(constants.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a78a04",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b7da045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_involvement</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ana  fever  leukopenia  thrombocytopenia  auto_immune_hemolysis  delirium  \\\n",
       "0    0      1           0                 0                      0         0   \n",
       "1    0      0           0                 0                      0         1   \n",
       "2    1      0           0                 0                      0         1   \n",
       "3    1      0           0                 0                      0         0   \n",
       "4    1      0           0                 1                      1         1   \n",
       "\n",
       "   psychosis  seizure  non_scarring_alopecia  oral_ulcers  ...  \\\n",
       "0          0        0                      0            0  ...   \n",
       "1          0        0                      0            0  ...   \n",
       "2          0        0                      0            0  ...   \n",
       "3          0        1                      1            0  ...   \n",
       "4          0        0                      0            0  ...   \n",
       "\n",
       "   joint_involvement  proteinuria  anti_cardioliphin_antibodies  \\\n",
       "0                  1            0                             0   \n",
       "1                  0            0                             0   \n",
       "2                  0            0                             0   \n",
       "3                  0            1                             0   \n",
       "4                  0            1                             0   \n",
       "\n",
       "   anti_β2gp1_antibodies  lupus_anti_coagulant  low_c3  low_c4  \\\n",
       "0                      0                     0       0       0   \n",
       "1                      0                     0       0       0   \n",
       "2                      0                     0       0       0   \n",
       "3                      0                     0       0       0   \n",
       "4                      0                     0       1       0   \n",
       "\n",
       "   anti_dsdna_antibody  anti_smith_antibody  label  \n",
       "0                    0                    0      0  \n",
       "1                    0                    0      0  \n",
       "2                    1                    0      1  \n",
       "3                    1                    1      1  \n",
       "4                    0                    1      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = pd.read_csv('../data/25_jan/train_set_basic.csv')\n",
    "train_df = pd.read_csv('../data/missingness/0/training_set.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d2ee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44200\n",
       "3     3120\n",
       "1     2246\n",
       "2      834\n",
       "Name: cutaneous_lupus, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.cutaneous_lupus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2cca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ana</th>\n",
       "      <th>fever</th>\n",
       "      <th>leukopenia</th>\n",
       "      <th>thrombocytopenia</th>\n",
       "      <th>auto_immune_hemolysis</th>\n",
       "      <th>delirium</th>\n",
       "      <th>psychosis</th>\n",
       "      <th>seizure</th>\n",
       "      <th>non_scarring_alopecia</th>\n",
       "      <th>oral_ulcers</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_involvement</th>\n",
       "      <th>proteinuria</th>\n",
       "      <th>anti_cardioliphin_antibodies</th>\n",
       "      <th>anti_β2gp1_antibodies</th>\n",
       "      <th>lupus_anti_coagulant</th>\n",
       "      <th>low_c3</th>\n",
       "      <th>low_c4</th>\n",
       "      <th>anti_dsdna_antibody</th>\n",
       "      <th>anti_smith_antibody</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ana, fever, leukopenia, thrombocytopenia, auto_immune_hemolysis, delirium, psychosis, seizure, non_scarring_alopecia, oral_ulcers, cutaneous_lupus, pleural_effusion, pericardial_effusion, acute_pericarditis, joint_involvement, proteinuria, anti_cardioliphin_antibodies, anti_β2gp1_antibodies, lupus_anti_coagulant, low_c3, low_c4, anti_dsdna_antibody, anti_smith_antibody, label]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.ana==0) & (train_df.label==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "433bb55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ana                             0\n",
       "fever                           0\n",
       "leukopenia                      0\n",
       "thrombocytopenia                0\n",
       "auto_immune_hemolysis           0\n",
       "delirium                        0\n",
       "psychosis                       0\n",
       "seizure                         0\n",
       "non_scarring_alopecia           0\n",
       "oral_ulcers                     0\n",
       "cutaneous_lupus                 0\n",
       "pleural_effusion                0\n",
       "pericardial_effusion            0\n",
       "acute_pericarditis              0\n",
       "joint_involvement               0\n",
       "proteinuria                     0\n",
       "anti_cardioliphin_antibodies    0\n",
       "anti_β2gp1_antibodies           0\n",
       "lupus_anti_coagulant            0\n",
       "low_c3                          0\n",
       "low_c4                          0\n",
       "anti_dsdna_antibody             0\n",
       "anti_smith_antibody             0\n",
       "label                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab40074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c493a363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50400, 23), (50400,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:, 0:-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86478146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No lupus',\n",
       " 'Lupus',\n",
       " 'Inconclusive diagnosis',\n",
       " 'ana',\n",
       " 'fever',\n",
       " 'leukopenia',\n",
       " 'thrombocytopenia',\n",
       " 'auto_immune_hemolysis',\n",
       " 'delirium',\n",
       " 'psychosis',\n",
       " 'seizure',\n",
       " 'non_scarring_alopecia',\n",
       " 'oral_ulcers',\n",
       " 'cutaneous_lupus',\n",
       " 'pleural_effusion',\n",
       " 'pericardial_effusion',\n",
       " 'acute_pericarditis',\n",
       " 'joint_involvement',\n",
       " 'proteinuria',\n",
       " 'anti_cardioliphin_antibodies',\n",
       " 'anti_β2gp1_antibodies',\n",
       " 'lupus_anti_coagulant',\n",
       " 'low_c3',\n",
       " 'low_c4',\n",
       " 'anti_dsdna_antibody',\n",
       " 'anti_smith_antibody']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list = list(constants.CLASS_DICT.keys()) + [col  for col in train_df.columns if col!='label']\n",
    "action_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aaed4c",
   "metadata": {},
   "source": [
    "#### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "437fc880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 97       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 466700   |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 941460   |\n",
      "| success rate            | 0.23     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1422072  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1909633  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 88       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2406529  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2911655  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3425531  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 3949822  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 4482053  |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 5026067  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 73       |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 5584080  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 6156136  |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 6739153  |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7339321  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 7956629  |\n",
      "| success rate            | 0.21     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8590481  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 56       |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 9247817  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 9928039  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 10630809 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 11364814 |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 42       |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 12134027 |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 12944514 |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 13805425 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 14730626 |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 25       |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -1.2     |\n",
      "| steps                   | 15737832 |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 16765356 |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 15       |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 17776427 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 18743917 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 19680361 |\n",
      "| success rate            | 0.28     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 20601463 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 21481564 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3200000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 22364888 |\n",
      "| success rate            | 0.39     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3300000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 23222448 |\n",
      "| success rate            | 0.28     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3400000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 24059399 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3500000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 24884513 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3600000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 25708500 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3700000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 26557266 |\n",
      "| success rate            | 0.3      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3800000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 27381930 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3900000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 28234612 |\n",
      "| success rate            | 0.28     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4000000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 29119642 |\n",
      "| success rate            | 0.38     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4100000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 30024054 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4200000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 30945277 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4300000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 31894586 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4400000  |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 32855579 |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4500000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 33850683 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4600000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 34874723 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4700000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 36025257 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4800000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 37140422 |\n",
      "| success rate            | 0.29     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 4900000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 38194801 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5000000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 39235268 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5100000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 40261321 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5200000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 41269343 |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5300000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 42277886 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5400000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 43371455 |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5500000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 44371261 |\n",
      "| success rate            | 0.3      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5600000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 45349526 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5700000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 46278123 |\n",
      "| success rate            | 0.3      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5800000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 47181755 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 5900000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 48071315 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6000000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 48943617 |\n",
      "| success rate            | 0.35     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6100000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 49830027 |\n",
      "| success rate            | 0.32     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6200000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 50718732 |\n",
      "| success rate            | 0.31     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6300000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 51595083 |\n",
      "| success rate            | 0.27     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6400000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 52469119 |\n",
      "| success rate            | 0.29     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6500000  |\n",
      "| mean 100 episode reward | -1.3     |\n",
      "| steps                   | 53395610 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6600000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 54509754 |\n",
      "| success rate            | 0.36     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6700000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 55522738 |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6800000  |\n",
      "| mean 100 episode reward | -1.2     |\n",
      "| steps                   | 56502121 |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 6900000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 57472856 |\n",
      "| success rate            | 0.39     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7000000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 58434541 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7100000  |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 59381846 |\n",
      "| success rate            | 0.32     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7200000  |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 60341159 |\n",
      "| success rate            | 0.3      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7300000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 61287297 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7400000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 62241070 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7500000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 63202093 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7600000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 64160694 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7700000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 65086503 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7800000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 65991459 |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 7900000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 66857192 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8000000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 67704209 |\n",
      "| success rate            | 0.39     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8100000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 68541338 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8200000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 69361912 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8300000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 70196188 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8400000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 71040958 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8500000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 71893918 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8600000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 72735299 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8700000  |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 73595694 |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8800000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 74480855 |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 8900000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 75387991 |\n",
      "| success rate            | 0.53     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9000000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 76323724 |\n",
      "| success rate            | 0.37     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9100000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 77283623 |\n",
      "| success rate            | 0.4      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9200000  |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 78274623 |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9300000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 79327772 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9400000  |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 80407686 |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9500000  |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 81522530 |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9600000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 82631636 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9700000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 83747505 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9800000  |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 84880527 |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 9900000  |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 86038394 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 87214020 |\n",
      "| success rate            | 0.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10100000 |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 88353950 |\n",
      "| success rate            | 0.5      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10200000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 89421848 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10300000 |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 90390521 |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10400000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 91350615 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10500000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 92430796 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10600000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 93502457 |\n",
      "| success rate            | 0.46     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10700000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 94643313 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10800000 |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 95869885 |\n",
      "| success rate            | 0.44     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10900000 |\n",
      "| mean 100 episode reward | -0.6     |\n",
      "| steps                   | 97262952 |\n",
      "| success rate            | 0.42     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000000 |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 98699906 |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11100000  |\n",
      "| mean 100 episode reward | -0.6      |\n",
      "| steps                   | 100089483 |\n",
      "| success rate            | 0.42      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11200000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 101408705 |\n",
      "| success rate            | 0.48      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11300000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 102528619 |\n",
      "| success rate            | 0.39      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11400000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 103650109 |\n",
      "| success rate            | 0.54      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11500000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 104772675 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11600000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 105974208 |\n",
      "| success rate            | 0.46      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11700000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 107193605 |\n",
      "| success rate            | 0.45      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11800000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 108309957 |\n",
      "| success rate            | 0.56      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 11900000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 109424092 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12000000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 110451850 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12100000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 111517605 |\n",
      "| success rate            | 0.42      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12200000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 112779221 |\n",
      "| success rate            | 0.51      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12300000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 114142237 |\n",
      "| success rate            | 0.65      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12400000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 115498515 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12500000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 116801718 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12600000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 118082688 |\n",
      "| success rate            | 0.44      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12700000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 119337660 |\n",
      "| success rate            | 0.6       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12800000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 120604638 |\n",
      "| success rate            | 0.55      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 12900000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 121852739 |\n",
      "| success rate            | 0.48      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13000000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 123112783 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13100000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 124405324 |\n",
      "| success rate            | 0.51      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13200000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 125703080 |\n",
      "| success rate            | 0.57      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13300000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 127054679 |\n",
      "| success rate            | 0.55      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13400000  |\n",
      "| mean 100 episode reward | -0.1      |\n",
      "| steps                   | 128424111 |\n",
      "| success rate            | 0.68      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13500000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 129796752 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13600000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 131177927 |\n",
      "| success rate            | 0.55      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13700000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 132556834 |\n",
      "| success rate            | 0.6       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13800000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 133939768 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 13900000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 135321031 |\n",
      "| success rate            | 0.62      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14000000  |\n",
      "| mean 100 episode reward | -0.1      |\n",
      "| steps                   | 136709864 |\n",
      "| success rate            | 0.65      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14100000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 138104855 |\n",
      "| success rate            | 0.61      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14200000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 139528050 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14300000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 140950328 |\n",
      "| success rate            | 0.48      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14400000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 142394495 |\n",
      "| success rate            | 0.6       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14500000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 143847106 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14600000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 145303138 |\n",
      "| success rate            | 0.55      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14700000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 146749577 |\n",
      "| success rate            | 0.64      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14800000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 148207651 |\n",
      "| success rate            | 0.61      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 14900000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 149611207 |\n",
      "| success rate            | 0.56      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15000000  |\n",
      "| mean 100 episode reward | -0.1      |\n",
      "| steps                   | 151034798 |\n",
      "| success rate            | 0.67      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15100000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 152539187 |\n",
      "| success rate            | 0.51      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15200000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 154052497 |\n",
      "| success rate            | 0.53      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15300000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 155558081 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15400000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 157061589 |\n",
      "| success rate            | 0.49      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15500000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 158584382 |\n",
      "| success rate            | 0.49      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15600000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 160111024 |\n",
      "| success rate            | 0.57      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15700000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 161620945 |\n",
      "| success rate            | 0.48      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15800000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 163122019 |\n",
      "| success rate            | 0.51      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 15900000  |\n",
      "| mean 100 episode reward | -0.6      |\n",
      "| steps                   | 164619020 |\n",
      "| success rate            | 0.45      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16000000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 166135728 |\n",
      "| success rate            | 0.64      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16100000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 167649234 |\n",
      "| success rate            | 0.61      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16200000  |\n",
      "| mean 100 episode reward | -0.6      |\n",
      "| steps                   | 169166167 |\n",
      "| success rate            | 0.46      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16300000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 170699383 |\n",
      "| success rate            | 0.61      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16400000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 172250908 |\n",
      "| success rate            | 0.56      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16500000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 173782549 |\n",
      "| success rate            | 0.61      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16600000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 175320757 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16700000  |\n",
      "| mean 100 episode reward | -0.5      |\n",
      "| steps                   | 176857809 |\n",
      "| success rate            | 0.46      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16800000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 178411338 |\n",
      "| success rate            | 0.59      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 16900000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 179962604 |\n",
      "| success rate            | 0.58      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17000000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 181523922 |\n",
      "| success rate            | 0.52      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17100000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 183073776 |\n",
      "| success rate            | 0.56      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17200000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 184610959 |\n",
      "| success rate            | 0.6       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17300000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 186141855 |\n",
      "| success rate            | 0.61      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17400000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 187614435 |\n",
      "| success rate            | 0.6       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17500000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 189089481 |\n",
      "| success rate            | 0.55      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17600000  |\n",
      "| mean 100 episode reward | -0.1      |\n",
      "| steps                   | 190573533 |\n",
      "| success rate            | 0.69      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17700000  |\n",
      "| mean 100 episode reward | -0.4      |\n",
      "| steps                   | 192031853 |\n",
      "| success rate            | 0.51      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17800000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 193497821 |\n",
      "| success rate            | 0.56      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 17900000  |\n",
      "| mean 100 episode reward | -0.3      |\n",
      "| steps                   | 194958910 |\n",
      "| success rate            | 0.61      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18000000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 196409693 |\n",
      "| success rate            | 0.62      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18100000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 197877455 |\n",
      "| success rate            | 0.61      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 5         |\n",
      "| episodes                | 18200000  |\n",
      "| mean 100 episode reward | -0.2      |\n",
      "| steps                   | 199342086 |\n",
      "| success rate            | 0.66      |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "training_env = utils.create_env(X_train, y_train)\n",
    "training_env = bench.Monitor(training_env, logger.get_dir())\n",
    "\n",
    "model = DQN('MlpPolicy', training_env, verbose=1, seed=constants.SEED, learning_rate=0.0001, buffer_size=1000000, \n",
    "            learning_starts=50000, train_freq=4, target_network_update_freq=10000, exploration_final_eps=0.05, \n",
    "            n_cpu_tf_sess=1, policy_kwargs=dict(dueling=False), double_q=False)\n",
    "\n",
    "    \n",
    "checkpoint_callback = CheckpointCallback(save_freq=100000, save_path='../models/logs/sb/dqn_seed_84', \n",
    "                                         name_prefix='dqn_vanilla_basic')\n",
    "\n",
    "model.learn(total_timesteps=200000000, log_interval=100000, callback=checkpoint_callback)\n",
    "\n",
    "# Save the trained DQN agent\n",
    "model.save('../models/22_mar/vanilla_dqn_seed_84_lupus_diagnosis')\n",
    "# training_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6c9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169bafa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
