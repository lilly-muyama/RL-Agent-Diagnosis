{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fea7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import random\n",
    "import collections\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import plotly.graph_objects as go\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from modules import utils, constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457472ca",
   "metadata": {},
   "source": [
    "#### The functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b484b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamline_frequency_dict(frequency_dict):\n",
    "    frequency_dict_list = [] #will hold dictonaries with 2 keys i.e. 'set' and 'value'\n",
    "    for path_dict, value in frequency_dict.items():\n",
    "        all_set_list = [i['set'] for i in frequency_dict_list] #get all the sets so far in the list \n",
    "        path_set = set(ast.literal_eval(path_dict)) #get the set of current path dict to check if its already in list\n",
    "        if path_set in all_set_list: #increase value else insert it - work on this!!!!!!!!!!!!!!!\n",
    "            for elem in frequency_dict_list: #look for if path_set is already in frequency_dict_list \n",
    "                if elem['set'] == path_set: #find the matching path_set in the frequency_dict_list\n",
    "                    elem['value'] += value #increase the value for that set\n",
    "        else:\n",
    "            frequency_dict_list.append({'set':path_set, 'value':value})\n",
    "    \n",
    "    all_list = [list(path_dict['set']) for path_dict in frequency_dict_list]\n",
    "    flat_list = [item for sublist in all_list for item in sublist]\n",
    "    commonest_elements = dict(collections.Counter(flat_list))\n",
    "    commonest_elements = {k: v for k, v in sorted(commonest_elements.items(), reverse=True, key=lambda item: item[1])}\n",
    "    commonest_elements_list = list(commonest_elements.keys())\n",
    "    commonest_elements_list = [i for i in commonest_elements_list if i not in ['Lupus', 'No lupus', 'Inconclusive diagnosis']] + ['Lupus', 'No lupus', 'Inconclusive diagnosis']\n",
    "    \n",
    "    for item in frequency_dict_list:\n",
    "        item['set'] = sorted(list(item['set']), key=lambda x: commonest_elements_list.index(x))\n",
    "    \n",
    "    keys = [str(i['set']) for i in frequency_dict_list]\n",
    "    values = [i['value'] for i in frequency_dict_list]\n",
    "    final_frequency_dict = {k:v for (k,v) in zip(keys, values)}\n",
    "    \n",
    "    return final_frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8176384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tuple_dict(df):\n",
    "    frequency_dict = {}\n",
    "    for traj in df.trajectory:\n",
    "        if traj in frequency_dict.keys():\n",
    "            frequency_dict[traj] += 1\n",
    "        else:\n",
    "            frequency_dict[traj] = 1\n",
    "    streamlined_frequency_dict = streamline_frequency_dict(frequency_dict)\n",
    "    overall_tup_dict = {}\n",
    "    for key, value in streamlined_frequency_dict.items():\n",
    "        new_key = ast.literal_eval(key)\n",
    "        for tup in zip(new_key, new_key[1:]):\n",
    "            #print(f'tup: {tup}')\n",
    "            if tup in overall_tup_dict.keys():\n",
    "                overall_tup_dict[tup] += value\n",
    "            else:\n",
    "                overall_tup_dict[tup] = value\n",
    "    #print(f'overall_tup_dict: {overall_tup_dict}')\n",
    "    return overall_tup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf92f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sankey_df(df):\n",
    "    overall_tup_dict = generate_tuple_dict(df)\n",
    "    sankey_df = pd.DataFrame()\n",
    "    sankey_df['source'] = [i[0] for i in overall_tup_dict.keys()]\n",
    "    sankey_df['target'] = [i[1] for i in overall_tup_dict.keys()]\n",
    "    sankey_df['value'] = list(overall_tup_dict.values())\n",
    "    sankey_df['link_type'] = sankey_df['target'].apply(lambda i: 'terminal' if i in ['No lupus', 'Lupus', 'Inconclusive diagnosis'] else 'non_terminal')\n",
    "    return sankey_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66ead8",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "672a2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_length</th>\n",
       "      <th>reward</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_actual</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>terminated</th>\n",
       "      <th>is_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'joint_involvement', 'low_c4', 'oral_u...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'joint_involvement', 'proteinuria', 'p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'joint_involvement', 'low_c4', 'oral_u...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'joint_involvement', 'proteinuria', 'p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['ana', 'joint_involvement', 'low_c4', 'oral_u...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_length    reward  y_pred  y_actual  \\\n",
       "0             8.0  1.727273     1.0       1.0   \n",
       "1            13.0  1.500000     1.0       1.0   \n",
       "2             8.0  1.727273     1.0       1.0   \n",
       "3            18.0  1.272727     1.0       1.0   \n",
       "4             8.0  1.727273     1.0       1.0   \n",
       "\n",
       "                                          trajectory  terminated  is_success  \n",
       "0  ['ana', 'joint_involvement', 'low_c4', 'oral_u...         0.0         1.0  \n",
       "1  ['ana', 'joint_involvement', 'proteinuria', 'p...         0.0         1.0  \n",
       "2  ['ana', 'joint_involvement', 'low_c4', 'oral_u...         0.0         1.0  \n",
       "3  ['ana', 'joint_involvement', 'proteinuria', 'p...         0.0         1.0  \n",
       "4  ['ana', 'joint_involvement', 'low_c4', 'oral_u...         0.0         1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df = pd.read_csv('../test_dfs/negative_reward/missingness_0.5.csv').drop(['index'], axis=1)\n",
    "test_df = pd.read_csv('../test_dfs/negative_reward/step_reward_twenty_two.csv').drop(['index'], axis=1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "950fd2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.71428571428572"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_rate, success_df = utils.success_rate(test_df)\n",
    "success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34d8f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1*len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e574c834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47df11",
   "metadata": {},
   "source": [
    "#### Pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44bf08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start_node = 'ana'\n",
    "# terminal_nodes = ['Lupus', 'No lupus', 'Inconclusive diagnosis']\n",
    "# non_terminal_nodes = ['anti_dsdna_antibody', 'joint_involvement', 'pericardial_effusion', 'proteinuria', 'low_c4', \n",
    "#                       'cutaneous_lupus', 'low_c3', 'non_scarring_alopecia', 'pleural_effusion', 'leukopenia', \n",
    "#                       'thrombocytopenia', 'fever', 'seizure', 'delirium', 'anti_smith_antibody', \n",
    "#                       'anti_cardioliphin_antibodies', 'psychosis', 'lupus_anti_coagulant', 'anti_β2gp1_antibodies', \n",
    "#                       'oral_ulcers', 'auto_immune_hemolysis', 'acute_pericarditis']\n",
    "pathways_df = create_sankey_df(test_df)\n",
    "start_node = pathways_df.iloc[0]['source']\n",
    "all_nodes = list(set(pathways_df.source.unique().tolist() + pathways_df.target.unique().tolist()))\n",
    "terminal_nodes = list(set(pathways_df[pathways_df.link_type=='terminal'].target))\n",
    "non_terminal_nodes = [i for i in all_nodes if i not in terminal_nodes and i!=start_node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7174123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pyvis_network(pathways_df):\n",
    "#     pathways_df = create_sankey_df(test_df)\n",
    "    pathways_df['type'] = 'directed'\n",
    "    \n",
    "    got_net = Network(notebook=True, height='750px', width='100%', directed=True, cdn_resources='in_line')\n",
    "    got_net.add_node(start_node, color='purple', size=20)\n",
    "    got_net.add_nodes(non_terminal_nodes, size=[15]*len(non_terminal_nodes), color=['blue']*len(non_terminal_nodes))\n",
    "    got_net.add_nodes(terminal_nodes, color=['green']*len(terminal_nodes), size=[20]*len(terminal_nodes))\n",
    "    for src, target, value in zip(pathways_df.source, pathways_df.target, pathways_df.value):\n",
    "        if value > threshold:\n",
    "            got_net.add_edge(src, target, value=value, color='red')\n",
    "        else:\n",
    "            got_net.add_edge(src, target, value=value, color='blue')\n",
    "    return got_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3c6a7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"Example.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f64d4514950>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_net = draw_pyvis_network(pathways_df)    \n",
    "got_net.show('Example.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede503d0",
   "metadata": {},
   "source": [
    "#### The Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06063658",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_confusion_matrix(test_df['y_actual'], test_df['y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b0b6c",
   "metadata": {},
   "source": [
    "#### The Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_classification_report(test_df['y_actual'], test_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275b5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0d0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
