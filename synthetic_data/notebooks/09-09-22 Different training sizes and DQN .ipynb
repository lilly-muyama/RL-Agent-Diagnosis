{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7654c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "import os\n",
    "import utils\n",
    "from envs import SyntheticComplexHbEnv\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines import bench, logger\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c8b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tensorflow.set_random_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441dd8ca",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e4cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_train_set(x, y, sample_num):\n",
    "    idx_list = random.sample(list(x.index), sample_num)\n",
    "    sampled_x = x.loc[idx_list]\n",
    "    sampled_y = y.loc[idx_list]\n",
    "    return np.array(sampled_x), np.array(sampled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d8d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_dqn(X_train, y_train, timesteps, model_file_name):\n",
    "    training_env = SyntheticComplexHbEnv(X_train, y_train)\n",
    "    env = bench.Monitor(training_env, logger.get_dir())\n",
    "    model = DQN('MlpPolicy', training_env, verbose=1, seed=SEED, n_cpu_tf_sess=1)\n",
    "    model.learn(total_timesteps=timesteps, log_interval=10000)\n",
    "    model.save(f'models/{model_file_name}.pkl')\n",
    "    env.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf10df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dqn(dqn_model, X_test, y_test):\n",
    "    test_df = pd.DataFrame()\n",
    "    test_env = SyntheticComplexHbEnv(X_test, y_test, random=False)\n",
    "    count=0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            count+=1\n",
    "            if count%5000==0:\n",
    "                print(f'Count: {count}')\n",
    "            obs, done = test_env.reset(), False\n",
    "            while not done:\n",
    "                action, _states = dqn_model.predict(obs, deterministic=True)\n",
    "                obs, rew, done,info = test_env.step(action)\n",
    "                if done == True:\n",
    "                    test_df = test_df.append(info, ignore_index=True)\n",
    "    except StopIteration:\n",
    "        print('Testing done.....')\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9cff5d",
   "metadata": {},
   "source": [
    "#### The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7406bf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No anemia': 0, 'Hemolytic anemia': 1, 'Aplastic anemia': 2, 'Iron deficiency anemia': 3, 'Vitamin B12/Folate deficiency anemia': 4, 'Anemia of chronic disease': 5}\n",
      "1    14146\n",
      "0    10000\n",
      "2     9450\n",
      "5     1869\n",
      "4     1575\n",
      "3     1343\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((26868, 6), (11515, 6), (26868,), (11515,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/anemia_synth_dataset_hb_some_nans.csv') #my real dataset i think\n",
    "df = df.fillna(0)\n",
    "classes = list(df.label.unique())\n",
    "nums = [i for i in range(len(classes))]\n",
    "class_dict = dict(zip(classes, nums))\n",
    "print(class_dict)\n",
    "df['label'] = df['label'].replace(class_dict)\n",
    "print(df.label.value_counts())\n",
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "full_X_train, X_test, full_y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "full_X_train.shape, X_test.shape, full_y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c2c3e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [500, 1000, 3000, 5000, 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f1f2b",
   "metadata": {},
   "source": [
    "#### 2M timetseps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e747fcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 500 starting ...\n",
      "{0: 118, 1: 186, 2: 141, 3: 19, 4: 17, 5: 19}\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\stable_baselines\\deepq\\policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 21069    |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 44618    |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 71491    |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | -0.5     |\n",
      "| steps                   | 104016   |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 28       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 145191   |\n",
      "| success rate            | 0.29     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 188290   |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 230281   |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 271012   |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 1.1      |\n",
      "| steps                   | 311904   |\n",
      "| success rate            | 0.63     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 353165   |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 394299   |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 435471   |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 476414   |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 517277   |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 558285   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 598893   |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 639354   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 680116   |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 721047   |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 762058   |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 802979   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 843761   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 884077   |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 924661   |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 965598   |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1005891  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1046982  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1088386  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1129143  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1170609  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1211802  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | 1.8      |\n",
      "| steps                   | 1253424  |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1294728  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1335885  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1377196  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1418359  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1459574  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1500807  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1542307  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1584327  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 410000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1625575  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 420000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1666593  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 430000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1707013  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 440000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1747842  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 450000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1788830  |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 460000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1829840  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 470000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1869785  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 480000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1910092  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 490000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1950087  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1989695  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "Count: 5000\n",
      "Count: 10000\n",
      "Testing done.....\n",
      "Success rate: 77.91576204950064\n",
      "Average length: 4.27216673903604\n",
      "Average return: 2.4517585757707336\n",
      "Accuracy: 0.9306088580022819\n",
      "F1: 0.6455552559950398\n",
      "ROC-AUC: 0.8173092781852825\n",
      "Train size 1000 starting ...\n",
      "{0: 285, 1: 371, 2: 233, 3: 29, 4: 34, 5: 48}\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 21068    |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 44617    |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 71481    |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 103927   |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 144757   |\n",
      "| success rate            | 0.33     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 1.5      |\n",
      "| steps                   | 190326   |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 233600   |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 273117   |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 312459   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 1.1      |\n",
      "| steps                   | 352679   |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 393196   |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 433268   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 473381   |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 514249   |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 555317   |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 596225   |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 638111   |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 678752   |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 719043   |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 759687   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 798938   |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 841403   |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 882737   |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 923248   |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 962797   |\n",
      "| success rate            | 0.94     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1002514  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | 3.3      |\n",
      "| steps                   | 1041808  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1081296  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 1120959  |\n",
      "| success rate            | 0.93     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | 3.4      |\n",
      "| steps                   | 1159686  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1199212  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1238260  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1277045  |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1315768  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1354924  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 1393324  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 1432321  |\n",
      "| success rate            | 0.94     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1471444  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 1510174  |\n",
      "| success rate            | 0.97     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1548087  |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 410000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1587101  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 420000   |\n",
      "| mean 100 episode reward | 3.5      |\n",
      "| steps                   | 1625910  |\n",
      "| success rate            | 0.92     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 430000   |\n",
      "| mean 100 episode reward | 3.3      |\n",
      "| steps                   | 1664439  |\n",
      "| success rate            | 0.96     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 440000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1703596  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 450000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 1742318  |\n",
      "| success rate            | 0.92     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 460000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1781728  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 470000   |\n",
      "| mean 100 episode reward | 2        |\n",
      "| steps                   | 1820820  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 480000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1859244  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 490000   |\n",
      "| mean 100 episode reward | 3.3      |\n",
      "| steps                   | 1898069  |\n",
      "| success rate            | 0.92     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | 3.3      |\n",
      "| steps                   | 1936448  |\n",
      "| success rate            | 0.92     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 510000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 1975270  |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "Count: 5000\n",
      "Count: 10000\n",
      "Testing done.....\n",
      "Success rate: 91.81068171949632\n",
      "Average length: 3.920885801128962\n",
      "Average return: 3.2297872340425533\n",
      "Accuracy: 0.9806140432241907\n",
      "F1: 0.9734001743598948\n",
      "ROC-AUC: 0.9801961320470983\n",
      "Train size 3000 starting ...\n",
      "{0: 771, 1: 1086, 2: 778, 3: 99, 4: 129, 5: 137}\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 21069    |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 44618    |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 71491    |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 103971   |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 143908   |\n",
      "| success rate            | 0.26     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 188821   |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 232622   |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 275801   |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 1.1      |\n",
      "| steps                   | 317113   |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 357214   |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 397798   |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 438175   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 477964   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 518511   |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 559136   |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 599382   |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 639656   |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 680448   |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 720929   |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 761007   |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 801730   |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 842011   |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 882724   |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 923103   |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 963530   |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1003779  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1044096  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | 2        |\n",
      "| steps                   | 1084450  |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1124731  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1165243  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1205003  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 1244935  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1285098  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1325378  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1365396  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1405629  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1445531  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 1485381  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1525503  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1565983  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 410000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1606253  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 420000   |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 1646922  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 430000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1686947  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 440000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1727269  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 450000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1767151  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 460000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1807401  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 470000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1846976  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 480000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1887874  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 490000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1928342  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1968345  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "Count: 5000\n",
      "Count: 10000\n",
      "Testing done.....\n",
      "Success rate: 83.12635692574902\n",
      "Average length: 4.126704298740773\n",
      "Average return: 2.573947025618758\n",
      "Accuracy: 0.9475351415561275\n",
      "F1: 0.5905137322954467\n",
      "ROC-AUC: 0.780596761550184\n",
      "Train size 5000 starting ...\n",
      "{0: 1330, 1: 1830, 2: 1251, 3: 162, 4: 176, 5: 251}\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 21069    |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 44618    |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 71491    |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 103951   |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 144645   |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 1.8      |\n",
      "| steps                   | 189904   |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 233593   |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 275866   |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 316799   |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 357266   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 398317   |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 438162   |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 478874   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 519262   |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 558446   |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 597370   |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 636730   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 675317   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 714413   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 754119   |\n",
      "| success rate            | 0.92     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 793895   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 834004   |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 872667   |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 911465   |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 951392   |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 989813   |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1028211  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1066824  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | 1.9      |\n",
      "| steps                   | 1105143  |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1143394  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1182101  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1222084  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1260754  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1300522  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 1339211  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1378498  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1416869  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1456057  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1494665  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1533608  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 410000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1572158  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 420000   |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 1610472  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 430000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1648807  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 440000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1687006  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 450000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1725571  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 460000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1763812  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 470000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1802152  |\n",
      "| success rate            | 0.91     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 480000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1840975  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 490000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1879405  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1918312  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 510000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1957853  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 520000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1999046  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "Count: 5000\n",
      "Count: 10000\n",
      "Testing done.....\n",
      "Success rate: 83.35214937038646\n",
      "Average length: 4.155275727312201\n",
      "Average return: 2.6410768562744247\n",
      "Accuracy: 0.945708936841068\n",
      "F1: 0.6381949437337584\n",
      "ROC-AUC: 0.8136503202770123\n",
      "Train size 10000 starting ...\n",
      "{0: 2678, 1: 3709, 2: 2417, 3: 343, 4: 380, 5: 473}\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 21069    |\n",
      "| success rate            | 0.24     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 44618    |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 71491    |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 103826   |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 28       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 144938   |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 191573   |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 233161   |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 273076   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 313465   |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 354128   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 393839   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 432919   |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | 1.4      |\n",
      "| steps                   | 472534   |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 512333   |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 551076   |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 590409   |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 629538   |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 668703   |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 707650   |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 746828   |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 785812   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 824939   |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 864018   |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 903397   |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 943059   |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 983854   |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1022211  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1061235  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1099905  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1139336  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1179128  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1218821  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 1258258  |\n",
      "| success rate            | 0.93     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1298354  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1337345  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1375583  |\n",
      "| success rate            | 0.9      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1414784  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1453375  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1492127  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1530574  |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 410000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1569346  |\n",
      "| success rate            | 0.94     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 420000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1607971  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 430000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1646001  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 440000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1684276  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 450000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1722705  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 460000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 1761184  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 470000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1800082  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 480000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1838829  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 490000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 1877507  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1916314  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 510000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1955112  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 520000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1993966  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "Count: 5000\n",
      "Count: 10000\n",
      "Testing done.....\n",
      "Success rate: 88.51063829787233\n",
      "Average length: 3.895701259227095\n",
      "Average return: 2.7644811115935735\n",
      "Accuracy: 0.9737269513709754\n",
      "F1: 0.7882517194172419\n",
      "ROC-AUC: 0.8816345137577027\n"
     ]
    }
   ],
   "source": [
    "for train_size in train_sizes:\n",
    "    print(f'Train size {train_size} starting ...')\n",
    "    X_train, y_train = sample_train_set(full_X_train, full_y_train, train_size)\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    if len(unique) != 6:\n",
    "        print(f'Unique classes: {len(unique)}')\n",
    "        print(f'Skipping {train_size} because only {len(np.unique(y_train))} classes are in the sample')\n",
    "    else:\n",
    "        counts_dict = dict(zip(unique, counts))\n",
    "        print(counts_dict)\n",
    "        dqn_model = stable_dqn(X_train, y_train, int(1e6), f'train_sizes/{train_size}_2e6')\n",
    "        test_df = evaluate_dqn(dqn_model, X_test, y_test)\n",
    "        y_pred_df, success_df, success_rate = utils.get_success_rate(test_df)\n",
    "        print(f'Success rate: {success_rate}')\n",
    "        \n",
    "        test_df.to_csv('test_dfs/train_sizes/test_df_1e6.csv', index=False)\n",
    "        y_pred_df.to_csv('test_dfs/train_sizes/y_pred_df_1e6.csv', index=False)\n",
    "        success_df.to_csv('test_dfs/train_sizes/success_df_1e6.csv', index=False)\n",
    "        \n",
    "        avg_length, avg_return = utils.get_avg_length_reward(test_df)\n",
    "        print(f'Average length: {avg_length}')\n",
    "        print(f'Average return: {avg_return}')\n",
    "        \n",
    "        acc, f1, roc_auc = utils.test(y_pred_df['y_actual'], y_pred_df['y_pred'])\n",
    "        print(f'Accuracy: {acc}')\n",
    "        print(f'F1: {f1}')\n",
    "        print(f'ROC-AUC: {roc_auc}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c187e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
