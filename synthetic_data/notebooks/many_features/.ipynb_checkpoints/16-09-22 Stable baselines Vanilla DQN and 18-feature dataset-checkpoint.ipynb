{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4842d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "# import torch\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from modules.many_features import utils, constants\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44b2ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "# torch.manual_seed(SEED)\n",
    "# torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73525e8e",
   "metadata": {},
   "source": [
    "#### The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d910eb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>ferritin</th>\n",
       "      <th>ret_count</th>\n",
       "      <th>segmented_neutrophils</th>\n",
       "      <th>tibc</th>\n",
       "      <th>mcv</th>\n",
       "      <th>serum_iron</th>\n",
       "      <th>rbc</th>\n",
       "      <th>gender</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>copper</th>\n",
       "      <th>ethanol</th>\n",
       "      <th>folate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>tsat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.728733</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.170892</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>44.186200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.405752</td>\n",
       "      <td>9.634615</td>\n",
       "      <td>5.659537</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>77.413788</td>\n",
       "      <td>212.671838</td>\n",
       "      <td>4.032519</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887130</td>\n",
       "      <td>96.311597</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>43.218595</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>83.207518</td>\n",
       "      <td>31.217256</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.132737</td>\n",
       "      <td>358.914888</td>\n",
       "      <td>1.842252</td>\n",
       "      <td>3.797487</td>\n",
       "      <td>315.102272</td>\n",
       "      <td>80.500314</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.639507</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>45.398211</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.340169</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.662209</td>\n",
       "      <td>2.441767</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>97.033963</td>\n",
       "      <td>102.079062</td>\n",
       "      <td>3.506041</td>\n",
       "      <td>1</td>\n",
       "      <td>1.020527</td>\n",
       "      <td>127.281715</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20.847013</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>62.210273</td>\n",
       "      <td>34.020508</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.691485</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.337971</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>99.838438</td>\n",
       "      <td>24.119564</td>\n",
       "      <td>2.010694</td>\n",
       "      <td>0</td>\n",
       "      <td>1.957666</td>\n",
       "      <td>34.633063</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.612121</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>112.411298</td>\n",
       "      <td>20.074456</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hemoglobin    ferritin  ret_count  segmented_neutrophils        tibc  \\\n",
       "0   14.728733   -1.000000   3.170892              -1.000000   -1.000000   \n",
       "1   10.405752    9.634615   5.659537              -1.000000   -1.000000   \n",
       "2   15.132737  358.914888   1.842252               3.797487  315.102272   \n",
       "3   11.340169   -1.000000   1.662209               2.441767   -1.000000   \n",
       "4    6.691485   -1.000000   3.337971              -1.000000   -1.000000   \n",
       "\n",
       "         mcv  serum_iron       rbc  gender  creatinine  cholestrol  copper  \\\n",
       "0  -1.000000   -1.000000 -1.000000       1   -1.000000   -1.000000    -1.0   \n",
       "1  77.413788  212.671838  4.032519       0    0.887130   96.311597    -1.0   \n",
       "2  80.500314   -1.000000  5.639507       0   -1.000000   -1.000000    -1.0   \n",
       "3  97.033963  102.079062  3.506041       1    1.020527  127.281715    -1.0   \n",
       "4  99.838438   24.119564  2.010694       0    1.957666   34.633063    -1.0   \n",
       "\n",
       "     ethanol  folate     glucose  hematocrit  tsat  label  \n",
       "0  -1.000000    -1.0   -1.000000   44.186200  -1.0      0  \n",
       "1  43.218595    -1.0   83.207518   31.217256  -1.0      4  \n",
       "2  -1.000000    -1.0   -1.000000   45.398211  -1.0      0  \n",
       "3  20.847013    -1.0   62.210273   34.020508  -1.0      6  \n",
       "4  34.612121    -1.0  112.411298   20.074456  -1.0      5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = pd.read_csv('../../final/data/train_set_basic.csv')\n",
    "train_df = pd.read_csv('../../../anemia_ml4hc/data/train_set_basic.csv')\n",
    "#train_df = pd.read_csv('../../final/data/train_set_noisy_6_missing_3.csv')\n",
    "train_df = train_df.fillna(-1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c7264c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7200\n",
       "6    6501\n",
       "5    6498\n",
       "1    6483\n",
       "2    6454\n",
       "3    6378\n",
       "4    6047\n",
       "7    4839\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f37c949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>ferritin</th>\n",
       "      <th>ret_count</th>\n",
       "      <th>segmented_neutrophils</th>\n",
       "      <th>tibc</th>\n",
       "      <th>mcv</th>\n",
       "      <th>serum_iron</th>\n",
       "      <th>rbc</th>\n",
       "      <th>gender</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>copper</th>\n",
       "      <th>ethanol</th>\n",
       "      <th>folate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>tsat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.116363</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.781573</td>\n",
       "      <td>2.738413</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>95.904198</td>\n",
       "      <td>68.457895</td>\n",
       "      <td>2.226085</td>\n",
       "      <td>0</td>\n",
       "      <td>1.892912</td>\n",
       "      <td>39.808550</td>\n",
       "      <td>110.329197</td>\n",
       "      <td>64.404350</td>\n",
       "      <td>21.654404</td>\n",
       "      <td>73.787009</td>\n",
       "      <td>21.349089</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.125320</td>\n",
       "      <td>92.230003</td>\n",
       "      <td>4.231419</td>\n",
       "      <td>1.188039</td>\n",
       "      <td>143.365567</td>\n",
       "      <td>104.057204</td>\n",
       "      <td>204.747831</td>\n",
       "      <td>2.342554</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652614</td>\n",
       "      <td>13.478089</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>32.705481</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>43.520272</td>\n",
       "      <td>24.375961</td>\n",
       "      <td>142.815207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.309450</td>\n",
       "      <td>38.324563</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>455.077909</td>\n",
       "      <td>76.402602</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.440732</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>33.928350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.763858</td>\n",
       "      <td>253.513394</td>\n",
       "      <td>2.262606</td>\n",
       "      <td>0.551444</td>\n",
       "      <td>453.772884</td>\n",
       "      <td>82.781943</td>\n",
       "      <td>90.101466</td>\n",
       "      <td>4.987993</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853521</td>\n",
       "      <td>104.005514</td>\n",
       "      <td>34.639227</td>\n",
       "      <td>0.963866</td>\n",
       "      <td>22.083012</td>\n",
       "      <td>88.891838</td>\n",
       "      <td>41.291574</td>\n",
       "      <td>19.856071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.464002</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>320.964653</td>\n",
       "      <td>104.287127</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.297819</td>\n",
       "      <td>0</td>\n",
       "      <td>1.163516</td>\n",
       "      <td>121.616315</td>\n",
       "      <td>105.895897</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.337462</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>34.392007</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hemoglobin    ferritin  ret_count  segmented_neutrophils        tibc  \\\n",
       "0    7.116363   -1.000000   3.781573               2.738413   -1.000000   \n",
       "1    8.125320   92.230003   4.231419               1.188039  143.365567   \n",
       "2   11.309450   38.324563  -1.000000              -1.000000  455.077909   \n",
       "3   13.763858  253.513394   2.262606               0.551444  453.772884   \n",
       "4   11.464002   -1.000000  -1.000000              -1.000000  320.964653   \n",
       "\n",
       "          mcv  serum_iron       rbc  gender  creatinine  cholestrol  \\\n",
       "0   95.904198   68.457895  2.226085       0    1.892912   39.808550   \n",
       "1  104.057204  204.747831  2.342554       0    0.652614   13.478089   \n",
       "2   76.402602   -1.000000  4.440732       0   -1.000000   -1.000000   \n",
       "3   82.781943   90.101466  4.987993       0    0.853521  104.005514   \n",
       "4  104.287127   -1.000000  3.297819       0    1.163516  121.616315   \n",
       "\n",
       "       copper    ethanol     folate    glucose  hematocrit        tsat  label  \n",
       "0  110.329197  64.404350  21.654404  73.787009   21.349089   -1.000000      5  \n",
       "1   -1.000000  32.705481  -1.000000  43.520272   24.375961  142.815207      1  \n",
       "2   -1.000000  -1.000000  -1.000000  -1.000000   33.928350   -1.000000      4  \n",
       "3   34.639227   0.963866  22.083012  88.891838   41.291574   19.856071      0  \n",
       "4  105.895897  -1.000000   9.337462  -1.000000   34.392007   -1.000000      7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../../final/data/test_set_constant.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c57275da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50400, 17), (14000, 17), (50400,), (14000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:, 0:-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "\n",
    "X_test = test_df.iloc[:, 0:-1]\n",
    "y_test = test_df.iloc[:, -1]\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3dba7c",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245634f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# timesteps = int(1e6)\n",
    "# dqn_model = utils.stable_dqn(X_train, y_train, timesteps, True, f'../../models/many_features/stable_dqn_{timesteps}')\n",
    "# test_df = utils.evaluate_dqn(dqn_model, X_test, y_test)\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff756ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using just stable baselines (not 3)\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key/home/lmuyama/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning:\n",
      "\n",
      "stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 98       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 26568    |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 97       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 52925    |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 80169    |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 94       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 107727   |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 135341   |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 92       |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 163603   |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 191698   |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 220511   |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 88       |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 249300   |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 278567   |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 308391   |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 338080   |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 368199   |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 399055   |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 429867   |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 460897   |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 491939   |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 522539   |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 73       |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 553601   |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 584798   |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 616494   |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 648442   |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 680275   |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 66       |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 712746   |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 746633   |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 781837   |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 817001   |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 852183   |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 888284   |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 56       |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 923840   |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 54       |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | -0.7     |\n",
      "| steps                   | 959062   |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 994637   |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1030799  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1067023  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 47       |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1103123  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1140587  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1179831  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 42       |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1218799  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1257274  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1292257  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 37       |\n",
      "| episodes                | 410000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1325643  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 420000   |\n",
      "| mean 100 episode reward | -0.8     |\n",
      "| steps                   | 1362472  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 430000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1394096  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 440000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1424415  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 450000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1453966  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 460000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1482861  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 28       |\n",
      "| episodes                | 470000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1513580  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 480000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1544008  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 25       |\n",
      "| episodes                | 490000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1574570  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 23       |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1605311  |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 510000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1634250  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 520000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1664034  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 530000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1693458  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 18       |\n",
      "| episodes                | 540000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1722166  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 550000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1748618  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 15       |\n",
      "| episodes                | 560000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1778098  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 13       |\n",
      "| episodes                | 570000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 1813566  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 580000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1845322  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 590000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1876137  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1902952  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 610000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1929493  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 620000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1962120  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 630000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 1991717  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 640000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2021944  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 650000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2049996  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 660000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2077199  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 670000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2105845  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 680000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2135380  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 690000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2166787  |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2199137  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 710000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2231466  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 720000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2262316  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 730000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2296269  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 740000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2326864  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 750000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2352593  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 760000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2378565  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 770000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2404568  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 780000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2430270  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 790000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2456787  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2484779  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 810000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2513667  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 820000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2541978  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 830000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2569356  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 840000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2595883  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 850000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2622652  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 860000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2649362  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 870000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2676661  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 880000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2703821  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 890000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2729715  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2754848  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 910000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2778253  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 920000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2801660  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 930000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2828796  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 940000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2858035  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 950000   |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 2887019  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 960000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2916015  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 970000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2940394  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 980000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2966903  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 990000   |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 2994236  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3021738  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1010000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3049458  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1020000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3076362  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1030000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3103821  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1040000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3130162  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1050000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3156159  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1060000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3181424  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1070000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3206073  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1080000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3230362  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1090000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3254604  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3280270  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1110000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3305576  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1120000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3330433  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1130000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3355843  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1140000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3381169  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1150000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3407163  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1160000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3433104  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1170000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3459651  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1180000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3485724  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1190000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3511433  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3537371  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1210000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3564518  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1220000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3591328  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1230000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3617799  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1240000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3644186  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1250000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3670221  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1260000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3696426  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1270000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3722749  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1280000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3749994  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1290000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3776923  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3804100  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1310000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3825851  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1320000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3850074  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1330000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3871844  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1340000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3895956  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1350000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3923953  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1360000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3949884  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1370000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3975034  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1380000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 3999970  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1390000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4025246  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4051546  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1410000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4077843  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1420000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4104338  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1430000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4130704  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1440000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4157528  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1450000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4184954  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1460000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4212482  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1470000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4239719  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1480000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4267132  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1490000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4294425  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4321691  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1510000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4349284  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1520000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4376903  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1530000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4404322  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1540000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4431802  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1550000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4458680  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1560000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4485248  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1570000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4512300  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1580000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4539217  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1590000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4566748  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4593959  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1610000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4620305  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1620000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4646572  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1630000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4672932  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1640000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4699033  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1650000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4724772  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1660000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4750481  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1670000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4776247  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1680000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4801794  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1690000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4827223  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4853370  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1710000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 4887334  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1720000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4919097  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1730000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4940658  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1740000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4961491  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1750000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 4987364  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1760000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5015648  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1770000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5042973  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1780000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5071072  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1790000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5099364  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5127572  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1810000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5155717  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1820000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5183764  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1830000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5211943  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1840000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5240360  |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1850000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5268613  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1860000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5293559  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1870000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5319133  |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1880000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5346042  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1890000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5373496  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1900000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5400540  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1910000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5427306  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1920000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5453839  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1930000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5480787  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1940000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5508587  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1950000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5536843  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1960000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5561912  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1970000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5591509  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1980000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5624971  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1990000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5653241  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5682406  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2010000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5710741  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2020000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5737584  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2030000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5764193  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2040000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5791099  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2050000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5819079  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2060000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5847729  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2070000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5875306  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2080000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 5903227  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2090000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5930910  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2100000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5958063  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2110000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 5984796  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2120000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6011255  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2130000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6040504  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2140000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6071388  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2150000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6099050  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2160000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6127396  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2170000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6155695  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2180000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6182375  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2190000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6209459  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2200000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6236734  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2210000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6263990  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2220000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6295370  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2230000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6325570  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2240000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6351907  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2250000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6378280  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2260000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6404968  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2270000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6432178  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2280000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6459894  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2290000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6487192  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2300000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6516341  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2310000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6545645  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2320000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6573057  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2330000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6599755  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2340000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6626798  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2350000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6654040  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2360000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6680982  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2370000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6707859  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2380000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6734951  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2390000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6761689  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2400000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6788261  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2410000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6816252  |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2420000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6843521  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2430000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6870958  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2440000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6898069  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2450000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6925089  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2460000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 6954335  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2470000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 6983262  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2480000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7011676  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2490000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7038856  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2500000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7065606  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2510000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7092266  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2520000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7119616  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2530000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7146779  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2540000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7175538  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2550000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7201816  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2560000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7228095  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2570000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7254430  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2580000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7281220  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2590000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7308378  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2600000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7336266  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2610000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7365154  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2620000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7392023  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2630000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7418543  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2640000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7445800  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2650000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7473402  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2660000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7501383  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2670000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7529469  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2680000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7556933  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2690000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7584639  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2700000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7612160  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2710000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7639553  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2720000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7666012  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2730000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7692658  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2740000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7721082  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2750000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7747824  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2760000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7775723  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2770000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7805765  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2780000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7836497  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2790000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7863234  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2800000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7889755  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2810000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 7915930  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2820000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7940966  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2830000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7967799  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2840000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 7995518  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2850000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8024319  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2860000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8052350  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2870000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8079999  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2880000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8109466  |\n",
      "| success rate            | 0.05     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2890000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8136093  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2900000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8162749  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2910000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8190167  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2920000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8216816  |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2930000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8243611  |\n",
      "| success rate            | 0.07     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2940000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8270174  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2950000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8297051  |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2960000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8323949  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2970000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8350662  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2980000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8378739  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 2990000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8410064  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3000000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8438627  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3010000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8466428  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3020000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8493782  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3030000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8520901  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3040000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8549176  |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3050000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8576797  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3060000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8604232  |\n",
      "| success rate            | 0.04     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3070000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8631463  |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3080000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8657676  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3090000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8683831  |\n",
      "| success rate            | 0.09     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3100000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8709886  |\n",
      "| success rate            | 0.08     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3110000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8735669  |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3120000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8761791  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3130000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8787355  |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3140000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8813588  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3150000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8840251  |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3160000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8868323  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3170000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8895029  |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3180000  |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 8920734  |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 3190000  |\n",
      "| mean 100 episode reward | -1       |\n",
      "| steps                   | 8947272  |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_147668/328616426.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# for steps in [int(2e3)]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     dqn_model = utils.stable_vanilla_dqn(X_train, y_train, steps, True, \n\u001b[0;32m---> 10\u001b[0;31m                                  f'../../../anemia_ml4hc/models/sb/dqn/dqn_{steps}')#,\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#                                  checkpoint_folder = '../../../anemia_ml4hc/models/sb/dueling_double_dqn',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#                                  checkpoint_prefix='dqn_basic')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/RL-Agent-Diagnosis/synthetic_data/modules/many_features/utils.py\u001b[0m in \u001b[0;36mstable_vanilla_dqn\u001b[0;34m(X_train, y_train, timesteps, save, filename, checkpoint_folder, checkpoint_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 double_q=False)\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# checkpoint_callback = CheckpointCallback(save_freq=500000, save_path=checkpoint_folder, name_prefix=checkpoint_prefix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, callback=checkpoint_callback)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{filename}.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, replay_wrapper)\u001b[0m\n\u001b[1;32m    294\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                         _, td_errors = self._train_step(obses_t, actions, rewards, obses_tp1, obses_tp1, dones, weights,\n\u001b[0;32m--> 296\u001b[0;31m                                                         sess=self.sess)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprioritized_replay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sess, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgivens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgivens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stable_baselines_tf2_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for steps in [int(50e6)]:\n",
    "#     dqn_model = utils.stable_dqn(X_train, y_train, steps, True, \n",
    "#                                  f'../../../anemia_ml4hc/models/complete_models/dueling_ddqn_{steps}',\n",
    "#                                  checkpoint_folder = '../../../anemia_ml4hc/models/sb/dueling_double_dqn',\n",
    "#                                  checkpoint_prefix='dddqn_basic')\n",
    "    \n",
    "for steps in [int(20e6)]:\n",
    "# for steps in [int(2e3)]:\n",
    "    dqn_model = utils.stable_vanilla_dqn(X_train, y_train, steps, True, \n",
    "                                 f'../../../anemia_ml4hc/models/sb/dqn/dqn_{steps}')#,\n",
    "#                                  checkpoint_folder = '../../../anemia_ml4hc/models/sb/dueling_double_dqn',\n",
    "#                                  checkpoint_prefix='dqn_basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74c47c",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a3120",
   "metadata": {},
   "source": [
    "#### Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv(f'../../test_dfs/many_features/test_df_2800000.csv', index=False)\n",
    "# success_df.to_csv(f'../../test_dfs/many_features/success_df_2800000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9b20f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
