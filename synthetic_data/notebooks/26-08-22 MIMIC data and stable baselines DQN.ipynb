{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1677aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484dae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tensorflow.set_random_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d5dc7",
   "metadata": {},
   "source": [
    "#### The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a47e0a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32009, 27), (8003, 27), (10004, 27))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv('data/mimic/training_set.csv')\n",
    "val_set = pd.read_csv('data/mimic/validation_set.csv')\n",
    "test_set = pd.read_csv('data/mimic/test_set.csv')\n",
    "train_set.shape, val_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058b4f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_ret_count</th>\n",
       "      <th>mean_ret_count</th>\n",
       "      <th>min_ret_count</th>\n",
       "      <th>max_ferritin</th>\n",
       "      <th>mean_ferritin</th>\n",
       "      <th>min_ferritin</th>\n",
       "      <th>max_hemoglobin</th>\n",
       "      <th>mean_hemoglobin</th>\n",
       "      <th>min_hemoglobin</th>\n",
       "      <th>max_iron</th>\n",
       "      <th>...</th>\n",
       "      <th>min_rbc</th>\n",
       "      <th>max_segmented_neutrophils</th>\n",
       "      <th>mean_segmented_neutrophils</th>\n",
       "      <th>min_segmented_neutrophils</th>\n",
       "      <th>max_tibc</th>\n",
       "      <th>mean_tibc</th>\n",
       "      <th>min_tibc</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>9.68</td>\n",
       "      <td>8.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>9.52</td>\n",
       "      <td>7.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.73</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.83</td>\n",
       "      <td>10.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.97</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.48</td>\n",
       "      <td>8.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.94</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_ret_count  mean_ret_count  min_ret_count  max_ferritin  mean_ferritin  \\\n",
       "0           -1.0            -1.0           -1.0          -1.0           -1.0   \n",
       "1           -1.0            -1.0           -1.0          -1.0           -1.0   \n",
       "2           -1.0            -1.0           -1.0          -1.0           -1.0   \n",
       "3           -1.0            -1.0           -1.0          -1.0           -1.0   \n",
       "4           -1.0            -1.0           -1.0          -1.0           -1.0   \n",
       "\n",
       "   min_ferritin  max_hemoglobin  mean_hemoglobin  min_hemoglobin  max_iron  \\\n",
       "0          -1.0            10.4             9.68             8.4      -1.0   \n",
       "1          -1.0            11.3             9.52             7.8      -1.0   \n",
       "2          -1.0            10.9            10.83            10.8      -1.0   \n",
       "3          -1.0            11.0            11.00            11.0      -1.0   \n",
       "4          -1.0            10.2             9.48             8.8      -1.0   \n",
       "\n",
       "   ...  min_rbc  max_segmented_neutrophils  mean_segmented_neutrophils  \\\n",
       "0  ...     2.57                       -1.0                        -1.0   \n",
       "1  ...     2.73                       -1.0                        -1.0   \n",
       "2  ...     3.51                       -1.0                        -1.0   \n",
       "3  ...     3.97                       -1.0                        -1.0   \n",
       "4  ...     2.94                       -1.0                        -1.0   \n",
       "\n",
       "   min_segmented_neutrophils  max_tibc  mean_tibc  min_tibc   age  gender  \\\n",
       "0                       -1.0      -1.0       -1.0      -1.0  86.0       1   \n",
       "1                       -1.0      -1.0       -1.0      -1.0  76.0       1   \n",
       "2                       -1.0      -1.0       -1.0      -1.0  87.0       1   \n",
       "3                       -1.0      -1.0       -1.0      -1.0  37.0       0   \n",
       "4                       -1.0      -1.0       -1.0      -1.0  68.0       0   \n",
       "\n",
       "   diagnosis  \n",
       "0          2  \n",
       "1          2  \n",
       "2          0  \n",
       "3          0  \n",
       "4          4  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ede352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_nans(df, old_value, new_value):\n",
    "    revised_df = df.replace([old_value], new_value)\n",
    "    return revised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce90d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40012, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_train_set = pd.concat([train_set, val_set], axis=0)\n",
    "entire_train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81f9280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_ret_count</th>\n",
       "      <th>mean_ret_count</th>\n",
       "      <th>min_ret_count</th>\n",
       "      <th>max_ferritin</th>\n",
       "      <th>mean_ferritin</th>\n",
       "      <th>min_ferritin</th>\n",
       "      <th>max_hemoglobin</th>\n",
       "      <th>mean_hemoglobin</th>\n",
       "      <th>min_hemoglobin</th>\n",
       "      <th>max_iron</th>\n",
       "      <th>...</th>\n",
       "      <th>min_rbc</th>\n",
       "      <th>max_segmented_neutrophils</th>\n",
       "      <th>mean_segmented_neutrophils</th>\n",
       "      <th>min_segmented_neutrophils</th>\n",
       "      <th>max_tibc</th>\n",
       "      <th>mean_tibc</th>\n",
       "      <th>min_tibc</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>9.68</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>9.52</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.83</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.48</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_ret_count  mean_ret_count  min_ret_count  max_ferritin  mean_ferritin  \\\n",
       "0            0.0             0.0            0.0           0.0            0.0   \n",
       "1            0.0             0.0            0.0           0.0            0.0   \n",
       "2            0.0             0.0            0.0           0.0            0.0   \n",
       "3            0.0             0.0            0.0           0.0            0.0   \n",
       "4            0.0             0.0            0.0           0.0            0.0   \n",
       "\n",
       "   min_ferritin  max_hemoglobin  mean_hemoglobin  min_hemoglobin  max_iron  \\\n",
       "0           0.0            10.4             9.68             8.4       0.0   \n",
       "1           0.0            11.3             9.52             7.8       0.0   \n",
       "2           0.0            10.9            10.83            10.8       0.0   \n",
       "3           0.0            11.0            11.00            11.0       0.0   \n",
       "4           0.0            10.2             9.48             8.8       0.0   \n",
       "\n",
       "   ...  min_rbc  max_segmented_neutrophils  mean_segmented_neutrophils  \\\n",
       "0  ...     2.57                        0.0                         0.0   \n",
       "1  ...     2.73                        0.0                         0.0   \n",
       "2  ...     3.51                        0.0                         0.0   \n",
       "3  ...     3.97                        0.0                         0.0   \n",
       "4  ...     2.94                        0.0                         0.0   \n",
       "\n",
       "   min_segmented_neutrophils  max_tibc  mean_tibc  min_tibc   age  gender  \\\n",
       "0                        0.0       0.0        0.0       0.0  86.0       1   \n",
       "1                        0.0       0.0        0.0       0.0  76.0       1   \n",
       "2                        0.0       0.0        0.0       0.0  87.0       1   \n",
       "3                        0.0       0.0        0.0       0.0  37.0       0   \n",
       "4                        0.0       0.0        0.0       0.0  68.0       0   \n",
       "\n",
       "   diagnosis  \n",
       "0          2  \n",
       "1          2  \n",
       "2          0  \n",
       "3          0  \n",
       "4          4  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_train_set = replace_with_nans(entire_train_set, -1, 0)\n",
    "test_set = replace_with_nans(test_set, -1, 0)\n",
    "entire_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ebf7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'Iron deficiency anemia': 0,\n",
    "              'Vitamin B12/Folate deficiency anemia': 1,\n",
    "              'Hemolytic anemia': 2,\n",
    "              'Aplastic anemia': 3,\n",
    "              'Anemia of chronic disease': 4,\n",
    "              'No anemia': 5\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74fcbed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40012, 26), (40012,), (10004, 26), (10004,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = entire_train_set.iloc[:, 0:-1]\n",
    "y_train = entire_train_set.iloc[:, -1]\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_test = test_set.iloc[:, 0:-1]\n",
    "y_test = test_set.iloc[:, -1]\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4901dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list = list(class_dict.keys()) + [col  for col in entire_train_set.columns if col!='diagnosis']\n",
    "len(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe6dbefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iron deficiency anemia',\n",
       " 'Vitamin B12/Folate deficiency anemia',\n",
       " 'Hemolytic anemia',\n",
       " 'Aplastic anemia',\n",
       " 'Anemia of chronic disease',\n",
       " 'No anemia',\n",
       " 'max_ret_count',\n",
       " 'mean_ret_count',\n",
       " 'min_ret_count',\n",
       " 'max_ferritin',\n",
       " 'mean_ferritin',\n",
       " 'min_ferritin',\n",
       " 'max_hemoglobin',\n",
       " 'mean_hemoglobin',\n",
       " 'min_hemoglobin',\n",
       " 'max_iron',\n",
       " 'mean_iron',\n",
       " 'min_iron',\n",
       " 'max_mcv',\n",
       " 'mean_mcv',\n",
       " 'min_mcv',\n",
       " 'max_rbc',\n",
       " 'mean_rbc',\n",
       " 'min_rbc',\n",
       " 'max_segmented_neutrophils',\n",
       " 'mean_segmented_neutrophils',\n",
       " 'min_segmented_neutrophils',\n",
       " 'max_tibc',\n",
       " 'mean_tibc',\n",
       " 'min_tibc',\n",
       " 'age',\n",
       " 'gender']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16438584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  , 10.4 ,  9.68,  8.4 ,\n",
       "          0.  ,  0.  ,  0.  , 99.  , 97.  , 96.  ,  3.22,  3.01,  2.57,\n",
       "          0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  , 86.  ,  1.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  , 11.3 ,  9.52,  7.8 ,\n",
       "          0.  ,  0.  ,  0.  , 90.  , 86.74, 80.  ,  4.21,  3.35,  2.73,\n",
       "          0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  , 76.  ,  1.  ]]),\n",
       " array([[0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         9.400e+00, 9.300e+00, 9.200e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         8.900e+01, 8.850e+01, 8.800e+01, 3.150e+00, 3.140e+00, 3.140e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         8.500e+01, 1.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 1.008e+03, 1.008e+03, 1.008e+03,\n",
       "         1.140e+01, 8.440e+00, 6.700e+00, 2.300e+01, 2.300e+01, 2.300e+01,\n",
       "         8.800e+01, 8.234e+01, 7.800e+01, 4.560e+00, 3.360e+00, 2.600e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 1.640e+02, 1.640e+02, 1.640e+02,\n",
       "         4.200e+01, 1.000e+00]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2], X_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714feb3d",
   "metadata": {},
   "source": [
    "#### The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f836162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs import MimicEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fe115",
   "metadata": {},
   "source": [
    "#### The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcdf434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines import bench, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7da20e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\stable_baselines\\deepq\\policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 52343    |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 1.8      |\n",
      "| steps                   | 109726   |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 1.6      |\n",
      "| steps                   | 173719   |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 1.1      |\n",
      "| steps                   | 246655   |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | -0.4     |\n",
      "| steps                   | 332155   |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | -5.8     |\n",
      "| steps                   | 437495   |\n",
      "| success rate            | 0.06     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | -8.7     |\n",
      "| steps                   | 568964   |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | -9.8     |\n",
      "| steps                   | 705516   |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | -6.2     |\n",
      "| steps                   | 841254   |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | -7.7     |\n",
      "| steps                   | 977281   |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | -8       |\n",
      "| steps                   | 1113557  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | -7.4     |\n",
      "| steps                   | 1249743  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | -7.4     |\n",
      "| steps                   | 1386354  |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | -8.2     |\n",
      "| steps                   | 1522708  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | -8.1     |\n",
      "| steps                   | 1659515  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | -8.7     |\n",
      "| steps                   | 1795863  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | -8.1     |\n",
      "| steps                   | 1932217  |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | -7.8     |\n",
      "| steps                   | 2068791  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | -8.9     |\n",
      "| steps                   | 2205001  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | -10.4    |\n",
      "| steps                   | 2341841  |\n",
      "| success rate            | 0.03     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | -8.9     |\n",
      "| steps                   | 2478533  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | -9.6     |\n",
      "| steps                   | 2614720  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | -9.4     |\n",
      "| steps                   | 2750154  |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | -9.2     |\n",
      "| steps                   | 2886423  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | -9.1     |\n",
      "| steps                   | 3023001  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | -8.8     |\n",
      "| steps                   | 3159265  |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | -8.7     |\n",
      "| steps                   | 3296157  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | -9       |\n",
      "| steps                   | 3432384  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | -8.7     |\n",
      "| steps                   | 3566481  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | -8.4     |\n",
      "| steps                   | 3702099  |\n",
      "| success rate            | 0.02     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | -9.2     |\n",
      "| steps                   | 3838321  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | -8.6     |\n",
      "| steps                   | 3974750  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | -9.3     |\n",
      "| steps                   | 4111163  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | -8.4     |\n",
      "| steps                   | 4246878  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | -8.1     |\n",
      "| steps                   | 4383382  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | -8.6     |\n",
      "| steps                   | 4515741  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | -7.8     |\n",
      "| steps                   | 4652323  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | -8.1     |\n",
      "| steps                   | 4786413  |\n",
      "| success rate            | 0        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | -9.1     |\n",
      "| steps                   | 4918882  |\n",
      "| success rate            | 0.01     |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def stable_dqn():\n",
    "    training_env = MimicEnv(X_train, y_train)\n",
    "    env = bench.Monitor(training_env, logger.get_dir())\n",
    "    model = DQN('MlpPolicy', training_env, verbose=1, seed=SEED, n_cpu_tf_sess=1)\n",
    "    model.learn(total_timesteps=int(5e6), log_interval=10000)\n",
    "    #model.learn(total_timesteps=int(1.2e5), log_interval=10000)\n",
    "    #model.save('models/synthetic_stable_dqn_1.8.pkl')\n",
    "    model.save('models/mimic/dqn_5e6.pkl')\n",
    "    env.close()\n",
    "    return model\n",
    "\n",
    "dqn_model = stable_dqn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e1a11",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a6322eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dqn_model = DQN.load('models/synthentic_with_hb_some_nans_stable_dqn2e6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e0418bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c64b2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass(actual_class, pred_class, average = 'macro'):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    avg = sum(roc_auc_dict.values()) / len(roc_auc_dict)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18f408d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ytest, ypred):\n",
    "    acc = accuracy_score(ytest, ypred)\n",
    "    f1 = f1_score(ytest, ypred, average ='macro', labels=np.unique(ytest))\n",
    "    try:\n",
    "        roc_auc = multiclass(ytest, ypred)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    return acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a95c5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_length_reward(df):\n",
    "    length = np.mean(df.episode_length)\n",
    "    reward = np.mean(df.reward)\n",
    "    return length, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5140150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 5000\n",
      "Count: 10000\n",
      "Testing done.....\n"
     ]
    }
   ],
   "source": [
    "def synthetic_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    env = MimicEnv(X_test, y_test, random=False)\n",
    "    #env = SyntheticComplexHbEnv(X_train, y_train, random=False)\n",
    "    count=0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            count+=1\n",
    "            if count%5000==0:\n",
    "                print(f'Count: {count}')\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                action, _states = dqn_model.predict(obs, deterministic=True)\n",
    "                obs, rew, done,info = env.step(action)\n",
    "                #if (done==True) & (np.isfinite(info['y_pred'])):\n",
    "                if done == True:\n",
    "                    test_df = test_df.append(info, ignore_index=True)\n",
    "                #print('....................TEST DF ....................')\n",
    "                #if len(test_df) != 0:\n",
    "                #    print(test_df.head())\n",
    "\n",
    "    except StopIteration:\n",
    "        print('Testing done.....')\n",
    "    return test_df\n",
    "\n",
    "test_df = synthetic_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dafb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40012, 40012)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c20c4695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 10004)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78ccf0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = test_df[test_df['y_pred'].notna()]\n",
    "success_df = y_pred_df[y_pred_df['y_pred']== y_pred_df['y_actual']]\n",
    "len(success_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41dccb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv('test_dfs/train_test_df_with_hb_some_nans_2e6.csv', index=False)\n",
    "# y_pred_df.to_csv('test_dfs/train_y_pred_df_with_hb_some_nans_2e6.csv', index=False)\n",
    "# success_df.to_csv('test_dfs/train_success_df_with_hb_some_nans_2e6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a059464e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.y_pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7b94d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: y_pred, dtype: int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d824df37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: y_actual, dtype: int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.y_actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae641e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_rate = len(success_df)/len(test_df)*100\n",
    "success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "860cb1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.0, -11.365053978408637)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#avg length and return \n",
    "avg_length, avg_return = get_avg_length_reward(test_df)\n",
    "avg_length, avg_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e885cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nan, nan, None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, f1, roc_auc = test(y_pred_df['y_actual'], y_pred_df['y_pred'])\n",
    "acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f03ed",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7981d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, save=False, filename=False):\n",
    "    cm_df = pd.DataFrame(cm, index = [0, 1, 2, 3, 4, 5], columns = [0, 1, 2, 3, 4, 5])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Anemia')\n",
    "    plt.xlabel('Predicted Anemia')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_pred_df['y_actual'], y_pred_df['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539cbabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    inch = 2.54\n",
    "    if type(tupl[0]) == tuple:\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56198e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values(pc, fmt=\"%.2f\", **kw):    \n",
    "    pc.update_scalarmappable()\n",
    "    ax = pc.axes\n",
    "    for p, color, value in zip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.all(color[:3] > 0.5):\n",
    "            color = (0.0, 0.0, 0.0)\n",
    "        else:\n",
    "            color = (1.0, 1.0, 1.0)\n",
    "        ax.text(x, y, fmt % value, ha=\"center\", va=\"center\", color=color, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0264db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(AUC, title, xlabel, ylabel, xticklabels, yticklabels, figure_width=40, figure_height=20, correct_orientation=False, cmap='RdBu'):\n",
    "    fig, ax = plt.subplots()    \n",
    "    c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap=cmap)\n",
    "    ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_xticklabels(xticklabels, minor=False)\n",
    "    ax.set_yticklabels(yticklabels, minor=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)      \n",
    "\n",
    "    # Remove last blank column\n",
    "    plt.xlim( (0, AUC.shape[1]) )\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()    \n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    # Add color bar\n",
    "    plt.colorbar(c)\n",
    "\n",
    "    # Add text in each cell \n",
    "    show_values(c)\n",
    "\n",
    "    # Proper orientation (origin at the top left instead of bottom left)\n",
    "    if correct_orientation:\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.tick_top()       \n",
    "\n",
    "    # resize \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(cm2inch(figure_width, figure_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb007fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(classification_report, save=False, filename=False, cmap='RdBu'):\n",
    "    lines = classification_report.split('\\n')\n",
    "    class_names = list(class_dict.keys())\n",
    "    plotMat = []\n",
    "    support = []\n",
    "    #class_names = []\n",
    "    #count = 0\n",
    "    for line in lines[2 : (len(lines) - 5)]:\n",
    "        t = line.strip().split()\n",
    "        if len(t) < 2: continue\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        support.append(int(t[-1]))\n",
    "        plotMat.append(v)\n",
    "\n",
    "    xlabel = 'Metrics'\n",
    "    ylabel = 'Classes'\n",
    "    xticklabels = ['Precision', 'Recall', 'F1-score']\n",
    "    ytick_labels = [f'{class_names[i]}({sup})' for i, sup in enumerate(support) ]\n",
    "    \n",
    "    #print(len(support))\n",
    "    yticklabels = ['{0} ({1})'.format(class_names[idx], sup) for idx, sup  in enumerate(support)]\n",
    "    figure_width = 25\n",
    "    figure_height = len(class_names) + 7\n",
    "    correct_orientation = False\n",
    "    heatmap(np.array(plotMat), 'classification report', xlabel, ylabel, xticklabels, yticklabels, figure_width, figure_height, correct_orientation, cmap=cmap)\n",
    "    #plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(filename, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_pred_df['y_actual'], y_pred_df['y_pred'])\n",
    "plot_classification_report(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c8627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
