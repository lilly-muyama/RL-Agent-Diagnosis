{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1677aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484dae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tensorflow.set_random_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d5dc7",
   "metadata": {},
   "source": [
    "#### The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3296e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hemolytic anemia': 0,\n",
       " 'Anemia of chronic disease': 1,\n",
       " 'No anemia': 2,\n",
       " 'Aplastic anemia': 3,\n",
       " 'Vitamin B12/Folate deficiency anemia': 4,\n",
       " 'Iron deficiency anemia': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('data/anemia_synth_dataset_hb_some_nans.csv') #my real dataset i think\n",
    "#df = pd.read_csv('data/anemia_synth_dataset_hb.csv')\n",
    "df = pd.read_csv('data/noisy_data_uniform_all_30_08_22.csv')\n",
    "df = df.fillna(0)\n",
    "classes = list(df.label.unique())\n",
    "nums = [i for i in range(len(classes))]\n",
    "class_dict = dict(zip(classes, nums))\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cde9b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 6), (18000, 6), (42000,), (18000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].replace(class_dict)\n",
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4901dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list = list(class_dict.keys()) + [col  for col in df.columns if col!='label']\n",
    "len(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6dbefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hemolytic anemia',\n",
       " 'Anemia of chronic disease',\n",
       " 'No anemia',\n",
       " 'Aplastic anemia',\n",
       " 'Vitamin B12/Folate deficiency anemia',\n",
       " 'Iron deficiency anemia',\n",
       " 'hemoglobin',\n",
       " 'ferritin',\n",
       " 'ret_count',\n",
       " 'segmented_neutrophils',\n",
       " 'tibc',\n",
       " 'mcv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16438584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1.87583201, 343.18430633,   4.98410354,   0.        ,\n",
       "           0.        ,  87.18608967],\n",
       "        [  1.57074342,   0.        ,   3.37668014,   2.06695952,\n",
       "           0.        ,  94.71994026]]),\n",
       " array([[  6.24850792,   0.        ,   0.5241004 ,   0.        ,\n",
       "         373.64490188,  98.79429654],\n",
       "        [  7.62067707, 127.79573525,   0.        ,   1.74847797,\n",
       "          82.66968799,  77.72260827]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2], X_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714feb3d",
   "metadata": {},
   "source": [
    "#### The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f836162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs import SyntheticComplexHbEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fe115",
   "metadata": {},
   "source": [
    "#### The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcdf434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\stable_baselines\\__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines import bench, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da20e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\stable_baselines\\deepq\\policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 94       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 20514    |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 42112    |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 64706    |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 77       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 88850    |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 114974   |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 143248   |\n",
      "| success rate            | 0.13     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 56       |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 174598   |\n",
      "| success rate            | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 47       |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 209195   |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 37       |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | -0       |\n",
      "| steps                   | 248778   |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 292373   |\n",
      "| success rate            | 0.28     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 338295   |\n",
      "| success rate            | 0.34     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 4        |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | 1.7      |\n",
      "| steps                   | 380392   |\n",
      "| success rate            | 0.41     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 414250   |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | 2        |\n",
      "| steps                   | 450093   |\n",
      "| success rate            | 0.48     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 484934   |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 520049   |\n",
      "| success rate            | 0.49     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 555484   |\n",
      "| success rate            | 0.57     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 590398   |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 625830   |\n",
      "| success rate            | 0.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 662452   |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 704136   |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | 1.8      |\n",
      "| steps                   | 747137   |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 789723   |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 831734   |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 873722   |\n",
      "| success rate            | 0.59     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 915147   |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 957748   |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1000073  |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1041452  |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1083477  |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1125737  |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1167709  |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1210076  |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1251501  |\n",
      "| success rate            | 0.62     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1292874  |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | 3.4      |\n",
      "| steps                   | 1333873  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1374749  |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1415707  |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1456595  |\n",
      "| success rate            | 0.66     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 1497424  |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 410000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1537903  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 420000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 1578727  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 430000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1619337  |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 440000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1659938  |\n",
      "| success rate            | 0.55     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 450000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1700724  |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 460000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1741896  |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 470000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1782639  |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 480000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1823966  |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 490000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 1865698  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1906738  |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 510000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1948673  |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 520000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 1989809  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 530000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 2031479  |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 540000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 2072646  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 550000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 2113077  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 560000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 2154022  |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 570000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 2194931  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 580000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 2235602  |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 590000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 2276465  |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 2317425  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 610000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 2359085  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 620000   |\n",
      "| mean 100 episode reward | 3.3      |\n",
      "| steps                   | 2399968  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 630000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 2441247  |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 640000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 2482444  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 650000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 2523695  |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 660000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 2565360  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 670000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 2606945  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 680000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 2649081  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 690000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 2690632  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 2733083  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 710000   |\n",
      "| mean 100 episode reward | 1.8      |\n",
      "| steps                   | 2775115  |\n",
      "| success rate            | 0.54     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 720000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 2817497  |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 730000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 2859808  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 740000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 2901563  |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 750000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 2943570  |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 760000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 2985621  |\n",
      "| success rate            | 0.64     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 770000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 3027881  |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 780000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 3069654  |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 790000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 3112607  |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 3154797  |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 810000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 3198043  |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 820000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 3240466  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 830000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 3282104  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 840000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 3324278  |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 850000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 3366297  |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 860000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 3408724  |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 870000   |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 3451355  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 880000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 3493688  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 890000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 3535952  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | 3.2      |\n",
      "| steps                   | 3578957  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 910000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 3620739  |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 920000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 3663006  |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 930000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 3705166  |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 940000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 3746835  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 950000   |\n",
      "| mean 100 episode reward | 3.3      |\n",
      "| steps                   | 3789015  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 960000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 3831026  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 970000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 3873375  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def stable_dqn():\n",
    "    training_env = SyntheticComplexHbEnv(X_train, y_train)\n",
    "    env = bench.Monitor(training_env, logger.get_dir())\n",
    "    model = DQN('MlpPolicy', training_env, verbose=1, seed=SEED, n_cpu_tf_sess=1)\n",
    "    model.learn(total_timesteps=int(4.1e6), log_interval=10000)\n",
    "    #model.learn(total_timesteps=int(1.2e5), log_interval=10000)\n",
    "    #model.save('models/synthetic_stable_dqn_1.8.pkl')\n",
    "    model.save('models/noisy/dqn_uniform_all_41e6.pkl')\n",
    "    env.close()\n",
    "    return model\n",
    "\n",
    "dqn_model = stable_dqn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e1a11",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a6322eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dqn_model = DQN.load('models/noisy/dqn_uniform_all_4e6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0418bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c64b2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass(actual_class, pred_class, average = 'macro'):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    avg = sum(roc_auc_dict.values()) / len(roc_auc_dict)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f408d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ytest, ypred):\n",
    "    acc = accuracy_score(ytest, ypred)\n",
    "    f1 = f1_score(ytest, ypred, average ='macro', labels=np.unique(ytest))\n",
    "    try:\n",
    "        roc_auc = multiclass(ytest, ypred)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    return acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a95c5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_length_reward(df):\n",
    "    length = np.mean(df.episode_length)\n",
    "    reward = np.mean(df.reward)\n",
    "    return length, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5140150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 5000\n",
      "Count: 10000\n",
      "Count: 15000\n",
      "Testing done.....\n"
     ]
    }
   ],
   "source": [
    "def synthetic_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    env = SyntheticComplexHbEnv(X_test, y_test, random=False)\n",
    "    #env = SyntheticComplexHbEnv(X_train, y_train, random=False)\n",
    "    count=0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            count+=1\n",
    "            if count%5000==0:\n",
    "                print(f'Count: {count}')\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                action, _states = dqn_model.predict(obs, deterministic=True)\n",
    "                obs, rew, done,info = env.step(action)\n",
    "                #if (done==True) & (np.isfinite(info['y_pred'])):\n",
    "                if done == True:\n",
    "                    test_df = test_df.append(info, ignore_index=True)\n",
    "                #print('....................TEST DF ....................')\n",
    "                #if len(test_df) != 0:\n",
    "                #    print(test_df.head())\n",
    "\n",
    "    except StopIteration:\n",
    "        print('Testing done.....')\n",
    "    return test_df\n",
    "\n",
    "test_df = synthetic_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c20c4695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 18000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78ccf0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14707"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = test_df[test_df['y_pred'].notna()]\n",
    "success_df = y_pred_df[y_pred_df['y_pred']== y_pred_df['y_actual']]\n",
    "len(success_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41dccb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv('test_dfs/noisy/final_test_df_4e6.csv', index=False)\n",
    "# y_pred_df.to_csv('test_dfs/noisy/final_y_pred_df_4e6.csv', index=False)\n",
    "# success_df.to_csv('test_dfs/noisy/final_success_df_4e6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a059464e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 3., 2., 4.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.y_pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7b94d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    6768\n",
       "3.0    3162\n",
       "2.0    3144\n",
       "1.0    2430\n",
       "4.0     476\n",
       "Name: y_pred, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d824df37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    6621\n",
       "3.0    3161\n",
       "2.0    2971\n",
       "1.0    2331\n",
       "4.0     788\n",
       "5.0     108\n",
       "Name: y_actual, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.y_actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae641e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.70555555555555"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_rate = len(success_df)/len(test_df)*100\n",
    "success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "860cb1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.359111111111111, 3.1145555555555555)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#avg length and return \n",
    "avg_length, avg_return = get_avg_length_reward(test_df)\n",
    "avg_length, avg_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e885cbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9203379224030037, 0.7010800996693796, 0.8395336148701881)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, f1, roc_auc = test(y_pred_df['y_actual'], y_pred_df['y_pred'])\n",
    "acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f03ed",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7981d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, save=False, filename=False):\n",
    "    cm_df = pd.DataFrame(cm, index = [0, 1, 2, 3, 4, 5], columns = [0, 1, 2, 3, 4, 5])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Anemia')\n",
    "    plt.xlabel('Predicted Anemia')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_pred_df['y_actual'], y_pred_df['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539cbabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    inch = 2.54\n",
    "    if type(tupl[0]) == tuple:\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56198e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values(pc, fmt=\"%.2f\", **kw):    \n",
    "    pc.update_scalarmappable()\n",
    "    ax = pc.axes\n",
    "    for p, color, value in zip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.all(color[:3] > 0.5):\n",
    "            color = (0.0, 0.0, 0.0)\n",
    "        else:\n",
    "            color = (1.0, 1.0, 1.0)\n",
    "        ax.text(x, y, fmt % value, ha=\"center\", va=\"center\", color=color, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0264db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(AUC, title, xlabel, ylabel, xticklabels, yticklabels, figure_width=40, figure_height=20, correct_orientation=False, cmap='RdBu'):\n",
    "    fig, ax = plt.subplots()    \n",
    "    c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap=cmap)\n",
    "    ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_xticklabels(xticklabels, minor=False)\n",
    "    ax.set_yticklabels(yticklabels, minor=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)      \n",
    "\n",
    "    # Remove last blank column\n",
    "    plt.xlim( (0, AUC.shape[1]) )\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()    \n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    # Add color bar\n",
    "    plt.colorbar(c)\n",
    "\n",
    "    # Add text in each cell \n",
    "    show_values(c)\n",
    "\n",
    "    # Proper orientation (origin at the top left instead of bottom left)\n",
    "    if correct_orientation:\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.tick_top()       \n",
    "\n",
    "    # resize \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(cm2inch(figure_width, figure_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb007fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(classification_report, save=False, filename=False, cmap='RdBu'):\n",
    "    lines = classification_report.split('\\n')\n",
    "    class_names = list(class_dict.keys())\n",
    "    plotMat = []\n",
    "    support = []\n",
    "    #class_names = []\n",
    "    #count = 0\n",
    "    for line in lines[2 : (len(lines) - 5)]:\n",
    "        t = line.strip().split()\n",
    "        if len(t) < 2: continue\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        support.append(int(t[-1]))\n",
    "        plotMat.append(v)\n",
    "\n",
    "    xlabel = 'Metrics'\n",
    "    ylabel = 'Classes'\n",
    "    xticklabels = ['Precision', 'Recall', 'F1-score']\n",
    "    ytick_labels = [f'{class_names[i]}({sup})' for i, sup in enumerate(support) ]\n",
    "    \n",
    "    #print(len(support))\n",
    "    yticklabels = ['{0} ({1})'.format(class_names[idx], sup) for idx, sup  in enumerate(support)]\n",
    "    figure_width = 25\n",
    "    figure_height = len(class_names) + 7\n",
    "    correct_orientation = False\n",
    "    heatmap(np.array(plotMat), 'classification report', xlabel, ylabel, xticklabels, yticklabels, figure_width, figure_height, correct_orientation, cmap=cmap)\n",
    "    #plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(filename, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_pred_df['y_actual'], y_pred_df['y_pred'])\n",
    "plot_classification_report(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c8627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
