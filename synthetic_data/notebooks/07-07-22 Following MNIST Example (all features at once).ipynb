{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c151694e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "#import keras\n",
    "#from keras import layers\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, auc, roc_curve\n",
    "import tensorflow as tf\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fc0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.ppo2 import ppo2\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "from baselines import bench\n",
    "from baselines import logger\n",
    "from baselines import deepq\n",
    "from baselines.common.tf_util import make_session\n",
    "from baselines.common import set_global_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51113337",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "#tf.random.set_seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b3b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass(actual_class, pred_class, average = 'macro'):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    avg = sum(roc_auc_dict.values()) / len(roc_auc_dict)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1220488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ytest, ypred):\n",
    "    acc = accuracy_score(ytest, ypred)\n",
    "    f1 = f1_score(ytest, ypred, average ='macro', labels=np.unique(ytest))\n",
    "    try:\n",
    "        roc_auc = multiclass(ytest, ypred)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    return acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b9299",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09901a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "input_shape = (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f514c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data with random zeros\n",
    "X_train = np.loadtxt('data/zeros/X_train.txt', dtype=np.float32)\n",
    "#X_val = np.loadtxt('data/zeros/X_val.txt', dtype=np.float32)\n",
    "X_test = np.loadtxt('data/zeros/X_test.txt', dtype=np.float32)\n",
    "\n",
    "y_train = np.loadtxt('data/zeros/y_train.txt', dtype=int)\n",
    "#y_val = np.loadtxt('data/zeros/y_val.txt', dtype=int)\n",
    "y_test = np.loadtxt('data/zeros/y_test.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be539b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original synthetic dataset\n",
    "# df = pd.read_csv('data/dataset_10000.csv')\n",
    "# class_dict = {'A':0, 'B':1, 'C':2}\n",
    "# df['label'] = df['label'].replace(class_dict)\n",
    "# X = df.iloc[:, 0:-1]\n",
    "# y = df.iloc[:, -1]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# #X_val = scaler.transform(X_val)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "# #X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "# X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6481e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7000, 3)\n",
      "7000 train samples\n",
      "3000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Make sure images have shape (28, 28, 1)\n",
    "#x_train = np.expand_dims(x_train, -1)\n",
    "#x_train = np.reshape(-1,3)\n",
    "#x_test = np.expand_dims(x_test, -1)\n",
    "x_train, x_test = X_train, X_test\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7617b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47253b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1,\n",
    "                                                shape=(3,),\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        info = {}\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "            info = {'y_pred':action, 'y_actual':self.expected_action}\n",
    "        if not self.random:\n",
    "            self.dataset_idx+=1\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    \n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            #print('choosing randomly')\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y[next_obs_idx])\n",
    "            obs = self.x[next_obs_idx]\n",
    "\n",
    "        else:\n",
    "            #self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "            #print('choosing sequentially')\n",
    "            obs = self.x[self.dataset_idx]\n",
    "            self.expected_action = int(self.y[self.dataset_idx])\n",
    "\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dad3a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/synthetic_dqn\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\models.py:94: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 99       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 98       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 98       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 198      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 97       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 298      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 398      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 498      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 598      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 94       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 698      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 798      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 92       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 898      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 91       |\n",
      "| episodes                | 1e+03    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 998      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1.1e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1.2e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 1.3e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 88       |\n",
      "| episodes                | 1.4e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 87       |\n",
      "| episodes                | 1.5e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 1.6e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 1.7e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 1.8e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 84       |\n",
      "| episodes                | 1.9e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 2e+03    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 2e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 2.1e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2.2e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2.3e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2.4e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 2.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 2.5e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 2.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 2.6e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 77       |\n",
      "| episodes                | 2.7e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 2.8e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 2.9e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 3e+03    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 74       |\n",
      "| episodes                | 3.1e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 73       |\n",
      "| episodes                | 3.2e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 3.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3.3e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3.4e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 3.4e+03  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3.5e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3.6e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 3.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 3.7e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 3.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 68       |\n",
      "| episodes                | 3.8e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 3.9e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 4e+03    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 4e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 66       |\n",
      "| episodes                | 4.1e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 4.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 4.2e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 4.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 4.3e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4.4e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 4.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4.5e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 4.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4.6e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4.7e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4.8e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 4.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 4.9e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 4.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 5e+03    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 5.1e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 5.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 5.2e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 5.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 56       |\n",
      "| episodes                | 5.3e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 5.4e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 54       |\n",
      "| episodes                | 5.5e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 5.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5.6e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5.7e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 5.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5.8e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5.9e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 5.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 6e+03    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 6.1e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 6.2e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 6.3e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 6.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 47       |\n",
      "| episodes                | 6.4e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 6.5e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 6.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 6.6e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 6.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6.7e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 6.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6.8e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6.9e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 42       |\n",
      "| episodes                | 7e+03    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 7e+03    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 7.1e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 7.2e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 39       |\n",
      "| episodes                | 7.3e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 7.4e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 7.5e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 7.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 37       |\n",
      "| episodes                | 7.6e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 7.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 36       |\n",
      "| episodes                | 7.7e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 7.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7.8e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 7.9e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 7.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 8e+03    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 8.1e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 8.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 8.2e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 8.3e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 8.4e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 8.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 8.5e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 8.6e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 28       |\n",
      "| episodes                | 8.7e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 8.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 8.8e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8.9e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 8.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 25       |\n",
      "| episodes                | 9e+03    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 9.1e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 9.2e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 23       |\n",
      "| episodes                | 9.3e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 9.4e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 21       |\n",
      "| episodes                | 9.5e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 9.6e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 9.7e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 9.8e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 18       |\n",
      "| episodes                | 9.9e+03  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 1e+04    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 1.01e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 15       |\n",
      "| episodes                | 1.02e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 15       |\n",
      "| episodes                | 1.03e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 1.04e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 13       |\n",
      "| episodes                | 1.05e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 1.06e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.06e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 11       |\n",
      "| episodes                | 1.07e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 1.08e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 1.09e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 1.1e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 1.11e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 1.12e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 1.13e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1.14e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1.15e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 4        |\n",
      "| episodes                | 1.16e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 1.17e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1.18e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.21e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.22e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.23e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.24e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.25e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.26e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.27e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.28e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.29e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.3e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.31e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.32e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.33e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.34e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.35e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.36e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.37e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.38e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.39e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.4e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.41e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.42e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.42e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.43e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.44e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.45e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.46e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.47e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.48e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.49e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.5e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.51e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.52e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.53e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.54e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.55e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.56e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.57e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.58e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.59e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.6e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.61e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.62e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.63e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.64e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.65e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.66e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.67e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.68e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.69e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.7e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.71e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.72e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.73e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.74e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.75e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.76e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.77e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.78e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.78e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.79e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.8e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.81e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.82e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.83e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.84e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.85e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.86e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.87e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.88e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.89e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.9e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.91e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.92e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.93e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.94e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.95e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.96e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.97e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.98e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.99e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2e+04    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2e+04    |\n",
      "--------------------------------------\n",
      "Saving model due to mean reward increase: None -> 0.5\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.01e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.02e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.03e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.04e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.05e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.06e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.07e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.08e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.09e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.1e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.11e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.12e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.13e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.13e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.14e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.15e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 2.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.16e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.17e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.18e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.19e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.2e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.21e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.22e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.23e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.24e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.25e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.26e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.27e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.28e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.29e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.3e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.31e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.32e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.33e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.34e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.35e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.36e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.37e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.38e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.39e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.4e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.41e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.42e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.43e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.44e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.45e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.46e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.47e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.48e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.49e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.49e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.5e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.51e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.52e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.53e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.54e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.55e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.56e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.57e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.58e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.59e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.6e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.61e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.62e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.63e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.64e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.65e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.66e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.67e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.68e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.69e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.7e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.71e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.72e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.73e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.74e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.75e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.76e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.77e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.78e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.79e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.8e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.81e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.82e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.83e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.84e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.85e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.85e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.86e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.87e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.88e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.89e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.9e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.91e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.92e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.93e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.94e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.95e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.96e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.97e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.98e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.99e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3e+04    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.01e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.02e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.03e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.04e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.05e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.06e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.07e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.08e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.09e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.1e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.11e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.12e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.13e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.14e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.15e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.16e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.17e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.18e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.19e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.2e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.21e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.21e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.22e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.23e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.24e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.25e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.26e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.27e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.28e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.29e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.3e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.31e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.32e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.33e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.34e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.35e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.36e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.37e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.38e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.39e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.4e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.41e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.42e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.43e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.44e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.45e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.46e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.47e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.48e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.49e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.5e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.51e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.52e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.53e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.54e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.55e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.56e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.57e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.57e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.58e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.59e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.6e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.61e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.62e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.63e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.64e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.65e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.66e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.67e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.68e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.69e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.7e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.71e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.72e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.73e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.74e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.75e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.76e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.77e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.78e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.79e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.8e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.81e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.82e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.83e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.84e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.85e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.86e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.87e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.88e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.89e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.9e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.91e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.92e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.93e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.93e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.94e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.95e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.96e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.97e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.98e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.99e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4e+04    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.01e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.02e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.03e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.04e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.05e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.06e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.07e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.08e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.09e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.1e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.11e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.12e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.13e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.14e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.15e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.16e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.17e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.18e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.19e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.2e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.21e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.22e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.23e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.24e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.25e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.26e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.27e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.28e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.29e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.29e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.3e+04  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.31e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.32e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.33e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.34e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.35e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.36e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.37e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.38e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.39e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.4e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.41e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.42e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.43e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.44e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.45e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.46e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.47e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.48e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.49e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.5e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.51e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.52e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.53e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.54e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.55e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.56e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.57e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.58e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.59e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.6e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.61e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.62e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.63e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 4.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.64e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.65e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.65e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.66e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.67e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.68e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.69e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.7e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.71e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.72e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.73e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.74e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.75e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.76e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.77e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.78e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.79e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.8e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.81e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.82e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.83e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.84e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.85e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.86e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.87e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.88e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.89e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.9e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.91e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.92e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.93e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.94e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.95e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.96e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.97e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.98e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.99e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5e+04    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5e+04    |\n",
      "--------------------------------------\n",
      "Saving model due to mean reward increase: 0.5 -> 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.01e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.02e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.03e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.04e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.05e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.06e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.07e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.08e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.09e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.1e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.11e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.12e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.13e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.14e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.15e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.16e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.17e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.18e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.19e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.2e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.21e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.22e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.23e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.24e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.25e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.26e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.27e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.28e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.29e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.3e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.31e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.32e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.33e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.34e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.35e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.36e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.36e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.37e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.38e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.39e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.4e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.41e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.42e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.43e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.44e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.45e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.46e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.47e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.48e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.49e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.5e+04  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.51e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.52e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.53e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.54e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.55e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.56e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.57e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.58e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.59e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.6e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.61e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.62e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.63e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.64e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.65e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.66e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.67e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.68e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.69e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.7e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.71e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.72e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.72e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.73e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.74e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.75e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.76e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.77e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.78e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.79e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.8e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.81e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.82e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.83e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.84e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.85e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.86e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.87e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.88e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.89e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.9e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.91e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.92e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.93e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.94e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.95e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.96e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.97e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.98e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.99e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6e+04    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.01e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.02e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.03e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.04e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.05e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.06e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.07e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.08e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.08e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.09e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.1e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.11e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.12e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.13e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.14e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.15e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.16e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.17e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.18e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.19e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.2e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.21e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.22e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.23e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.24e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.25e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.26e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.27e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.28e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.29e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.3e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.31e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.32e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.33e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.34e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.35e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.36e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.37e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.38e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.39e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.4e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.41e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.42e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.43e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.44e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.44e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.45e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.46e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.47e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.48e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.49e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.5e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.51e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.52e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.53e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.54e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.55e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.56e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.57e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.58e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.59e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.6e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.61e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.62e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.63e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.64e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.65e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.66e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.67e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.68e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.69e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.7e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.71e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.72e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.73e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.74e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.75e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.76e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.77e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.78e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.79e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.8e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.8e+04  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.81e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.82e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.83e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.84e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.85e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.86e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.87e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.88e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.89e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.9e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.91e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.92e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.93e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.94e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.95e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.96e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 6.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.97e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.98e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.99e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7e+04    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.01e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.02e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.03e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.04e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.05e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.06e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.07e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.08e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.09e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.1e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.11e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.12e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.13e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.14e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.15e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.16e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.16e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.17e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.18e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.19e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.2e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.21e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.22e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.23e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.24e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.25e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.26e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.27e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.28e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.29e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.3e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.31e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.32e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.33e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.34e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.35e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.36e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.37e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.38e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.39e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.4e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.41e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.42e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.43e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.44e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.45e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.46e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.47e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.48e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.49e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.5e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.51e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.52e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.52e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.53e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.54e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.55e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.56e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.57e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.58e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.59e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.6e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.61e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.62e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.63e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.64e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.65e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.66e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.67e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.68e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.69e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.7e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.71e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.72e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.73e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.74e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.75e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.76e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.77e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.78e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.79e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.8e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.81e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.82e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.83e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.84e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.85e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.86e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.87e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.88e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.88e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.89e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.9e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.91e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.92e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.93e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.94e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.95e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.96e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.97e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.98e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.99e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8e+04    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.01e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.02e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.03e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.04e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.05e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.06e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.07e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.08e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.09e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.1e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.11e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.12e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.13e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.14e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.15e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.16e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.17e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.18e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.19e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.2e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.21e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.22e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.23e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.24e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.24e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.25e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.26e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.27e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.28e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.29e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.3e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.31e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.32e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.33e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.34e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.35e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.36e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.37e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.38e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.39e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.4e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.41e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.42e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.43e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.44e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.45e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.46e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.47e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.48e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.49e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.5e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.51e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.52e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.53e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.54e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 8.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.55e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.56e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.57e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.58e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.59e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.6e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.6e+04  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.61e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.62e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.63e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.64e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.65e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.66e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.67e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.68e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.69e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.7e+04  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.71e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.72e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.73e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.74e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.75e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.76e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.77e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.78e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.79e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.8e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.81e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.82e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.83e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.84e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.85e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.86e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.87e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.88e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.89e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.9e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.91e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.92e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.93e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.94e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.95e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.96e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.96e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.97e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.98e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.99e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9e+04    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.01e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.02e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.03e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.04e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.05e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.06e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.07e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.08e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.09e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.1e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.11e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.12e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.13e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.14e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.15e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.16e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.17e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.18e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.19e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.2e+04  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.21e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.22e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.23e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.24e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.25e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.26e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.27e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.28e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.29e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.3e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.31e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.32e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.32e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.33e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.34e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.35e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.36e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.37e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.38e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.39e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.4e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.41e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.42e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.43e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.44e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.45e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.46e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.47e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.48e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.49e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.5e+04  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.51e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.52e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.53e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.54e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.55e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.56e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.57e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.58e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.59e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.6e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.61e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.62e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.63e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.64e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.65e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.66e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.67e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.68e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.68e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.69e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.7e+04  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.71e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.72e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.73e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.74e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.75e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.76e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.77e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.78e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.79e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.8e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.81e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.82e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.83e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.84e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.85e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.86e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.87e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.88e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.89e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.9e+04  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.91e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.92e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.93e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.94e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.95e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.96e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.97e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.98e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.99e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.00e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.10e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "Restored model with mean reward: 0.6\n",
      "DQN Training Time: 324.9491002559662\n"
     ]
    }
   ],
   "source": [
    "def synthetic_dqn():\n",
    "    logger.configure(dir='./logs/synthetic_dqn', format_strs=['stdout', 'tensorboard'])\n",
    "    env = SyntheticEnv(images_per_episode=1)\n",
    "    env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "    model = deepq.learn(\n",
    "        env,\n",
    "        'mlp',\n",
    "        num_layers=1, #change number of layers\n",
    "        num_hidden=64,\n",
    "        activation=tf.nn.relu,\n",
    "        hiddens=[32],\n",
    "        dueling=False, #change to True after\n",
    "        lr=1e-4,\n",
    "        total_timesteps=int(1.2e5),\n",
    "        #total_timesteps = 100,\n",
    "        buffer_size=10000,\n",
    "        exploration_fraction=0.1,\n",
    "        exploration_final_eps=0.01,\n",
    "        train_freq=4,\n",
    "        learning_starts=10000,\n",
    "        target_network_update_freq=1000,\n",
    "    )\n",
    "\n",
    "    model.save('models/dqn_synth.pkl')\n",
    "    env.close()\n",
    "\n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "dqn_model = synthetic_dqn()\n",
    "print(\"DQN Training Time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be69f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 46.5%\n"
     ]
    }
   ],
   "source": [
    "def dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "    #a =0\n",
    "\n",
    "    env = SyntheticEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "        #while a <5:\n",
    "            #a+=1\n",
    "            #print(f'Attempt {attempts}')\n",
    "            obs, done = env.reset(), False\n",
    "            #print(f'Dataset index: {env.dataset_idx}')\n",
    "            while not done:\n",
    "                obs, rew, done, info = env.step(dqn_model(obs[None])[0])\n",
    "                #print(f'obs: {obs}')\n",
    "                #print(f'reward: {rew}')\n",
    "                #print(f'done: {done}')\n",
    "                #print(f'info: {info}')\n",
    "                if done==True:\n",
    "                    test_df = test_df.append(info, ignore_index=True)\n",
    "\n",
    "                attempts += 1\n",
    "                if rew > 0:\n",
    "                    correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "    return test_df\n",
    "\n",
    "test_df = dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4771291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.465, 0.2141974499158582, 0.498906265156988)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, f1, roc_auc = test(test_df['y_actual'], test_df['y_pred'])\n",
    "acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8408e62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4e94d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f9d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28baa93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac34e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41d43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2cf23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a982d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6860b94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/synthetic_ppo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.156     |\n",
      "| fps                     | 71        |\n",
      "| loss/approxkl           | 2.58e-06  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 1.1       |\n",
      "| loss/policy_loss        | -0.000253 |\n",
      "| loss/value_loss         | 0.0745    |\n",
      "| misc/explained_variance | 0.0113    |\n",
      "| misc/nupdates           | 1         |\n",
      "| misc/serial_timesteps   | 32        |\n",
      "| misc/time_elapsed       | 0.45      |\n",
      "| misc/total_timesteps    | 32        |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.39     |\n",
      "| fps                     | 210      |\n",
      "| loss/approxkl           | 0.000112 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 1.09     |\n",
      "| loss/policy_loss        | -0.00416 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0.0102   |\n",
      "| misc/nupdates           | 10       |\n",
      "| misc/serial_timesteps   | 320      |\n",
      "| misc/time_elapsed       | 1.78     |\n",
      "| misc/total_timesteps    | 320      |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.33     |\n",
      "| fps                     | 197      |\n",
      "| loss/approxkl           | 0.000745 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 1.02     |\n",
      "| loss/policy_loss        | -0.00427 |\n",
      "| loss/value_loss         | 0.118    |\n",
      "| misc/explained_variance | 0.00388  |\n",
      "| misc/nupdates           | 20       |\n",
      "| misc/serial_timesteps   | 640      |\n",
      "| misc/time_elapsed       | 3.22     |\n",
      "| misc/total_timesteps    | 640      |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 203      |\n",
      "| loss/approxkl           | 0.00175  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.723    |\n",
      "| loss/policy_loss        | -0.0204  |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | -0.00455 |\n",
      "| misc/nupdates           | 30       |\n",
      "| misc/serial_timesteps   | 960      |\n",
      "| misc/time_elapsed       | 4.68     |\n",
      "| misc/total_timesteps    | 960      |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 196      |\n",
      "| loss/approxkl           | 6.27e-05 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.365    |\n",
      "| loss/policy_loss        | -0.00182 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.0063   |\n",
      "| misc/nupdates           | 40       |\n",
      "| misc/serial_timesteps   | 1.28e+03 |\n",
      "| misc/time_elapsed       | 6.15     |\n",
      "| misc/total_timesteps    | 1.28e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.55     |\n",
      "| fps                     | 212      |\n",
      "| loss/approxkl           | 0.000431 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.234    |\n",
      "| loss/policy_loss        | -0.00116 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | -0.0207  |\n",
      "| misc/nupdates           | 50       |\n",
      "| misc/serial_timesteps   | 1.6e+03  |\n",
      "| misc/time_elapsed       | 7.61     |\n",
      "| misc/total_timesteps    | 1.6e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.4      |\n",
      "| fps                     | 212      |\n",
      "| loss/approxkl           | 6.01e-05 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.107    |\n",
      "| loss/policy_loss        | -0.00171 |\n",
      "| loss/value_loss         | 0.131    |\n",
      "| misc/explained_variance | 0.000455 |\n",
      "| misc/nupdates           | 60       |\n",
      "| misc/serial_timesteps   | 1.92e+03 |\n",
      "| misc/time_elapsed       | 9.04     |\n",
      "| misc/total_timesteps    | 1.92e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 215       |\n",
      "| loss/approxkl           | 4.24e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0564    |\n",
      "| loss/policy_loss        | -1.34e-06 |\n",
      "| loss/value_loss         | 0.129     |\n",
      "| misc/explained_variance | 0.00202   |\n",
      "| misc/nupdates           | 70        |\n",
      "| misc/serial_timesteps   | 2.24e+03  |\n",
      "| misc/time_elapsed       | 10.5      |\n",
      "| misc/total_timesteps    | 2.24e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 208       |\n",
      "| loss/approxkl           | 1.4e-07   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0501    |\n",
      "| loss/policy_loss        | -2.63e-05 |\n",
      "| loss/value_loss         | 0.122     |\n",
      "| misc/explained_variance | 0.00384   |\n",
      "| misc/nupdates           | 80        |\n",
      "| misc/serial_timesteps   | 2.56e+03  |\n",
      "| misc/time_elapsed       | 11.9      |\n",
      "| misc/total_timesteps    | 2.56e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 192       |\n",
      "| loss/approxkl           | 8.3e-08   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.055     |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.131     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 90        |\n",
      "| misc/serial_timesteps   | 2.88e+03  |\n",
      "| misc/time_elapsed       | 13.4      |\n",
      "| misc/total_timesteps    | 2.88e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 209       |\n",
      "| loss/approxkl           | 3.25e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0416    |\n",
      "| loss/policy_loss        | -1.86e-09 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 100       |\n",
      "| misc/serial_timesteps   | 3.2e+03   |\n",
      "| misc/time_elapsed       | 14.8      |\n",
      "| misc/total_timesteps    | 3.2e+03   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 201      |\n",
      "| loss/approxkl           | 4.53e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0313   |\n",
      "| loss/policy_loss        | 3.83e-07 |\n",
      "| loss/value_loss         | 0.146    |\n",
      "| misc/explained_variance | 0.00614  |\n",
      "| misc/nupdates           | 110      |\n",
      "| misc/serial_timesteps   | 3.52e+03 |\n",
      "| misc/time_elapsed       | 16.3     |\n",
      "| misc/total_timesteps    | 3.52e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.55      |\n",
      "| fps                     | 197       |\n",
      "| loss/approxkl           | 2.25e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0256    |\n",
      "| loss/policy_loss        | -5.59e-09 |\n",
      "| loss/value_loss         | 0.157     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 120       |\n",
      "| misc/serial_timesteps   | 3.84e+03  |\n",
      "| misc/time_elapsed       | 17.8      |\n",
      "| misc/total_timesteps    | 3.84e+03  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 179       |\n",
      "| loss/approxkl           | 1.69e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0226    |\n",
      "| loss/policy_loss        | -2.79e-09 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 130       |\n",
      "| misc/serial_timesteps   | 4.16e+03  |\n",
      "| misc/time_elapsed       | 19.3      |\n",
      "| misc/total_timesteps    | 4.16e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.4       |\n",
      "| fps                     | 197       |\n",
      "| loss/approxkl           | 2.58e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0232    |\n",
      "| loss/policy_loss        | -8.38e-08 |\n",
      "| loss/value_loss         | 0.129     |\n",
      "| misc/explained_variance | -0.00103  |\n",
      "| misc/nupdates           | 140       |\n",
      "| misc/serial_timesteps   | 4.48e+03  |\n",
      "| misc/time_elapsed       | 20.8      |\n",
      "| misc/total_timesteps    | 4.48e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.57     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 2.25e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0213   |\n",
      "| loss/policy_loss        | 7.33e-07 |\n",
      "| loss/value_loss         | 0.136    |\n",
      "| misc/explained_variance | -0.0137  |\n",
      "| misc/nupdates           | 150      |\n",
      "| misc/serial_timesteps   | 4.8e+03  |\n",
      "| misc/time_elapsed       | 22.3     |\n",
      "| misc/total_timesteps    | 4.8e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 207      |\n",
      "| loss/approxkl           | 1.78e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0166   |\n",
      "| loss/policy_loss        | 7.89e-07 |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | 0.0233   |\n",
      "| misc/nupdates           | 160      |\n",
      "| misc/serial_timesteps   | 5.12e+03 |\n",
      "| misc/time_elapsed       | 23.8     |\n",
      "| misc/total_timesteps    | 5.12e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 200       |\n",
      "| loss/approxkl           | 7.17e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0176    |\n",
      "| loss/policy_loss        | -4.66e-09 |\n",
      "| loss/value_loss         | 0.132     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 170       |\n",
      "| misc/serial_timesteps   | 5.44e+03  |\n",
      "| misc/time_elapsed       | 25.2      |\n",
      "| misc/total_timesteps    | 5.44e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.36      |\n",
      "| fps                     | 211       |\n",
      "| loss/approxkl           | 2.95e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0136    |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.119     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 180       |\n",
      "| misc/serial_timesteps   | 5.76e+03  |\n",
      "| misc/time_elapsed       | 26.7      |\n",
      "| misc/total_timesteps    | 5.76e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 351       |\n",
      "| loss/approxkl           | 5.52e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0117    |\n",
      "| loss/policy_loss        | -1.22e-07 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | 0.043     |\n",
      "| misc/nupdates           | 190       |\n",
      "| misc/serial_timesteps   | 6.08e+03  |\n",
      "| misc/time_elapsed       | 27.8      |\n",
      "| misc/total_timesteps    | 6.08e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.41     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 2.35e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0123   |\n",
      "| loss/policy_loss        | -1.4e-08 |\n",
      "| loss/value_loss         | 0.117    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 200      |\n",
      "| misc/serial_timesteps   | 6.4e+03  |\n",
      "| misc/time_elapsed       | 29.2     |\n",
      "| misc/total_timesteps    | 6.4e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 211      |\n",
      "| loss/approxkl           | 1.5e-10  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0122   |\n",
      "| loss/policy_loss        | 1.17e-07 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | -0.00788 |\n",
      "| misc/nupdates           | 210      |\n",
      "| misc/serial_timesteps   | 6.72e+03 |\n",
      "| misc/time_elapsed       | 30.4     |\n",
      "| misc/total_timesteps    | 6.72e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 200       |\n",
      "| loss/approxkl           | 4.7e-10   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0122    |\n",
      "| loss/policy_loss        | -9.03e-08 |\n",
      "| loss/value_loss         | 0.132     |\n",
      "| misc/explained_variance | -0.0145   |\n",
      "| misc/nupdates           | 220       |\n",
      "| misc/serial_timesteps   | 7.04e+03  |\n",
      "| misc/time_elapsed       | 31.9      |\n",
      "| misc/total_timesteps    | 7.04e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.57     |\n",
      "| fps                     | 190      |\n",
      "| loss/approxkl           | 1.73e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.008    |\n",
      "| loss/policy_loss        | 6.52e-09 |\n",
      "| loss/value_loss         | 0.13     |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 230      |\n",
      "| misc/serial_timesteps   | 7.36e+03 |\n",
      "| misc/time_elapsed       | 33.4     |\n",
      "| misc/total_timesteps    | 7.36e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 211       |\n",
      "| loss/approxkl           | 3.56e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00842   |\n",
      "| loss/policy_loss        | -7.64e-07 |\n",
      "| loss/value_loss         | 0.119     |\n",
      "| misc/explained_variance | 0.0272    |\n",
      "| misc/nupdates           | 240       |\n",
      "| misc/serial_timesteps   | 7.68e+03  |\n",
      "| misc/time_elapsed       | 34.9      |\n",
      "| misc/total_timesteps    | 7.68e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 214       |\n",
      "| loss/approxkl           | 1.35e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00892   |\n",
      "| loss/policy_loss        | -2.49e-07 |\n",
      "| loss/value_loss         | 0.119     |\n",
      "| misc/explained_variance | 0.0214    |\n",
      "| misc/nupdates           | 250       |\n",
      "| misc/serial_timesteps   | 8e+03     |\n",
      "| misc/time_elapsed       | 36.4      |\n",
      "| misc/total_timesteps    | 8e+03     |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 210       |\n",
      "| loss/approxkl           | 2.04e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00899   |\n",
      "| loss/policy_loss        | -1.86e-09 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 260       |\n",
      "| misc/serial_timesteps   | 8.32e+03  |\n",
      "| misc/time_elapsed       | 37.9      |\n",
      "| misc/total_timesteps    | 8.32e+03  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 174       |\n",
      "| loss/approxkl           | 4.42e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00953   |\n",
      "| loss/policy_loss        | -9.36e-08 |\n",
      "| loss/value_loss         | 0.14      |\n",
      "| misc/explained_variance | 0.0039    |\n",
      "| misc/nupdates           | 270       |\n",
      "| misc/serial_timesteps   | 8.64e+03  |\n",
      "| misc/time_elapsed       | 39.6      |\n",
      "| misc/total_timesteps    | 8.64e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.44     |\n",
      "| fps                     | 202      |\n",
      "| loss/approxkl           | 0.000862 |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.00846  |\n",
      "| loss/policy_loss        | -0.00317 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | -0.00867 |\n",
      "| misc/nupdates           | 280      |\n",
      "| misc/serial_timesteps   | 8.96e+03 |\n",
      "| misc/time_elapsed       | 41.1     |\n",
      "| misc/total_timesteps    | 8.96e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 208       |\n",
      "| loss/approxkl           | 3.19e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00631   |\n",
      "| loss/policy_loss        | -1.15e-07 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0.000131  |\n",
      "| misc/nupdates           | 290       |\n",
      "| misc/serial_timesteps   | 9.28e+03  |\n",
      "| misc/time_elapsed       | 42.5      |\n",
      "| misc/total_timesteps    | 9.28e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 5.25e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00645  |\n",
      "| loss/policy_loss        | 2.56e-07 |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | 0.00207  |\n",
      "| misc/nupdates           | 300      |\n",
      "| misc/serial_timesteps   | 9.6e+03  |\n",
      "| misc/time_elapsed       | 44       |\n",
      "| misc/total_timesteps    | 9.6e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.39      |\n",
      "| fps                     | 219       |\n",
      "| loss/approxkl           | 5.12e-13  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00435   |\n",
      "| loss/policy_loss        | -1.74e-07 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | -0.0286   |\n",
      "| misc/nupdates           | 310       |\n",
      "| misc/serial_timesteps   | 9.92e+03  |\n",
      "| misc/time_elapsed       | 45.3      |\n",
      "| misc/total_timesteps    | 9.92e+03  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.36     |\n",
      "| fps                     | 210      |\n",
      "| loss/approxkl           | 5.97e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00475  |\n",
      "| loss/policy_loss        | 4.38e-08 |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | 0.00799  |\n",
      "| misc/nupdates           | 320      |\n",
      "| misc/serial_timesteps   | 1.02e+04 |\n",
      "| misc/time_elapsed       | 46.6     |\n",
      "| misc/total_timesteps    | 1.02e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 209       |\n",
      "| loss/approxkl           | 6.88e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00256   |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 330       |\n",
      "| misc/serial_timesteps   | 1.06e+04  |\n",
      "| misc/time_elapsed       | 48        |\n",
      "| misc/total_timesteps    | 1.06e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.45     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 4.76e-13 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00264  |\n",
      "| loss/policy_loss        | 5.59e-09 |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | 0.00226  |\n",
      "| misc/nupdates           | 340      |\n",
      "| misc/serial_timesteps   | 1.09e+04 |\n",
      "| misc/time_elapsed       | 49.4     |\n",
      "| misc/total_timesteps    | 1.09e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.46     |\n",
      "| fps                     | 217      |\n",
      "| loss/approxkl           | 1.79e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00276  |\n",
      "| loss/policy_loss        | 5.59e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 350      |\n",
      "| misc/serial_timesteps   | 1.12e+04 |\n",
      "| misc/time_elapsed       | 50.7     |\n",
      "| misc/total_timesteps    | 1.12e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 212      |\n",
      "| loss/approxkl           | 2.05e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00239  |\n",
      "| loss/policy_loss        | -9.5e-08 |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | 0.0242   |\n",
      "| misc/nupdates           | 360      |\n",
      "| misc/serial_timesteps   | 1.15e+04 |\n",
      "| misc/time_elapsed       | 52.2     |\n",
      "| misc/total_timesteps    | 1.15e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 216      |\n",
      "| loss/approxkl           | 6.74e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00233  |\n",
      "| loss/policy_loss        | 6.52e-09 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 370      |\n",
      "| misc/serial_timesteps   | 1.18e+04 |\n",
      "| misc/time_elapsed       | 53.6     |\n",
      "| misc/total_timesteps    | 1.18e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.38      |\n",
      "| fps                     | 215       |\n",
      "| loss/approxkl           | 2.36e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00253   |\n",
      "| loss/policy_loss        | -1.39e-07 |\n",
      "| loss/value_loss         | 0.117     |\n",
      "| misc/explained_variance | 0.00462   |\n",
      "| misc/nupdates           | 380       |\n",
      "| misc/serial_timesteps   | 1.22e+04  |\n",
      "| misc/time_elapsed       | 55        |\n",
      "| misc/total_timesteps    | 1.22e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 208      |\n",
      "| loss/approxkl           | 1.7e-11  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00259  |\n",
      "| loss/policy_loss        | 2.65e-07 |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | -0.0211  |\n",
      "| misc/nupdates           | 390      |\n",
      "| misc/serial_timesteps   | 1.25e+04 |\n",
      "| misc/time_elapsed       | 56.5     |\n",
      "| misc/total_timesteps    | 1.25e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 201      |\n",
      "| loss/approxkl           | 1.87e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00269  |\n",
      "| loss/policy_loss        | 9.31e-10 |\n",
      "| loss/value_loss         | 0.134    |\n",
      "| misc/explained_variance | -0.00187 |\n",
      "| misc/nupdates           | 400      |\n",
      "| misc/serial_timesteps   | 1.28e+04 |\n",
      "| misc/time_elapsed       | 58       |\n",
      "| misc/total_timesteps    | 1.28e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 206       |\n",
      "| loss/approxkl           | 7.15e-13  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00295   |\n",
      "| loss/policy_loss        | -1.86e-08 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | -0.00234  |\n",
      "| misc/nupdates           | 410       |\n",
      "| misc/serial_timesteps   | 1.31e+04  |\n",
      "| misc/time_elapsed       | 59.4      |\n",
      "| misc/total_timesteps    | 1.31e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 214       |\n",
      "| loss/approxkl           | 6.61e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00297   |\n",
      "| loss/policy_loss        | -7.68e-08 |\n",
      "| loss/value_loss         | 0.129     |\n",
      "| misc/explained_variance | -0.0026   |\n",
      "| misc/nupdates           | 420       |\n",
      "| misc/serial_timesteps   | 1.34e+04  |\n",
      "| misc/time_elapsed       | 60.9      |\n",
      "| misc/total_timesteps    | 1.34e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.53      |\n",
      "| fps                     | 213       |\n",
      "| loss/approxkl           | 6.64e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0031    |\n",
      "| loss/policy_loss        | -8.38e-09 |\n",
      "| loss/value_loss         | 0.13      |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 430       |\n",
      "| misc/serial_timesteps   | 1.38e+04  |\n",
      "| misc/time_elapsed       | 62.3      |\n",
      "| misc/total_timesteps    | 1.38e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.34      |\n",
      "| fps                     | 220       |\n",
      "| loss/approxkl           | 1.86e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00361   |\n",
      "| loss/policy_loss        | -5.03e-08 |\n",
      "| loss/value_loss         | 0.101     |\n",
      "| misc/explained_variance | 0.00205   |\n",
      "| misc/nupdates           | 440       |\n",
      "| misc/serial_timesteps   | 1.41e+04  |\n",
      "| misc/time_elapsed       | 63.7      |\n",
      "| misc/total_timesteps    | 1.41e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.57      |\n",
      "| fps                     | 233       |\n",
      "| loss/approxkl           | 9.61e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00322   |\n",
      "| loss/policy_loss        | -8.06e-08 |\n",
      "| loss/value_loss         | 0.118     |\n",
      "| misc/explained_variance | 0.0244    |\n",
      "| misc/nupdates           | 450       |\n",
      "| misc/serial_timesteps   | 1.44e+04  |\n",
      "| misc/time_elapsed       | 65.1      |\n",
      "| misc/total_timesteps    | 1.44e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.46     |\n",
      "| fps                     | 231      |\n",
      "| loss/approxkl           | 3.73e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00372  |\n",
      "| loss/policy_loss        | 1.67e-07 |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | -0.00883 |\n",
      "| misc/nupdates           | 460      |\n",
      "| misc/serial_timesteps   | 1.47e+04 |\n",
      "| misc/time_elapsed       | 66.5     |\n",
      "| misc/total_timesteps    | 1.47e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 229       |\n",
      "| loss/approxkl           | 7.49e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00393   |\n",
      "| loss/policy_loss        | -4.66e-09 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 470       |\n",
      "| misc/serial_timesteps   | 1.5e+04   |\n",
      "| misc/time_elapsed       | 67.7      |\n",
      "| misc/total_timesteps    | 1.5e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 211      |\n",
      "| loss/approxkl           | 4.75e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00374  |\n",
      "| loss/policy_loss        | 7.45e-09 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 480      |\n",
      "| misc/serial_timesteps   | 1.54e+04 |\n",
      "| misc/time_elapsed       | 69.1     |\n",
      "| misc/total_timesteps    | 1.54e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 213      |\n",
      "| loss/approxkl           | 5.98e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00417  |\n",
      "| loss/policy_loss        | 1.29e-07 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.00406  |\n",
      "| misc/nupdates           | 490      |\n",
      "| misc/serial_timesteps   | 1.57e+04 |\n",
      "| misc/time_elapsed       | 70.5     |\n",
      "| misc/total_timesteps    | 1.57e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.35     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 5.6e-12  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00493  |\n",
      "| loss/policy_loss        | 2.93e-08 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.00143  |\n",
      "| misc/nupdates           | 500      |\n",
      "| misc/serial_timesteps   | 1.6e+04  |\n",
      "| misc/time_elapsed       | 71.9     |\n",
      "| misc/total_timesteps    | 1.6e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 200      |\n",
      "| loss/approxkl           | 3.34e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.005    |\n",
      "| loss/policy_loss        | 1.31e-07 |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | 0.021    |\n",
      "| misc/nupdates           | 510      |\n",
      "| misc/serial_timesteps   | 1.63e+04 |\n",
      "| misc/time_elapsed       | 73.4     |\n",
      "| misc/total_timesteps    | 1.63e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.34      |\n",
      "| fps                     | 210       |\n",
      "| loss/approxkl           | 7.31e-13  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00221   |\n",
      "| loss/policy_loss        | -5.12e-09 |\n",
      "| loss/value_loss         | 0.0884    |\n",
      "| misc/explained_variance | -0.00344  |\n",
      "| misc/nupdates           | 520       |\n",
      "| misc/serial_timesteps   | 1.66e+04  |\n",
      "| misc/time_elapsed       | 74.7      |\n",
      "| misc/total_timesteps    | 1.66e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 209      |\n",
      "| loss/approxkl           | 6.48e-13 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00208  |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 530      |\n",
      "| misc/serial_timesteps   | 1.7e+04  |\n",
      "| misc/time_elapsed       | 76.2     |\n",
      "| misc/total_timesteps    | 1.7e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 208       |\n",
      "| loss/approxkl           | 4.59e-13  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00232   |\n",
      "| loss/policy_loss        | -1.58e-08 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 540       |\n",
      "| misc/serial_timesteps   | 1.73e+04  |\n",
      "| misc/time_elapsed       | 77.6      |\n",
      "| misc/total_timesteps    | 1.73e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 3.45e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00235  |\n",
      "| loss/policy_loss        | 2.79e-09 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 550      |\n",
      "| misc/serial_timesteps   | 1.76e+04 |\n",
      "| misc/time_elapsed       | 79.2     |\n",
      "| misc/total_timesteps    | 1.76e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 211      |\n",
      "| loss/approxkl           | 7.76e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00236  |\n",
      "| loss/policy_loss        | 2.64e-07 |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | -0.00648 |\n",
      "| misc/nupdates           | 560      |\n",
      "| misc/serial_timesteps   | 1.79e+04 |\n",
      "| misc/time_elapsed       | 80.6     |\n",
      "| misc/total_timesteps    | 1.79e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 208       |\n",
      "| loss/approxkl           | 5.78e-13  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00232   |\n",
      "| loss/policy_loss        | -1.12e-08 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -9e-05    |\n",
      "| misc/nupdates           | 570       |\n",
      "| misc/serial_timesteps   | 1.82e+04  |\n",
      "| misc/time_elapsed       | 82.1      |\n",
      "| misc/total_timesteps    | 1.82e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.37      |\n",
      "| fps                     | 200       |\n",
      "| loss/approxkl           | 1.21e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00286   |\n",
      "| loss/policy_loss        | -8.38e-09 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | -0.0116   |\n",
      "| misc/nupdates           | 580       |\n",
      "| misc/serial_timesteps   | 1.86e+04  |\n",
      "| misc/time_elapsed       | 83.6      |\n",
      "| misc/total_timesteps    | 1.86e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.41      |\n",
      "| fps                     | 213       |\n",
      "| loss/approxkl           | 7.2e-11   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00305   |\n",
      "| loss/policy_loss        | -3.73e-09 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 590       |\n",
      "| misc/serial_timesteps   | 1.89e+04  |\n",
      "| misc/time_elapsed       | 85.1      |\n",
      "| misc/total_timesteps    | 1.89e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 206      |\n",
      "| loss/approxkl           | 2.32e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00329  |\n",
      "| loss/policy_loss        | 3.73e-09 |\n",
      "| loss/value_loss         | 0.128    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 600      |\n",
      "| misc/serial_timesteps   | 1.92e+04 |\n",
      "| misc/time_elapsed       | 86.6     |\n",
      "| misc/total_timesteps    | 1.92e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 202      |\n",
      "| loss/approxkl           | 4.33e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00328  |\n",
      "| loss/policy_loss        | 1.73e-07 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0.00581  |\n",
      "| misc/nupdates           | 610      |\n",
      "| misc/serial_timesteps   | 1.95e+04 |\n",
      "| misc/time_elapsed       | 88.1     |\n",
      "| misc/total_timesteps    | 1.95e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 200       |\n",
      "| loss/approxkl           | 1.27e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00193   |\n",
      "| loss/policy_loss        | -2.67e-07 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | -0.00568  |\n",
      "| misc/nupdates           | 620       |\n",
      "| misc/serial_timesteps   | 1.98e+04  |\n",
      "| misc/time_elapsed       | 89.5      |\n",
      "| misc/total_timesteps    | 1.98e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 201      |\n",
      "| loss/approxkl           | 3.73e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00193  |\n",
      "| loss/policy_loss        | 2.87e-07 |\n",
      "| loss/value_loss         | 0.132    |\n",
      "| misc/explained_variance | -0.00521 |\n",
      "| misc/nupdates           | 630      |\n",
      "| misc/serial_timesteps   | 2.02e+04 |\n",
      "| misc/time_elapsed       | 91       |\n",
      "| misc/total_timesteps    | 2.02e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.4       |\n",
      "| fps                     | 179       |\n",
      "| loss/approxkl           | 2.78e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00241   |\n",
      "| loss/policy_loss        | -1.12e-08 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 640       |\n",
      "| misc/serial_timesteps   | 2.05e+04  |\n",
      "| misc/time_elapsed       | 92.6      |\n",
      "| misc/total_timesteps    | 2.05e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 180       |\n",
      "| loss/approxkl           | 1.06e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00227   |\n",
      "| loss/policy_loss        | -2.14e-08 |\n",
      "| loss/value_loss         | 0.131     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 650       |\n",
      "| misc/serial_timesteps   | 2.08e+04  |\n",
      "| misc/time_elapsed       | 94.1      |\n",
      "| misc/total_timesteps    | 2.08e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 204       |\n",
      "| loss/approxkl           | 8.66e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00272   |\n",
      "| loss/policy_loss        | -6.52e-09 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 660       |\n",
      "| misc/serial_timesteps   | 2.11e+04  |\n",
      "| misc/time_elapsed       | 95.6      |\n",
      "| misc/total_timesteps    | 2.11e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 203      |\n",
      "| loss/approxkl           | 9.79e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0028   |\n",
      "| loss/policy_loss        | 9.08e-08 |\n",
      "| loss/value_loss         | 0.133    |\n",
      "| misc/explained_variance | 0.0092   |\n",
      "| misc/nupdates           | 670      |\n",
      "| misc/serial_timesteps   | 2.14e+04 |\n",
      "| misc/time_elapsed       | 97.1     |\n",
      "| misc/total_timesteps    | 2.14e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 518       |\n",
      "| loss/approxkl           | 1.63e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00321   |\n",
      "| loss/policy_loss        | -1.02e-08 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0.0164    |\n",
      "| misc/nupdates           | 680       |\n",
      "| misc/serial_timesteps   | 2.18e+04  |\n",
      "| misc/time_elapsed       | 98.5      |\n",
      "| misc/total_timesteps    | 2.18e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 214       |\n",
      "| loss/approxkl           | 2.89e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00351   |\n",
      "| loss/policy_loss        | -7.45e-09 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 690       |\n",
      "| misc/serial_timesteps   | 2.21e+04  |\n",
      "| misc/time_elapsed       | 99.9      |\n",
      "| misc/total_timesteps    | 2.21e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.43     |\n",
      "| fps                     | 324      |\n",
      "| loss/approxkl           | 7.17e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00396  |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 700      |\n",
      "| misc/serial_timesteps   | 2.24e+04 |\n",
      "| misc/time_elapsed       | 101      |\n",
      "| misc/total_timesteps    | 2.24e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.43     |\n",
      "| fps                     | 198      |\n",
      "| loss/approxkl           | 0.00285  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.00283  |\n",
      "| loss/policy_loss        | -0.00454 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0.00929  |\n",
      "| misc/nupdates           | 710      |\n",
      "| misc/serial_timesteps   | 2.27e+04 |\n",
      "| misc/time_elapsed       | 103      |\n",
      "| misc/total_timesteps    | 2.27e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 192      |\n",
      "| loss/approxkl           | 6.12e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00208  |\n",
      "| loss/policy_loss        | -2.7e-07 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.0166   |\n",
      "| misc/nupdates           | 720      |\n",
      "| misc/serial_timesteps   | 2.3e+04  |\n",
      "| misc/time_elapsed       | 104      |\n",
      "| misc/total_timesteps    | 2.3e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.46     |\n",
      "| fps                     | 202      |\n",
      "| loss/approxkl           | 6.42e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00227  |\n",
      "| loss/policy_loss        | 4.1e-08  |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | -0.00227 |\n",
      "| misc/nupdates           | 730      |\n",
      "| misc/serial_timesteps   | 2.34e+04 |\n",
      "| misc/time_elapsed       | 106      |\n",
      "| misc/total_timesteps    | 2.34e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 194       |\n",
      "| loss/approxkl           | 7.45e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00238   |\n",
      "| loss/policy_loss        | -4.66e-09 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 740       |\n",
      "| misc/serial_timesteps   | 2.37e+04  |\n",
      "| misc/time_elapsed       | 107       |\n",
      "| misc/total_timesteps    | 2.37e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 290      |\n",
      "| loss/approxkl           | 2.4e-11  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00264  |\n",
      "| loss/policy_loss        | 1.02e-07 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | 0.00669  |\n",
      "| misc/nupdates           | 750      |\n",
      "| misc/serial_timesteps   | 2.4e+04  |\n",
      "| misc/time_elapsed       | 109      |\n",
      "| misc/total_timesteps    | 2.4e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.44     |\n",
      "| fps                     | 198      |\n",
      "| loss/approxkl           | 2.92e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00333  |\n",
      "| loss/policy_loss        | 2.79e-09 |\n",
      "| loss/value_loss         | 0.13     |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 760      |\n",
      "| misc/serial_timesteps   | 2.43e+04 |\n",
      "| misc/time_elapsed       | 110      |\n",
      "| misc/total_timesteps    | 2.43e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 198       |\n",
      "| loss/approxkl           | 2.34e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00314   |\n",
      "| loss/policy_loss        | -3.59e-08 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0.00624   |\n",
      "| misc/nupdates           | 770       |\n",
      "| misc/serial_timesteps   | 2.46e+04  |\n",
      "| misc/time_elapsed       | 112       |\n",
      "| misc/total_timesteps    | 2.46e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 212       |\n",
      "| loss/approxkl           | 8.07e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00389   |\n",
      "| loss/policy_loss        | -1.86e-08 |\n",
      "| loss/value_loss         | 0.118     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 780       |\n",
      "| misc/serial_timesteps   | 2.5e+04   |\n",
      "| misc/time_elapsed       | 113       |\n",
      "| misc/total_timesteps    | 2.5e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.38     |\n",
      "| fps                     | 212      |\n",
      "| loss/approxkl           | 1.9e-11  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00525  |\n",
      "| loss/policy_loss        | 1.49e-07 |\n",
      "| loss/value_loss         | 0.114    |\n",
      "| misc/explained_variance | -0.0125  |\n",
      "| misc/nupdates           | 790      |\n",
      "| misc/serial_timesteps   | 2.53e+04 |\n",
      "| misc/time_elapsed       | 115      |\n",
      "| misc/total_timesteps    | 2.53e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 198      |\n",
      "| loss/approxkl           | 4.38e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00433  |\n",
      "| loss/policy_loss        | -4.1e-08 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0.00372  |\n",
      "| misc/nupdates           | 800      |\n",
      "| misc/serial_timesteps   | 2.56e+04 |\n",
      "| misc/time_elapsed       | 116      |\n",
      "| misc/total_timesteps    | 2.56e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 266      |\n",
      "| loss/approxkl           | 9.21e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00449  |\n",
      "| loss/policy_loss        | 1.65e-07 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | -0.00275 |\n",
      "| misc/nupdates           | 810      |\n",
      "| misc/serial_timesteps   | 2.59e+04 |\n",
      "| misc/time_elapsed       | 117      |\n",
      "| misc/total_timesteps    | 2.59e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 218      |\n",
      "| loss/approxkl           | 8.91e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00528  |\n",
      "| loss/policy_loss        | 5.59e-09 |\n",
      "| loss/value_loss         | 0.128    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 820      |\n",
      "| misc/serial_timesteps   | 2.62e+04 |\n",
      "| misc/time_elapsed       | 119      |\n",
      "| misc/total_timesteps    | 2.62e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.41      |\n",
      "| fps                     | 232       |\n",
      "| loss/approxkl           | 2.34e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00212   |\n",
      "| loss/policy_loss        | -1.21e-08 |\n",
      "| loss/value_loss         | 0.116     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 830       |\n",
      "| misc/serial_timesteps   | 2.66e+04  |\n",
      "| misc/time_elapsed       | 120       |\n",
      "| misc/total_timesteps    | 2.66e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 213       |\n",
      "| loss/approxkl           | 1.07e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00207   |\n",
      "| loss/policy_loss        | -6.52e-09 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 840       |\n",
      "| misc/serial_timesteps   | 2.69e+04  |\n",
      "| misc/time_elapsed       | 122       |\n",
      "| misc/total_timesteps    | 2.69e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 207       |\n",
      "| loss/approxkl           | 1.75e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00207   |\n",
      "| loss/policy_loss        | -3.05e-07 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | -0.00645  |\n",
      "| misc/nupdates           | 850       |\n",
      "| misc/serial_timesteps   | 2.72e+04  |\n",
      "| misc/time_elapsed       | 123       |\n",
      "| misc/total_timesteps    | 2.72e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 203       |\n",
      "| loss/approxkl           | 9.36e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00285   |\n",
      "| loss/policy_loss        | -3.26e-08 |\n",
      "| loss/value_loss         | 0.131     |\n",
      "| misc/explained_variance | -0.000633 |\n",
      "| misc/nupdates           | 860       |\n",
      "| misc/serial_timesteps   | 2.75e+04  |\n",
      "| misc/time_elapsed       | 125       |\n",
      "| misc/total_timesteps    | 2.75e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 209       |\n",
      "| loss/approxkl           | 1.09e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00319   |\n",
      "| loss/policy_loss        | -1.28e-07 |\n",
      "| loss/value_loss         | 0.13      |\n",
      "| misc/explained_variance | -0.00521  |\n",
      "| misc/nupdates           | 870       |\n",
      "| misc/serial_timesteps   | 2.78e+04  |\n",
      "| misc/time_elapsed       | 126       |\n",
      "| misc/total_timesteps    | 2.78e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 209      |\n",
      "| loss/approxkl           | 3.51e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00345  |\n",
      "| loss/policy_loss        | 4.48e-07 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0.0107   |\n",
      "| misc/nupdates           | 880      |\n",
      "| misc/serial_timesteps   | 2.82e+04 |\n",
      "| misc/time_elapsed       | 127      |\n",
      "| misc/total_timesteps    | 2.82e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.52      |\n",
      "| fps                     | 209       |\n",
      "| loss/approxkl           | 8.25e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00302   |\n",
      "| loss/policy_loss        | -4.89e-08 |\n",
      "| loss/value_loss         | 0.129     |\n",
      "| misc/explained_variance | -0.00225  |\n",
      "| misc/nupdates           | 890       |\n",
      "| misc/serial_timesteps   | 2.85e+04  |\n",
      "| misc/time_elapsed       | 129       |\n",
      "| misc/total_timesteps    | 2.85e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 178      |\n",
      "| loss/approxkl           | 2.72e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00442  |\n",
      "| loss/policy_loss        | 6.48e-07 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | -0.0207  |\n",
      "| misc/nupdates           | 900      |\n",
      "| misc/serial_timesteps   | 2.88e+04 |\n",
      "| misc/time_elapsed       | 130      |\n",
      "| misc/total_timesteps    | 2.88e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 214      |\n",
      "| loss/approxkl           | 1.22e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00384  |\n",
      "| loss/policy_loss        | 7.82e-07 |\n",
      "| loss/value_loss         | 0.121    |\n",
      "| misc/explained_variance | 0.00235  |\n",
      "| misc/nupdates           | 910      |\n",
      "| misc/serial_timesteps   | 2.91e+04 |\n",
      "| misc/time_elapsed       | 132      |\n",
      "| misc/total_timesteps    | 2.91e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.41     |\n",
      "| fps                     | 229      |\n",
      "| loss/approxkl           | 4.29e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00572  |\n",
      "| loss/policy_loss        | 7.74e-07 |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | 0.00209  |\n",
      "| misc/nupdates           | 920      |\n",
      "| misc/serial_timesteps   | 2.94e+04 |\n",
      "| misc/time_elapsed       | 133      |\n",
      "| misc/total_timesteps    | 2.94e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 176      |\n",
      "| loss/approxkl           | 5.73e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00651  |\n",
      "| loss/policy_loss        | 6.45e-07 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | 0.00493  |\n",
      "| misc/nupdates           | 930      |\n",
      "| misc/serial_timesteps   | 2.98e+04 |\n",
      "| misc/time_elapsed       | 135      |\n",
      "| misc/total_timesteps    | 2.98e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 169       |\n",
      "| loss/approxkl           | 4.99e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00328   |\n",
      "| loss/policy_loss        | -1.38e-07 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | 0.00106   |\n",
      "| misc/nupdates           | 940       |\n",
      "| misc/serial_timesteps   | 3.01e+04  |\n",
      "| misc/time_elapsed       | 136       |\n",
      "| misc/total_timesteps    | 3.01e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 203       |\n",
      "| loss/approxkl           | 1e-10     |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00379   |\n",
      "| loss/policy_loss        | -3.15e-07 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.00122  |\n",
      "| misc/nupdates           | 950       |\n",
      "| misc/serial_timesteps   | 3.04e+04  |\n",
      "| misc/time_elapsed       | 138       |\n",
      "| misc/total_timesteps    | 3.04e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.45     |\n",
      "| fps                     | 206      |\n",
      "| loss/approxkl           | 0.00206  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.00321  |\n",
      "| loss/policy_loss        | -0.00311 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | -0.00341 |\n",
      "| misc/nupdates           | 960      |\n",
      "| misc/serial_timesteps   | 3.07e+04 |\n",
      "| misc/time_elapsed       | 139      |\n",
      "| misc/total_timesteps    | 3.07e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.33     |\n",
      "| fps                     | 211      |\n",
      "| loss/approxkl           | 3.07e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00285  |\n",
      "| loss/policy_loss        | 3.21e-07 |\n",
      "| loss/value_loss         | 0.105    |\n",
      "| misc/explained_variance | -0.00797 |\n",
      "| misc/nupdates           | 970      |\n",
      "| misc/serial_timesteps   | 3.1e+04  |\n",
      "| misc/time_elapsed       | 141      |\n",
      "| misc/total_timesteps    | 3.1e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 1.19e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00304  |\n",
      "| loss/policy_loss        | 6.01e-07 |\n",
      "| loss/value_loss         | 0.128    |\n",
      "| misc/explained_variance | -0.0185  |\n",
      "| misc/nupdates           | 980      |\n",
      "| misc/serial_timesteps   | 3.14e+04 |\n",
      "| misc/time_elapsed       | 142      |\n",
      "| misc/total_timesteps    | 3.14e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.46     |\n",
      "| fps                     | 210      |\n",
      "| loss/approxkl           | 8.06e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00353  |\n",
      "| loss/policy_loss        | 1.78e-07 |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | -0.00227 |\n",
      "| misc/nupdates           | 990      |\n",
      "| misc/serial_timesteps   | 3.17e+04 |\n",
      "| misc/time_elapsed       | 144      |\n",
      "| misc/total_timesteps    | 3.17e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 207      |\n",
      "| loss/approxkl           | 1.15e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00343  |\n",
      "| loss/policy_loss        | 7.54e-08 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | -0.00607 |\n",
      "| misc/nupdates           | 1e+03    |\n",
      "| misc/serial_timesteps   | 3.2e+04  |\n",
      "| misc/time_elapsed       | 145      |\n",
      "| misc/total_timesteps    | 3.2e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 203      |\n",
      "| loss/approxkl           | 2.17e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00393  |\n",
      "| loss/policy_loss        | 3e-07    |\n",
      "| loss/value_loss         | 0.133    |\n",
      "| misc/explained_variance | -0.00258 |\n",
      "| misc/nupdates           | 1.01e+03 |\n",
      "| misc/serial_timesteps   | 3.23e+04 |\n",
      "| misc/time_elapsed       | 147      |\n",
      "| misc/total_timesteps    | 3.23e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 174      |\n",
      "| loss/approxkl           | 4.17e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00468  |\n",
      "| loss/policy_loss        | 3.73e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.02e+03 |\n",
      "| misc/serial_timesteps   | 3.26e+04 |\n",
      "| misc/time_elapsed       | 148      |\n",
      "| misc/total_timesteps    | 3.26e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.38      |\n",
      "| fps                     | 216       |\n",
      "| loss/approxkl           | 8.11e-13  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00301   |\n",
      "| loss/policy_loss        | -4.66e-10 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | 0.0147    |\n",
      "| misc/nupdates           | 1.03e+03  |\n",
      "| misc/serial_timesteps   | 3.3e+04   |\n",
      "| misc/time_elapsed       | 150       |\n",
      "| misc/total_timesteps    | 3.3e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.4      |\n",
      "| fps                     | 195      |\n",
      "| loss/approxkl           | 2.31e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.004    |\n",
      "| loss/policy_loss        | 2.33e-06 |\n",
      "| loss/value_loss         | 0.117    |\n",
      "| misc/explained_variance | -0.0184  |\n",
      "| misc/nupdates           | 1.04e+03 |\n",
      "| misc/serial_timesteps   | 3.33e+04 |\n",
      "| misc/time_elapsed       | 151      |\n",
      "| misc/total_timesteps    | 3.33e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.55      |\n",
      "| fps                     | 205       |\n",
      "| loss/approxkl           | 2e-09     |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00577   |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.05e+03  |\n",
      "| misc/serial_timesteps   | 3.36e+04  |\n",
      "| misc/time_elapsed       | 153       |\n",
      "| misc/total_timesteps    | 3.36e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.46     |\n",
      "| fps                     | 212      |\n",
      "| loss/approxkl           | 1.95e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00764  |\n",
      "| loss/policy_loss        | -1.4e-08 |\n",
      "| loss/value_loss         | 0.121    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.06e+03 |\n",
      "| misc/serial_timesteps   | 3.39e+04 |\n",
      "| misc/time_elapsed       | 154      |\n",
      "| misc/total_timesteps    | 3.39e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 205       |\n",
      "| loss/approxkl           | 1.37e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0136    |\n",
      "| loss/policy_loss        | -5.01e-07 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0.000282  |\n",
      "| misc/nupdates           | 1.07e+03  |\n",
      "| misc/serial_timesteps   | 3.42e+04  |\n",
      "| misc/time_elapsed       | 156       |\n",
      "| misc/total_timesteps    | 3.42e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 218       |\n",
      "| loss/approxkl           | 1.96e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0157    |\n",
      "| loss/policy_loss        | -5.94e-06 |\n",
      "| loss/value_loss         | 0.13      |\n",
      "| misc/explained_variance | -0.00583  |\n",
      "| misc/nupdates           | 1.08e+03  |\n",
      "| misc/serial_timesteps   | 3.46e+04  |\n",
      "| misc/time_elapsed       | 157       |\n",
      "| misc/total_timesteps    | 3.46e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.52      |\n",
      "| fps                     | 215       |\n",
      "| loss/approxkl           | 3.96e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0148    |\n",
      "| loss/policy_loss        | -1.25e-07 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0.000188  |\n",
      "| misc/nupdates           | 1.09e+03  |\n",
      "| misc/serial_timesteps   | 3.49e+04  |\n",
      "| misc/time_elapsed       | 159       |\n",
      "| misc/total_timesteps    | 3.49e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.52      |\n",
      "| fps                     | 203       |\n",
      "| loss/approxkl           | 2.98e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0143    |\n",
      "| loss/policy_loss        | -4.61e-06 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0.00447   |\n",
      "| misc/nupdates           | 1.1e+03   |\n",
      "| misc/serial_timesteps   | 3.52e+04  |\n",
      "| misc/time_elapsed       | 160       |\n",
      "| misc/total_timesteps    | 3.52e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 209      |\n",
      "| loss/approxkl           | 1.69e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0311   |\n",
      "| loss/policy_loss        | 1.6e-06  |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | -0.0034  |\n",
      "| misc/nupdates           | 1.11e+03 |\n",
      "| misc/serial_timesteps   | 3.55e+04 |\n",
      "| misc/time_elapsed       | 162      |\n",
      "| misc/total_timesteps    | 3.55e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 215      |\n",
      "| loss/approxkl           | 0.00206  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0485   |\n",
      "| loss/policy_loss        | -0.00432 |\n",
      "| loss/value_loss         | 0.128    |\n",
      "| misc/explained_variance | -0.0103  |\n",
      "| misc/nupdates           | 1.12e+03 |\n",
      "| misc/serial_timesteps   | 3.58e+04 |\n",
      "| misc/time_elapsed       | 163      |\n",
      "| misc/total_timesteps    | 3.58e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 216       |\n",
      "| loss/approxkl           | 9e-10     |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.015     |\n",
      "| loss/policy_loss        | -1.05e-06 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | -0.0294   |\n",
      "| misc/nupdates           | 1.13e+03  |\n",
      "| misc/serial_timesteps   | 3.62e+04  |\n",
      "| misc/time_elapsed       | 164       |\n",
      "| misc/total_timesteps    | 3.62e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 4.56e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0153   |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.14e+03 |\n",
      "| misc/serial_timesteps   | 3.65e+04 |\n",
      "| misc/time_elapsed       | 166      |\n",
      "| misc/total_timesteps    | 3.65e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.4       |\n",
      "| fps                     | 200       |\n",
      "| loss/approxkl           | 6.41e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0617    |\n",
      "| loss/policy_loss        | -3.73e-09 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.15e+03  |\n",
      "| misc/serial_timesteps   | 3.68e+04  |\n",
      "| misc/time_elapsed       | 167       |\n",
      "| misc/total_timesteps    | 3.68e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 198      |\n",
      "| loss/approxkl           | 2e-09    |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.017    |\n",
      "| loss/policy_loss        | 1.08e-07 |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | 0.00103  |\n",
      "| misc/nupdates           | 1.16e+03 |\n",
      "| misc/serial_timesteps   | 3.71e+04 |\n",
      "| misc/time_elapsed       | 169      |\n",
      "| misc/total_timesteps    | 3.71e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 215       |\n",
      "| loss/approxkl           | 9.96e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00947   |\n",
      "| loss/policy_loss        | -2.79e-09 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.17e+03  |\n",
      "| misc/serial_timesteps   | 3.74e+04  |\n",
      "| misc/time_elapsed       | 170       |\n",
      "| misc/total_timesteps    | 3.74e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 191      |\n",
      "| loss/approxkl           | 1.72e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0101   |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.128    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.18e+03 |\n",
      "| misc/serial_timesteps   | 3.78e+04 |\n",
      "| misc/time_elapsed       | 172      |\n",
      "| misc/total_timesteps    | 3.78e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 214      |\n",
      "| loss/approxkl           | 1.25e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00997  |\n",
      "| loss/policy_loss        | 2.01e-07 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | 3.1e-06  |\n",
      "| misc/nupdates           | 1.19e+03 |\n",
      "| misc/serial_timesteps   | 3.81e+04 |\n",
      "| misc/time_elapsed       | 173      |\n",
      "| misc/total_timesteps    | 3.81e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.44     |\n",
      "| fps                     | 339      |\n",
      "| loss/approxkl           | 2.12e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00765  |\n",
      "| loss/policy_loss        | 5.02e-07 |\n",
      "| loss/value_loss         | 0.121    |\n",
      "| misc/explained_variance | 0.00209  |\n",
      "| misc/nupdates           | 1.2e+03  |\n",
      "| misc/serial_timesteps   | 3.84e+04 |\n",
      "| misc/time_elapsed       | 175      |\n",
      "| misc/total_timesteps    | 3.84e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 729       |\n",
      "| loss/approxkl           | 2.3e-09   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00833   |\n",
      "| loss/policy_loss        | -1.81e-06 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | 0.0199    |\n",
      "| misc/nupdates           | 1.21e+03  |\n",
      "| misc/serial_timesteps   | 3.87e+04  |\n",
      "| misc/time_elapsed       | 175       |\n",
      "| misc/total_timesteps    | 3.87e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 596       |\n",
      "| loss/approxkl           | 2.77e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00942   |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.22e+03  |\n",
      "| misc/serial_timesteps   | 3.9e+04   |\n",
      "| misc/time_elapsed       | 176       |\n",
      "| misc/total_timesteps    | 3.9e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 357       |\n",
      "| loss/approxkl           | 7.05e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0114    |\n",
      "| loss/policy_loss        | -1.02e-08 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.23e+03  |\n",
      "| misc/serial_timesteps   | 3.94e+04  |\n",
      "| misc/time_elapsed       | 177       |\n",
      "| misc/total_timesteps    | 3.94e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.43     |\n",
      "| fps                     | 315      |\n",
      "| loss/approxkl           | 2.22e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0116   |\n",
      "| loss/policy_loss        | 1.97e-06 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | -0.0099  |\n",
      "| misc/nupdates           | 1.24e+03 |\n",
      "| misc/serial_timesteps   | 3.97e+04 |\n",
      "| misc/time_elapsed       | 178      |\n",
      "| misc/total_timesteps    | 3.97e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.42     |\n",
      "| fps                     | 586      |\n",
      "| loss/approxkl           | 3.04e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00851  |\n",
      "| loss/policy_loss        | 4.16e-07 |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | 0.00854  |\n",
      "| misc/nupdates           | 1.25e+03 |\n",
      "| misc/serial_timesteps   | 4e+04    |\n",
      "| misc/time_elapsed       | 178      |\n",
      "| misc/total_timesteps    | 4e+04    |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 601      |\n",
      "| loss/approxkl           | 3.86e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00803  |\n",
      "| loss/policy_loss        | 1.04e-06 |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | 0.00962  |\n",
      "| misc/nupdates           | 1.26e+03 |\n",
      "| misc/serial_timesteps   | 4.03e+04 |\n",
      "| misc/time_elapsed       | 179      |\n",
      "| misc/total_timesteps    | 4.03e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 342       |\n",
      "| loss/approxkl           | 6.97e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00871   |\n",
      "| loss/policy_loss        | -3.43e-06 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0.0371    |\n",
      "| misc/nupdates           | 1.27e+03  |\n",
      "| misc/serial_timesteps   | 4.06e+04  |\n",
      "| misc/time_elapsed       | 180       |\n",
      "| misc/total_timesteps    | 4.06e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 347      |\n",
      "| loss/approxkl           | 1.6e-09  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00905  |\n",
      "| loss/policy_loss        | 5.2e-07  |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.023    |\n",
      "| misc/nupdates           | 1.28e+03 |\n",
      "| misc/serial_timesteps   | 4.1e+04  |\n",
      "| misc/time_elapsed       | 180      |\n",
      "| misc/total_timesteps    | 4.1e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 395      |\n",
      "| loss/approxkl           | 5.55e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0107   |\n",
      "| loss/policy_loss        | 9.31e-10 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.29e+03 |\n",
      "| misc/serial_timesteps   | 4.13e+04 |\n",
      "| misc/time_elapsed       | 181      |\n",
      "| misc/total_timesteps    | 4.13e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.43     |\n",
      "| fps                     | 356      |\n",
      "| loss/approxkl           | 6.63e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0123   |\n",
      "| loss/policy_loss        | 7.54e-06 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | -0.0897  |\n",
      "| misc/nupdates           | 1.3e+03  |\n",
      "| misc/serial_timesteps   | 4.16e+04 |\n",
      "| misc/time_elapsed       | 182      |\n",
      "| misc/total_timesteps    | 4.16e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 359       |\n",
      "| loss/approxkl           | 8.4e-09   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0132    |\n",
      "| loss/policy_loss        | -4.51e-06 |\n",
      "| loss/value_loss         | 0.131     |\n",
      "| misc/explained_variance | -0.0341   |\n",
      "| misc/nupdates           | 1.31e+03  |\n",
      "| misc/serial_timesteps   | 4.19e+04  |\n",
      "| misc/time_elapsed       | 183       |\n",
      "| misc/total_timesteps    | 4.19e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.37      |\n",
      "| fps                     | 332       |\n",
      "| loss/approxkl           | 7.94e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0185    |\n",
      "| loss/policy_loss        | -5.59e-09 |\n",
      "| loss/value_loss         | 0.111     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.32e+03  |\n",
      "| misc/serial_timesteps   | 4.22e+04  |\n",
      "| misc/time_elapsed       | 184       |\n",
      "| misc/total_timesteps    | 4.22e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.38      |\n",
      "| fps                     | 356       |\n",
      "| loss/approxkl           | 1.26e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0197    |\n",
      "| loss/policy_loss        | -6.52e-09 |\n",
      "| loss/value_loss         | 0.129     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.33e+03  |\n",
      "| misc/serial_timesteps   | 4.26e+04  |\n",
      "| misc/time_elapsed       | 185       |\n",
      "| misc/total_timesteps    | 4.26e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 362       |\n",
      "| loss/approxkl           | 5.92e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.018     |\n",
      "| loss/policy_loss        | -9.31e-09 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.34e+03  |\n",
      "| misc/serial_timesteps   | 4.29e+04  |\n",
      "| misc/time_elapsed       | 186       |\n",
      "| misc/total_timesteps    | 4.29e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 286      |\n",
      "| loss/approxkl           | 4.25e-08 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0315   |\n",
      "| loss/policy_loss        | 5.59e-09 |\n",
      "| loss/value_loss         | 0.13     |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.35e+03 |\n",
      "| misc/serial_timesteps   | 4.32e+04 |\n",
      "| misc/time_elapsed       | 187      |\n",
      "| misc/total_timesteps    | 4.32e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 347       |\n",
      "| loss/approxkl           | 1.44e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0215    |\n",
      "| loss/policy_loss        | -1.34e-06 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | -0.00787  |\n",
      "| misc/nupdates           | 1.36e+03  |\n",
      "| misc/serial_timesteps   | 4.35e+04  |\n",
      "| misc/time_elapsed       | 187       |\n",
      "| misc/total_timesteps    | 4.35e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.43     |\n",
      "| fps                     | 360      |\n",
      "| loss/approxkl           | 0.00148  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0995   |\n",
      "| loss/policy_loss        | -0.00484 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | -0.0157  |\n",
      "| misc/nupdates           | 1.37e+03 |\n",
      "| misc/serial_timesteps   | 4.38e+04 |\n",
      "| misc/time_elapsed       | 188      |\n",
      "| misc/total_timesteps    | 4.38e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 356       |\n",
      "| loss/approxkl           | 2.59e-06  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.115     |\n",
      "| loss/policy_loss        | -3.32e-05 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.00671  |\n",
      "| misc/nupdates           | 1.38e+03  |\n",
      "| misc/serial_timesteps   | 4.42e+04  |\n",
      "| misc/time_elapsed       | 189       |\n",
      "| misc/total_timesteps    | 4.42e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.45     |\n",
      "| fps                     | 359      |\n",
      "| loss/approxkl           | 0.000835 |\n",
      "| loss/clipfrac           | 0.00781  |\n",
      "| loss/policy_entropy     | 0.0599   |\n",
      "| loss/policy_loss        | -0.00402 |\n",
      "| loss/value_loss         | 0.13     |\n",
      "| misc/explained_variance | -0.00339 |\n",
      "| misc/nupdates           | 1.39e+03 |\n",
      "| misc/serial_timesteps   | 4.45e+04 |\n",
      "| misc/time_elapsed       | 190      |\n",
      "| misc/total_timesteps    | 4.45e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 502       |\n",
      "| loss/approxkl           | 2.93e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0235    |\n",
      "| loss/policy_loss        | -6.68e-06 |\n",
      "| loss/value_loss         | 0.118     |\n",
      "| misc/explained_variance | 0.0143    |\n",
      "| misc/nupdates           | 1.4e+03   |\n",
      "| misc/serial_timesteps   | 4.48e+04  |\n",
      "| misc/time_elapsed       | 191       |\n",
      "| misc/total_timesteps    | 4.48e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 360       |\n",
      "| loss/approxkl           | 2.89e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0232    |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.41e+03  |\n",
      "| misc/serial_timesteps   | 4.51e+04  |\n",
      "| misc/time_elapsed       | 192       |\n",
      "| misc/total_timesteps    | 4.51e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 361      |\n",
      "| loss/approxkl           | 1.59e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0256   |\n",
      "| loss/policy_loss        | 0        |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.42e+03 |\n",
      "| misc/serial_timesteps   | 4.54e+04 |\n",
      "| misc/time_elapsed       | 192      |\n",
      "| misc/total_timesteps    | 4.54e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.41     |\n",
      "| fps                     | 362      |\n",
      "| loss/approxkl           | 0.000772 |\n",
      "| loss/clipfrac           | 0.00781  |\n",
      "| loss/policy_entropy     | 0.0152   |\n",
      "| loss/policy_loss        | -0.00288 |\n",
      "| loss/value_loss         | 0.119    |\n",
      "| misc/explained_variance | -0.00621 |\n",
      "| misc/nupdates           | 1.43e+03 |\n",
      "| misc/serial_timesteps   | 4.58e+04 |\n",
      "| misc/time_elapsed       | 193      |\n",
      "| misc/total_timesteps    | 4.58e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.56     |\n",
      "| fps                     | 347      |\n",
      "| loss/approxkl           | 7.8e-10  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0088   |\n",
      "| loss/policy_loss        | 5.59e-09 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.44e+03 |\n",
      "| misc/serial_timesteps   | 4.61e+04 |\n",
      "| misc/time_elapsed       | 194      |\n",
      "| misc/total_timesteps    | 4.61e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 363      |\n",
      "| loss/approxkl           | 5.33e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00892  |\n",
      "| loss/policy_loss        | 5.76e-07 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0.0105   |\n",
      "| misc/nupdates           | 1.45e+03 |\n",
      "| misc/serial_timesteps   | 4.64e+04 |\n",
      "| misc/time_elapsed       | 195      |\n",
      "| misc/total_timesteps    | 4.64e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 344       |\n",
      "| loss/approxkl           | 1.27e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0058    |\n",
      "| loss/policy_loss        | -3.02e-07 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0.0151    |\n",
      "| misc/nupdates           | 1.46e+03  |\n",
      "| misc/serial_timesteps   | 4.67e+04  |\n",
      "| misc/time_elapsed       | 196       |\n",
      "| misc/total_timesteps    | 4.67e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.39      |\n",
      "| fps                     | 359       |\n",
      "| loss/approxkl           | 1.53e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00277   |\n",
      "| loss/policy_loss        | -6.52e-09 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.47e+03  |\n",
      "| misc/serial_timesteps   | 4.7e+04   |\n",
      "| misc/time_elapsed       | 197       |\n",
      "| misc/total_timesteps    | 4.7e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 597       |\n",
      "| loss/approxkl           | 1.63e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0028    |\n",
      "| loss/policy_loss        | -1.12e-08 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.48e+03  |\n",
      "| misc/serial_timesteps   | 4.74e+04  |\n",
      "| misc/time_elapsed       | 198       |\n",
      "| misc/total_timesteps    | 4.74e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.53      |\n",
      "| fps                     | 366       |\n",
      "| loss/approxkl           | 3.57e-14  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00247   |\n",
      "| loss/policy_loss        | 9.31e-09  |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.000595 |\n",
      "| misc/nupdates           | 1.49e+03  |\n",
      "| misc/serial_timesteps   | 4.77e+04  |\n",
      "| misc/time_elapsed       | 198       |\n",
      "| misc/total_timesteps    | 4.77e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 607       |\n",
      "| loss/approxkl           | 1.84e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00313   |\n",
      "| loss/policy_loss        | -5.59e-09 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 5.96e-08  |\n",
      "| misc/nupdates           | 1.5e+03   |\n",
      "| misc/serial_timesteps   | 4.8e+04   |\n",
      "| misc/time_elapsed       | 199       |\n",
      "| misc/total_timesteps    | 4.8e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 352      |\n",
      "| loss/approxkl           | 1.06e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00169  |\n",
      "| loss/policy_loss        | 4e-08    |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.0105   |\n",
      "| misc/nupdates           | 1.51e+03 |\n",
      "| misc/serial_timesteps   | 4.83e+04 |\n",
      "| misc/time_elapsed       | 200      |\n",
      "| misc/total_timesteps    | 4.83e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.46     |\n",
      "| fps                     | 353      |\n",
      "| loss/approxkl           | 9.43e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00187  |\n",
      "| loss/policy_loss        | 2.17e-07 |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | -0.012   |\n",
      "| misc/nupdates           | 1.52e+03 |\n",
      "| misc/serial_timesteps   | 4.86e+04 |\n",
      "| misc/time_elapsed       | 201      |\n",
      "| misc/total_timesteps    | 4.86e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 350       |\n",
      "| loss/approxkl           | 3.06e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00244   |\n",
      "| loss/policy_loss        | -2.19e-08 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | -0.000394 |\n",
      "| misc/nupdates           | 1.53e+03  |\n",
      "| misc/serial_timesteps   | 4.9e+04   |\n",
      "| misc/time_elapsed       | 202       |\n",
      "| misc/total_timesteps    | 4.9e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 359       |\n",
      "| loss/approxkl           | 1.85e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00269   |\n",
      "| loss/policy_loss        | 2.05e-08  |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | -0.000873 |\n",
      "| misc/nupdates           | 1.54e+03  |\n",
      "| misc/serial_timesteps   | 4.93e+04  |\n",
      "| misc/time_elapsed       | 203       |\n",
      "| misc/total_timesteps    | 4.93e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 361      |\n",
      "| loss/approxkl           | 1.84e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00262  |\n",
      "| loss/policy_loss        | 7.44e-07 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | -0.014   |\n",
      "| misc/nupdates           | 1.55e+03 |\n",
      "| misc/serial_timesteps   | 4.96e+04 |\n",
      "| misc/time_elapsed       | 203      |\n",
      "| misc/total_timesteps    | 4.96e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 371      |\n",
      "| loss/approxkl           | 4.76e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00309  |\n",
      "| loss/policy_loss        | -7.8e-07 |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | 0.00682  |\n",
      "| misc/nupdates           | 1.56e+03 |\n",
      "| misc/serial_timesteps   | 4.99e+04 |\n",
      "| misc/time_elapsed       | 204      |\n",
      "| misc/total_timesteps    | 4.99e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.44     |\n",
      "| fps                     | 355      |\n",
      "| loss/approxkl           | 6.97e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00186  |\n",
      "| loss/policy_loss        | 7.64e-08 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | -0.00583 |\n",
      "| misc/nupdates           | 1.57e+03 |\n",
      "| misc/serial_timesteps   | 5.02e+04 |\n",
      "| misc/time_elapsed       | 205      |\n",
      "| misc/total_timesteps    | 5.02e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 345       |\n",
      "| loss/approxkl           | 2.27e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00228   |\n",
      "| loss/policy_loss        | -3.73e-09 |\n",
      "| loss/value_loss         | 0.132     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.58e+03  |\n",
      "| misc/serial_timesteps   | 5.06e+04  |\n",
      "| misc/time_elapsed       | 206       |\n",
      "| misc/total_timesteps    | 5.06e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 342      |\n",
      "| loss/approxkl           | 8.12e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00229  |\n",
      "| loss/policy_loss        | 1.03e-07 |\n",
      "| loss/value_loss         | 0.121    |\n",
      "| misc/explained_variance | 0.00712  |\n",
      "| misc/nupdates           | 1.59e+03 |\n",
      "| misc/serial_timesteps   | 5.09e+04 |\n",
      "| misc/time_elapsed       | 207      |\n",
      "| misc/total_timesteps    | 5.09e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.36      |\n",
      "| fps                     | 391       |\n",
      "| loss/approxkl           | 1.9e-10   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00352   |\n",
      "| loss/policy_loss        | -1.12e-08 |\n",
      "| loss/value_loss         | 0.107     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.6e+03   |\n",
      "| misc/serial_timesteps   | 5.12e+04  |\n",
      "| misc/time_elapsed       | 208       |\n",
      "| misc/total_timesteps    | 5.12e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.46     |\n",
      "| fps                     | 392      |\n",
      "| loss/approxkl           | 1.74e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00355  |\n",
      "| loss/policy_loss        | 8.71e-08 |\n",
      "| loss/value_loss         | 0.131    |\n",
      "| misc/explained_variance | 0.000195 |\n",
      "| misc/nupdates           | 1.61e+03 |\n",
      "| misc/serial_timesteps   | 5.15e+04 |\n",
      "| misc/time_elapsed       | 209      |\n",
      "| misc/total_timesteps    | 5.15e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.55     |\n",
      "| fps                     | 360      |\n",
      "| loss/approxkl           | 2.66e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00481  |\n",
      "| loss/policy_loss        | 8.38e-09 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.62e+03 |\n",
      "| misc/serial_timesteps   | 5.18e+04 |\n",
      "| misc/time_elapsed       | 209      |\n",
      "| misc/total_timesteps    | 5.18e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 383       |\n",
      "| loss/approxkl           | 5.78e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00514   |\n",
      "| loss/policy_loss        | -9.92e-07 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | 0.00521   |\n",
      "| misc/nupdates           | 1.63e+03  |\n",
      "| misc/serial_timesteps   | 5.22e+04  |\n",
      "| misc/time_elapsed       | 210       |\n",
      "| misc/total_timesteps    | 5.22e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.41      |\n",
      "| fps                     | 343       |\n",
      "| loss/approxkl           | 1.94e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00652   |\n",
      "| loss/policy_loss        | -1.02e-08 |\n",
      "| loss/value_loss         | 0.118     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.64e+03  |\n",
      "| misc/serial_timesteps   | 5.25e+04  |\n",
      "| misc/time_elapsed       | 211       |\n",
      "| misc/total_timesteps    | 5.25e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.61     |\n",
      "| fps                     | 347      |\n",
      "| loss/approxkl           | 6.99e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00413  |\n",
      "| loss/policy_loss        | 4.66e-09 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.65e+03 |\n",
      "| misc/serial_timesteps   | 5.28e+04 |\n",
      "| misc/time_elapsed       | 212      |\n",
      "| misc/total_timesteps    | 5.28e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.38     |\n",
      "| fps                     | 355      |\n",
      "| loss/approxkl           | 3.19e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0223   |\n",
      "| loss/policy_loss        | 1.88e-07 |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | 0.0023   |\n",
      "| misc/nupdates           | 1.66e+03 |\n",
      "| misc/serial_timesteps   | 5.31e+04 |\n",
      "| misc/time_elapsed       | 213      |\n",
      "| misc/total_timesteps    | 5.31e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 345       |\n",
      "| loss/approxkl           | 3.97e-07  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.044     |\n",
      "| loss/policy_loss        | -3.29e-05 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0.0167    |\n",
      "| misc/nupdates           | 1.67e+03  |\n",
      "| misc/serial_timesteps   | 5.34e+04  |\n",
      "| misc/time_elapsed       | 214       |\n",
      "| misc/total_timesteps    | 5.34e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.4      |\n",
      "| fps                     | 423      |\n",
      "| loss/approxkl           | 5.9e-08  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.141    |\n",
      "| loss/policy_loss        | 9.4e-06  |\n",
      "| loss/value_loss         | 0.128    |\n",
      "| misc/explained_variance | 0.00371  |\n",
      "| misc/nupdates           | 1.68e+03 |\n",
      "| misc/serial_timesteps   | 5.38e+04 |\n",
      "| misc/time_elapsed       | 215      |\n",
      "| misc/total_timesteps    | 5.38e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 334      |\n",
      "| loss/approxkl           | 1.78e-08 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0321   |\n",
      "| loss/policy_loss        | 6.52e-09 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.69e+03 |\n",
      "| misc/serial_timesteps   | 5.41e+04 |\n",
      "| misc/time_elapsed       | 215      |\n",
      "| misc/total_timesteps    | 5.41e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 345       |\n",
      "| loss/approxkl           | 1.07e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0376    |\n",
      "| loss/policy_loss        | -1.02e-08 |\n",
      "| loss/value_loss         | 0.118     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.7e+03   |\n",
      "| misc/serial_timesteps   | 5.44e+04  |\n",
      "| misc/time_elapsed       | 216       |\n",
      "| misc/total_timesteps    | 5.44e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 333      |\n",
      "| loss/approxkl           | 1.3e-08  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0201   |\n",
      "| loss/policy_loss        | 3.99e-06 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.0107   |\n",
      "| misc/nupdates           | 1.71e+03 |\n",
      "| misc/serial_timesteps   | 5.47e+04 |\n",
      "| misc/time_elapsed       | 217      |\n",
      "| misc/total_timesteps    | 5.47e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.4      |\n",
      "| fps                     | 321      |\n",
      "| loss/approxkl           | 1e-08    |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.022    |\n",
      "| loss/policy_loss        | 1.79e-06 |\n",
      "| loss/value_loss         | 0.112    |\n",
      "| misc/explained_variance | 5.44e-05 |\n",
      "| misc/nupdates           | 1.72e+03 |\n",
      "| misc/serial_timesteps   | 5.5e+04  |\n",
      "| misc/time_elapsed       | 218      |\n",
      "| misc/total_timesteps    | 5.5e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 347       |\n",
      "| loss/approxkl           | 9.45e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0224    |\n",
      "| loss/policy_loss        | -3.62e-06 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | 0.00492   |\n",
      "| misc/nupdates           | 1.73e+03  |\n",
      "| misc/serial_timesteps   | 5.54e+04  |\n",
      "| misc/time_elapsed       | 219       |\n",
      "| misc/total_timesteps    | 5.54e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 349       |\n",
      "| loss/approxkl           | 1.97e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0146    |\n",
      "| loss/policy_loss        | 1.03e-07  |\n",
      "| loss/value_loss         | 0.119     |\n",
      "| misc/explained_variance | -0.000713 |\n",
      "| misc/nupdates           | 1.74e+03  |\n",
      "| misc/serial_timesteps   | 5.57e+04  |\n",
      "| misc/time_elapsed       | 220       |\n",
      "| misc/total_timesteps    | 5.57e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 357      |\n",
      "| loss/approxkl           | 4.46e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0151   |\n",
      "| loss/policy_loss        | 9.31e-10 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.75e+03 |\n",
      "| misc/serial_timesteps   | 5.6e+04  |\n",
      "| misc/time_elapsed       | 221      |\n",
      "| misc/total_timesteps    | 5.6e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 361       |\n",
      "| loss/approxkl           | 4.5e-11   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0196    |\n",
      "| loss/policy_loss        | -7.45e-09 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.76e+03  |\n",
      "| misc/serial_timesteps   | 5.63e+04  |\n",
      "| misc/time_elapsed       | 221       |\n",
      "| misc/total_timesteps    | 5.63e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 389       |\n",
      "| loss/approxkl           | 2.54e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0121    |\n",
      "| loss/policy_loss        | -1.59e-06 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0.00805   |\n",
      "| misc/nupdates           | 1.77e+03  |\n",
      "| misc/serial_timesteps   | 5.66e+04  |\n",
      "| misc/time_elapsed       | 222       |\n",
      "| misc/total_timesteps    | 5.66e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 364       |\n",
      "| loss/approxkl           | 9.67e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0115    |\n",
      "| loss/policy_loss        | -9.02e-07 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | -0.00259  |\n",
      "| misc/nupdates           | 1.78e+03  |\n",
      "| misc/serial_timesteps   | 5.7e+04   |\n",
      "| misc/time_elapsed       | 223       |\n",
      "| misc/total_timesteps    | 5.7e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.45     |\n",
      "| fps                     | 346      |\n",
      "| loss/approxkl           | 3.05e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00655  |\n",
      "| loss/policy_loss        | 1.51e-07 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0.00117  |\n",
      "| misc/nupdates           | 1.79e+03 |\n",
      "| misc/serial_timesteps   | 5.73e+04 |\n",
      "| misc/time_elapsed       | 224      |\n",
      "| misc/total_timesteps    | 5.73e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 358       |\n",
      "| loss/approxkl           | 1.02e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00676   |\n",
      "| loss/policy_loss        | 4.66e-09  |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.000214 |\n",
      "| misc/nupdates           | 1.8e+03   |\n",
      "| misc/serial_timesteps   | 5.76e+04  |\n",
      "| misc/time_elapsed       | 225       |\n",
      "| misc/total_timesteps    | 5.76e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.4       |\n",
      "| fps                     | 378       |\n",
      "| loss/approxkl           | 7.22e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00793   |\n",
      "| loss/policy_loss        | -1.29e-05 |\n",
      "| loss/value_loss         | 0.109     |\n",
      "| misc/explained_variance | 0.0579    |\n",
      "| misc/nupdates           | 1.81e+03  |\n",
      "| misc/serial_timesteps   | 5.79e+04  |\n",
      "| misc/time_elapsed       | 226       |\n",
      "| misc/total_timesteps    | 5.79e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.4      |\n",
      "| fps                     | 319      |\n",
      "| loss/approxkl           | 1.64e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0113   |\n",
      "| loss/policy_loss        | 1.4e-06  |\n",
      "| loss/value_loss         | 0.118    |\n",
      "| misc/explained_variance | 0.0254   |\n",
      "| misc/nupdates           | 1.82e+03 |\n",
      "| misc/serial_timesteps   | 5.82e+04 |\n",
      "| misc/time_elapsed       | 227      |\n",
      "| misc/total_timesteps    | 5.82e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.41      |\n",
      "| fps                     | 373       |\n",
      "| loss/approxkl           | 6.47e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0207    |\n",
      "| loss/policy_loss        | -8.38e-09 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.83e+03  |\n",
      "| misc/serial_timesteps   | 5.86e+04  |\n",
      "| misc/time_elapsed       | 227       |\n",
      "| misc/total_timesteps    | 5.86e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.42     |\n",
      "| fps                     | 357      |\n",
      "| loss/approxkl           | 8.23e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00836  |\n",
      "| loss/policy_loss        | -3.8e-07 |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | -0.0137  |\n",
      "| misc/nupdates           | 1.84e+03 |\n",
      "| misc/serial_timesteps   | 5.89e+04 |\n",
      "| misc/time_elapsed       | 228      |\n",
      "| misc/total_timesteps    | 5.89e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.38      |\n",
      "| fps                     | 369       |\n",
      "| loss/approxkl           | 7.85e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0045    |\n",
      "| loss/policy_loss        | -3.41e-07 |\n",
      "| loss/value_loss         | 0.119     |\n",
      "| misc/explained_variance | 0.0142    |\n",
      "| misc/nupdates           | 1.85e+03  |\n",
      "| misc/serial_timesteps   | 5.92e+04  |\n",
      "| misc/time_elapsed       | 229       |\n",
      "| misc/total_timesteps    | 5.92e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 3.3e-10   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00474   |\n",
      "| loss/policy_loss        | -1.12e-08 |\n",
      "| loss/value_loss         | 0.119     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.86e+03  |\n",
      "| misc/serial_timesteps   | 5.95e+04  |\n",
      "| misc/time_elapsed       | 230       |\n",
      "| misc/total_timesteps    | 5.95e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.52      |\n",
      "| fps                     | 354       |\n",
      "| loss/approxkl           | 7.32e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0129    |\n",
      "| loss/policy_loss        | -3.78e-07 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.0163   |\n",
      "| misc/nupdates           | 1.87e+03  |\n",
      "| misc/serial_timesteps   | 5.98e+04  |\n",
      "| misc/time_elapsed       | 230       |\n",
      "| misc/total_timesteps    | 5.98e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.45     |\n",
      "| fps                     | 393      |\n",
      "| loss/approxkl           | 9.79e-08 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0353   |\n",
      "| loss/policy_loss        | 9.31e-10 |\n",
      "| loss/value_loss         | 0.134    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 1.88e+03 |\n",
      "| misc/serial_timesteps   | 6.02e+04 |\n",
      "| misc/time_elapsed       | 231      |\n",
      "| misc/total_timesteps    | 6.02e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 390       |\n",
      "| loss/approxkl           | 6e-10     |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0305    |\n",
      "| loss/policy_loss        | -2.79e-09 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.89e+03  |\n",
      "| misc/serial_timesteps   | 6.05e+04  |\n",
      "| misc/time_elapsed       | 232       |\n",
      "| misc/total_timesteps    | 6.05e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 350       |\n",
      "| loss/approxkl           | 2.39e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0253    |\n",
      "| loss/policy_loss        | -1.34e-05 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | -0.00593  |\n",
      "| misc/nupdates           | 1.9e+03   |\n",
      "| misc/serial_timesteps   | 6.08e+04  |\n",
      "| misc/time_elapsed       | 233       |\n",
      "| misc/total_timesteps    | 6.08e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 380       |\n",
      "| loss/approxkl           | 1.76e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0246    |\n",
      "| loss/policy_loss        | -1.96e-08 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.91e+03  |\n",
      "| misc/serial_timesteps   | 6.11e+04  |\n",
      "| misc/time_elapsed       | 234       |\n",
      "| misc/total_timesteps    | 6.11e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.37      |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 1.3e-09   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0334    |\n",
      "| loss/policy_loss        | -2.79e-09 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.92e+03  |\n",
      "| misc/serial_timesteps   | 6.14e+04  |\n",
      "| misc/time_elapsed       | 235       |\n",
      "| misc/total_timesteps    | 6.14e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 645      |\n",
      "| loss/approxkl           | 1.93e-08 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0534   |\n",
      "| loss/policy_loss        | 5.46e-06 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | -0.00582 |\n",
      "| misc/nupdates           | 1.93e+03 |\n",
      "| misc/serial_timesteps   | 6.18e+04 |\n",
      "| misc/time_elapsed       | 236      |\n",
      "| misc/total_timesteps    | 6.18e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.4       |\n",
      "| fps                     | 332       |\n",
      "| loss/approxkl           | 3.39e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0487    |\n",
      "| loss/policy_loss        | -1.03e-05 |\n",
      "| loss/value_loss         | 0.116     |\n",
      "| misc/explained_variance | -0.00067  |\n",
      "| misc/nupdates           | 1.94e+03  |\n",
      "| misc/serial_timesteps   | 6.21e+04  |\n",
      "| misc/time_elapsed       | 236       |\n",
      "| misc/total_timesteps    | 6.21e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 344       |\n",
      "| loss/approxkl           | 2.82e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0417    |\n",
      "| loss/policy_loss        | -6.11e-06 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | -0.00279  |\n",
      "| misc/nupdates           | 1.95e+03  |\n",
      "| misc/serial_timesteps   | 6.24e+04  |\n",
      "| misc/time_elapsed       | 237       |\n",
      "| misc/total_timesteps    | 6.24e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 358       |\n",
      "| loss/approxkl           | 2.11e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0456    |\n",
      "| loss/policy_loss        | -4.66e-09 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 1.96e+03  |\n",
      "| misc/serial_timesteps   | 6.27e+04  |\n",
      "| misc/time_elapsed       | 238       |\n",
      "| misc/total_timesteps    | 6.27e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 377      |\n",
      "| loss/approxkl           | 7.13e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.015    |\n",
      "| loss/policy_loss        | 5.36e-06 |\n",
      "| loss/value_loss         | 0.132    |\n",
      "| misc/explained_variance | -0.0318  |\n",
      "| misc/nupdates           | 1.97e+03 |\n",
      "| misc/serial_timesteps   | 6.3e+04  |\n",
      "| misc/time_elapsed       | 239      |\n",
      "| misc/total_timesteps    | 6.3e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 342      |\n",
      "| loss/approxkl           | 4.93e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0178   |\n",
      "| loss/policy_loss        | 1.93e-06 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | -0.01    |\n",
      "| misc/nupdates           | 1.98e+03 |\n",
      "| misc/serial_timesteps   | 6.34e+04 |\n",
      "| misc/time_elapsed       | 240      |\n",
      "| misc/total_timesteps    | 6.34e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.59      |\n",
      "| fps                     | 358       |\n",
      "| loss/approxkl           | 0.00147   |\n",
      "| loss/clipfrac           | 0.0156    |\n",
      "| loss/policy_entropy     | 0.0128    |\n",
      "| loss/policy_loss        | -0.00551  |\n",
      "| loss/value_loss         | 0.119     |\n",
      "| misc/explained_variance | -0.000441 |\n",
      "| misc/nupdates           | 1.99e+03  |\n",
      "| misc/serial_timesteps   | 6.37e+04  |\n",
      "| misc/time_elapsed       | 241       |\n",
      "| misc/total_timesteps    | 6.37e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.59      |\n",
      "| fps                     | 349       |\n",
      "| loss/approxkl           | 1.41e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00781   |\n",
      "| loss/policy_loss        | -1.63e-07 |\n",
      "| loss/value_loss         | 0.129     |\n",
      "| misc/explained_variance | 0.00166   |\n",
      "| misc/nupdates           | 2e+03     |\n",
      "| misc/serial_timesteps   | 6.4e+04   |\n",
      "| misc/time_elapsed       | 242       |\n",
      "| misc/total_timesteps    | 6.4e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.44     |\n",
      "| fps                     | 345      |\n",
      "| loss/approxkl           | 1.18e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0129   |\n",
      "| loss/policy_loss        | 2.79e-09 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.01e+03 |\n",
      "| misc/serial_timesteps   | 6.43e+04 |\n",
      "| misc/time_elapsed       | 242      |\n",
      "| misc/total_timesteps    | 6.43e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 349       |\n",
      "| loss/approxkl           | 2.29e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0118    |\n",
      "| loss/policy_loss        | -1.08e-07 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0.00585   |\n",
      "| misc/nupdates           | 2.02e+03  |\n",
      "| misc/serial_timesteps   | 6.46e+04  |\n",
      "| misc/time_elapsed       | 243       |\n",
      "| misc/total_timesteps    | 6.46e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.45     |\n",
      "| fps                     | 333      |\n",
      "| loss/approxkl           | 5.4e-10  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00862  |\n",
      "| loss/policy_loss        | 1.52e-07 |\n",
      "| loss/value_loss         | 0.143    |\n",
      "| misc/explained_variance | 0.00545  |\n",
      "| misc/nupdates           | 2.03e+03 |\n",
      "| misc/serial_timesteps   | 6.5e+04  |\n",
      "| misc/time_elapsed       | 244      |\n",
      "| misc/total_timesteps    | 6.5e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 354       |\n",
      "| loss/approxkl           | 1.46e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00846   |\n",
      "| loss/policy_loss        | -4.31e-06 |\n",
      "| loss/value_loss         | 0.132     |\n",
      "| misc/explained_variance | -0.0278   |\n",
      "| misc/nupdates           | 2.04e+03  |\n",
      "| misc/serial_timesteps   | 6.53e+04  |\n",
      "| misc/time_elapsed       | 245       |\n",
      "| misc/total_timesteps    | 6.53e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 349      |\n",
      "| loss/approxkl           | 0.00114  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0178   |\n",
      "| loss/policy_loss        | -0.00574 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | -0.00733 |\n",
      "| misc/nupdates           | 2.05e+03 |\n",
      "| misc/serial_timesteps   | 6.56e+04 |\n",
      "| misc/time_elapsed       | 246      |\n",
      "| misc/total_timesteps    | 6.56e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 352       |\n",
      "| loss/approxkl           | 4.44e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0119    |\n",
      "| loss/policy_loss        | -1.56e-07 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | -0.0227   |\n",
      "| misc/nupdates           | 2.06e+03  |\n",
      "| misc/serial_timesteps   | 6.59e+04  |\n",
      "| misc/time_elapsed       | 247       |\n",
      "| misc/total_timesteps    | 6.59e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.37      |\n",
      "| fps                     | 355       |\n",
      "| loss/approxkl           | 5.85e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0158    |\n",
      "| loss/policy_loss        | -3.73e-09 |\n",
      "| loss/value_loss         | 0.106     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.07e+03  |\n",
      "| misc/serial_timesteps   | 6.62e+04  |\n",
      "| misc/time_elapsed       | 248       |\n",
      "| misc/total_timesteps    | 6.62e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 351       |\n",
      "| loss/approxkl           | 2.32e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0139    |\n",
      "| loss/policy_loss        | -1.37e-05 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0.0138    |\n",
      "| misc/nupdates           | 2.08e+03  |\n",
      "| misc/serial_timesteps   | 6.66e+04  |\n",
      "| misc/time_elapsed       | 248       |\n",
      "| misc/total_timesteps    | 6.66e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 344       |\n",
      "| loss/approxkl           | 2.55e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0161    |\n",
      "| loss/policy_loss        | -9.38e-07 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | 0.0162    |\n",
      "| misc/nupdates           | 2.09e+03  |\n",
      "| misc/serial_timesteps   | 6.69e+04  |\n",
      "| misc/time_elapsed       | 249       |\n",
      "| misc/total_timesteps    | 6.69e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 340       |\n",
      "| loss/approxkl           | 4.43e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00838   |\n",
      "| loss/policy_loss        | -7.45e-09 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.1e+03   |\n",
      "| misc/serial_timesteps   | 6.72e+04  |\n",
      "| misc/time_elapsed       | 250       |\n",
      "| misc/total_timesteps    | 6.72e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 315       |\n",
      "| loss/approxkl           | 7.96e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00924   |\n",
      "| loss/policy_loss        | -1.28e-06 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0.00577   |\n",
      "| misc/nupdates           | 2.11e+03  |\n",
      "| misc/serial_timesteps   | 6.75e+04  |\n",
      "| misc/time_elapsed       | 251       |\n",
      "| misc/total_timesteps    | 6.75e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 611      |\n",
      "| loss/approxkl           | 2.52e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00838  |\n",
      "| loss/policy_loss        | 4.37e-07 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | 0.0076   |\n",
      "| misc/nupdates           | 2.12e+03 |\n",
      "| misc/serial_timesteps   | 6.78e+04 |\n",
      "| misc/time_elapsed       | 252      |\n",
      "| misc/total_timesteps    | 6.78e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.53      |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 1.75e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00917   |\n",
      "| loss/policy_loss        | -2.87e-06 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.0035   |\n",
      "| misc/nupdates           | 2.13e+03  |\n",
      "| misc/serial_timesteps   | 6.82e+04  |\n",
      "| misc/time_elapsed       | 253       |\n",
      "| misc/total_timesteps    | 6.82e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.45     |\n",
      "| fps                     | 343      |\n",
      "| loss/approxkl           | 3.13e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0139   |\n",
      "| loss/policy_loss        | -4e-06   |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | -0.00472 |\n",
      "| misc/nupdates           | 2.14e+03 |\n",
      "| misc/serial_timesteps   | 6.85e+04 |\n",
      "| misc/time_elapsed       | 253      |\n",
      "| misc/total_timesteps    | 6.85e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 395      |\n",
      "| loss/approxkl           | 3.75e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00685  |\n",
      "| loss/policy_loss        | 7.45e-09 |\n",
      "| loss/value_loss         | 0.128    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.15e+03 |\n",
      "| misc/serial_timesteps   | 6.88e+04 |\n",
      "| misc/time_elapsed       | 254      |\n",
      "| misc/total_timesteps    | 6.88e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 339       |\n",
      "| loss/approxkl           | 5.32e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00693   |\n",
      "| loss/policy_loss        | -9.45e-07 |\n",
      "| loss/value_loss         | 0.119     |\n",
      "| misc/explained_variance | -0.00541  |\n",
      "| misc/nupdates           | 2.16e+03  |\n",
      "| misc/serial_timesteps   | 6.91e+04  |\n",
      "| misc/time_elapsed       | 255       |\n",
      "| misc/total_timesteps    | 6.91e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 318       |\n",
      "| loss/approxkl           | 5.57e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00793   |\n",
      "| loss/policy_loss        | -1.03e-07 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | -0.00657  |\n",
      "| misc/nupdates           | 2.17e+03  |\n",
      "| misc/serial_timesteps   | 6.94e+04  |\n",
      "| misc/time_elapsed       | 256       |\n",
      "| misc/total_timesteps    | 6.94e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.39     |\n",
      "| fps                     | 346      |\n",
      "| loss/approxkl           | 9.25e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.01     |\n",
      "| loss/policy_loss        | 1.2e-06  |\n",
      "| loss/value_loss         | 0.114    |\n",
      "| misc/explained_variance | -0.00121 |\n",
      "| misc/nupdates           | 2.18e+03 |\n",
      "| misc/serial_timesteps   | 6.98e+04 |\n",
      "| misc/time_elapsed       | 257      |\n",
      "| misc/total_timesteps    | 6.98e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.4       |\n",
      "| fps                     | 410       |\n",
      "| loss/approxkl           | 2.87e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0134    |\n",
      "| loss/policy_loss        | -2.06e-06 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.000385 |\n",
      "| misc/nupdates           | 2.19e+03  |\n",
      "| misc/serial_timesteps   | 7.01e+04  |\n",
      "| misc/time_elapsed       | 258       |\n",
      "| misc/total_timesteps    | 7.01e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 337      |\n",
      "| loss/approxkl           | 2.38e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0128   |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.2e+03  |\n",
      "| misc/serial_timesteps   | 7.04e+04 |\n",
      "| misc/time_elapsed       | 259      |\n",
      "| misc/total_timesteps    | 7.04e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 564       |\n",
      "| loss/approxkl           | 5.58e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0133    |\n",
      "| loss/policy_loss        | -1.14e-06 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0.00103   |\n",
      "| misc/nupdates           | 2.21e+03  |\n",
      "| misc/serial_timesteps   | 7.07e+04  |\n",
      "| misc/time_elapsed       | 259       |\n",
      "| misc/total_timesteps    | 7.07e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 346       |\n",
      "| loss/approxkl           | 2.26e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0141    |\n",
      "| loss/policy_loss        | -4.56e-06 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | -0.014    |\n",
      "| misc/nupdates           | 2.22e+03  |\n",
      "| misc/serial_timesteps   | 7.1e+04   |\n",
      "| misc/time_elapsed       | 260       |\n",
      "| misc/total_timesteps    | 7.1e+04   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 498      |\n",
      "| loss/approxkl           | 1.67e-08 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0161   |\n",
      "| loss/policy_loss        | 4.66e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.23e+03 |\n",
      "| misc/serial_timesteps   | 7.14e+04 |\n",
      "| misc/time_elapsed       | 261      |\n",
      "| misc/total_timesteps    | 7.14e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 431       |\n",
      "| loss/approxkl           | 4.36e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00877   |\n",
      "| loss/policy_loss        | -2.14e-06 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0.0027    |\n",
      "| misc/nupdates           | 2.24e+03  |\n",
      "| misc/serial_timesteps   | 7.17e+04  |\n",
      "| misc/time_elapsed       | 262       |\n",
      "| misc/total_timesteps    | 7.17e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 369       |\n",
      "| loss/approxkl           | 1.89e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00355   |\n",
      "| loss/policy_loss        | 3.26e-09  |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | -0.000132 |\n",
      "| misc/nupdates           | 2.25e+03  |\n",
      "| misc/serial_timesteps   | 7.2e+04   |\n",
      "| misc/time_elapsed       | 263       |\n",
      "| misc/total_timesteps    | 7.2e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.41     |\n",
      "| fps                     | 337      |\n",
      "| loss/approxkl           | 6.98e-13 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00302  |\n",
      "| loss/policy_loss        | 7.17e-08 |\n",
      "| loss/value_loss         | 0.14     |\n",
      "| misc/explained_variance | -0.00394 |\n",
      "| misc/nupdates           | 2.26e+03 |\n",
      "| misc/serial_timesteps   | 7.23e+04 |\n",
      "| misc/time_elapsed       | 263      |\n",
      "| misc/total_timesteps    | 7.23e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.4       |\n",
      "| fps                     | 427       |\n",
      "| loss/approxkl           | 4.56e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00375   |\n",
      "| loss/policy_loss        | -4.61e-08 |\n",
      "| loss/value_loss         | 0.14      |\n",
      "| misc/explained_variance | 0.00383   |\n",
      "| misc/nupdates           | 2.27e+03  |\n",
      "| misc/serial_timesteps   | 7.26e+04  |\n",
      "| misc/time_elapsed       | 264       |\n",
      "| misc/total_timesteps    | 7.26e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.56      |\n",
      "| fps                     | 348       |\n",
      "| loss/approxkl           | 6.56e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00363   |\n",
      "| loss/policy_loss        | -7.38e-07 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.0209   |\n",
      "| misc/nupdates           | 2.28e+03  |\n",
      "| misc/serial_timesteps   | 7.3e+04   |\n",
      "| misc/time_elapsed       | 265       |\n",
      "| misc/total_timesteps    | 7.3e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 353      |\n",
      "| loss/approxkl           | 1.1e-11  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00206  |\n",
      "| loss/policy_loss        | 0        |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.29e+03 |\n",
      "| misc/serial_timesteps   | 7.33e+04 |\n",
      "| misc/time_elapsed       | 266      |\n",
      "| misc/total_timesteps    | 7.33e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 330      |\n",
      "| loss/approxkl           | 1.44e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00388  |\n",
      "| loss/policy_loss        | 1.02e-08 |\n",
      "| loss/value_loss         | 0.132    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.3e+03  |\n",
      "| misc/serial_timesteps   | 7.36e+04 |\n",
      "| misc/time_elapsed       | 267      |\n",
      "| misc/total_timesteps    | 7.36e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.62     |\n",
      "| fps                     | 347      |\n",
      "| loss/approxkl           | 4.6e-10  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00295  |\n",
      "| loss/policy_loss        | 1.58e-08 |\n",
      "| loss/value_loss         | 0.118    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.31e+03 |\n",
      "| misc/serial_timesteps   | 7.39e+04 |\n",
      "| misc/time_elapsed       | 268      |\n",
      "| misc/total_timesteps    | 7.39e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.53      |\n",
      "| fps                     | 338       |\n",
      "| loss/approxkl           | 1.91e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00443   |\n",
      "| loss/policy_loss        | -2.97e-07 |\n",
      "| loss/value_loss         | 0.122     |\n",
      "| misc/explained_variance | 0.0103    |\n",
      "| misc/nupdates           | 2.32e+03  |\n",
      "| misc/serial_timesteps   | 7.42e+04  |\n",
      "| misc/time_elapsed       | 269       |\n",
      "| misc/total_timesteps    | 7.42e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 356       |\n",
      "| loss/approxkl           | 1.92e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00461   |\n",
      "| loss/policy_loss        | -9.03e-08 |\n",
      "| loss/value_loss         | 0.132     |\n",
      "| misc/explained_variance | 0.00552   |\n",
      "| misc/nupdates           | 2.33e+03  |\n",
      "| misc/serial_timesteps   | 7.46e+04  |\n",
      "| misc/time_elapsed       | 269       |\n",
      "| misc/total_timesteps    | 7.46e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 365       |\n",
      "| loss/approxkl           | 1.66e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00632   |\n",
      "| loss/policy_loss        | -2.93e-08 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0.000151  |\n",
      "| misc/nupdates           | 2.34e+03  |\n",
      "| misc/serial_timesteps   | 7.49e+04  |\n",
      "| misc/time_elapsed       | 270       |\n",
      "| misc/total_timesteps    | 7.49e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 353      |\n",
      "| loss/approxkl           | 1.03e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00663  |\n",
      "| loss/policy_loss        | -2e-07   |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | 0.00542  |\n",
      "| misc/nupdates           | 2.35e+03 |\n",
      "| misc/serial_timesteps   | 7.52e+04 |\n",
      "| misc/time_elapsed       | 271      |\n",
      "| misc/total_timesteps    | 7.52e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 356       |\n",
      "| loss/approxkl           | 1.64e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00716   |\n",
      "| loss/policy_loss        | -1.02e-08 |\n",
      "| loss/value_loss         | 0.122     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.36e+03  |\n",
      "| misc/serial_timesteps   | 7.55e+04  |\n",
      "| misc/time_elapsed       | 272       |\n",
      "| misc/total_timesteps    | 7.55e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 344      |\n",
      "| loss/approxkl           | 1.48e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00663  |\n",
      "| loss/policy_loss        | -1.6e-06 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.00687  |\n",
      "| misc/nupdates           | 2.37e+03 |\n",
      "| misc/serial_timesteps   | 7.58e+04 |\n",
      "| misc/time_elapsed       | 273      |\n",
      "| misc/total_timesteps    | 7.58e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 337       |\n",
      "| loss/approxkl           | 1.61e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00893   |\n",
      "| loss/policy_loss        | -2.33e-08 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0.0148    |\n",
      "| misc/nupdates           | 2.38e+03  |\n",
      "| misc/serial_timesteps   | 7.62e+04  |\n",
      "| misc/time_elapsed       | 274       |\n",
      "| misc/total_timesteps    | 7.62e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.41      |\n",
      "| fps                     | 359       |\n",
      "| loss/approxkl           | 7.56e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0112    |\n",
      "| loss/policy_loss        | -6.52e-09 |\n",
      "| loss/value_loss         | 0.119     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.39e+03  |\n",
      "| misc/serial_timesteps   | 7.65e+04  |\n",
      "| misc/time_elapsed       | 275       |\n",
      "| misc/total_timesteps    | 7.65e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 352       |\n",
      "| loss/approxkl           | 3.66e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00582   |\n",
      "| loss/policy_loss        | -3.92e-07 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0.0179    |\n",
      "| misc/nupdates           | 2.4e+03   |\n",
      "| misc/serial_timesteps   | 7.68e+04  |\n",
      "| misc/time_elapsed       | 276       |\n",
      "| misc/total_timesteps    | 7.68e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 459      |\n",
      "| loss/approxkl           | 2.84e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00587  |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.41e+03 |\n",
      "| misc/serial_timesteps   | 7.71e+04 |\n",
      "| misc/time_elapsed       | 276      |\n",
      "| misc/total_timesteps    | 7.71e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 357      |\n",
      "| loss/approxkl           | 7.19e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.006    |\n",
      "| loss/policy_loss        | 1.4e-08  |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.42e+03 |\n",
      "| misc/serial_timesteps   | 7.74e+04 |\n",
      "| misc/time_elapsed       | 277      |\n",
      "| misc/total_timesteps    | 7.74e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.46     |\n",
      "| fps                     | 402      |\n",
      "| loss/approxkl           | 1.07e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0104   |\n",
      "| loss/policy_loss        | 1.1e-06  |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | 0.0243   |\n",
      "| misc/nupdates           | 2.43e+03 |\n",
      "| misc/serial_timesteps   | 7.78e+04 |\n",
      "| misc/time_elapsed       | 278      |\n",
      "| misc/total_timesteps    | 7.78e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 332       |\n",
      "| loss/approxkl           | 1.88e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0112    |\n",
      "| loss/policy_loss        | -2.79e-09 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.44e+03  |\n",
      "| misc/serial_timesteps   | 7.81e+04  |\n",
      "| misc/time_elapsed       | 279       |\n",
      "| misc/total_timesteps    | 7.81e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 338       |\n",
      "| loss/approxkl           | 7.78e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00173   |\n",
      "| loss/policy_loss        | -8.38e-09 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.45e+03  |\n",
      "| misc/serial_timesteps   | 7.84e+04  |\n",
      "| misc/time_elapsed       | 280       |\n",
      "| misc/total_timesteps    | 7.84e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 335       |\n",
      "| loss/approxkl           | 5.47e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00146   |\n",
      "| loss/policy_loss        | -2.19e-07 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0.00365   |\n",
      "| misc/nupdates           | 2.46e+03  |\n",
      "| misc/serial_timesteps   | 7.87e+04  |\n",
      "| misc/time_elapsed       | 281       |\n",
      "| misc/total_timesteps    | 7.87e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.45     |\n",
      "| fps                     | 350      |\n",
      "| loss/approxkl           | 2.34e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00173  |\n",
      "| loss/policy_loss        | 5.87e-08 |\n",
      "| loss/value_loss         | 0.121    |\n",
      "| misc/explained_variance | 0.00637  |\n",
      "| misc/nupdates           | 2.47e+03 |\n",
      "| misc/serial_timesteps   | 7.9e+04  |\n",
      "| misc/time_elapsed       | 282      |\n",
      "| misc/total_timesteps    | 7.9e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 369       |\n",
      "| loss/approxkl           | 1.52e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00272   |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.48e+03  |\n",
      "| misc/serial_timesteps   | 7.94e+04  |\n",
      "| misc/time_elapsed       | 282       |\n",
      "| misc/total_timesteps    | 7.94e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.58     |\n",
      "| fps                     | 359      |\n",
      "| loss/approxkl           | 4.46e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00246  |\n",
      "| loss/policy_loss        | 5.59e-09 |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | 0.0158   |\n",
      "| misc/nupdates           | 2.49e+03 |\n",
      "| misc/serial_timesteps   | 7.97e+04 |\n",
      "| misc/time_elapsed       | 283      |\n",
      "| misc/total_timesteps    | 7.97e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 363       |\n",
      "| loss/approxkl           | 1.14e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00358   |\n",
      "| loss/policy_loss        | -4.66e-09 |\n",
      "| loss/value_loss         | 0.122     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.5e+03   |\n",
      "| misc/serial_timesteps   | 8e+04     |\n",
      "| misc/time_elapsed       | 284       |\n",
      "| misc/total_timesteps    | 8e+04     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 366       |\n",
      "| loss/approxkl           | 4.75e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00321   |\n",
      "| loss/policy_loss        | 8.57e-08  |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -2.41e-05 |\n",
      "| misc/nupdates           | 2.51e+03  |\n",
      "| misc/serial_timesteps   | 8.03e+04  |\n",
      "| misc/time_elapsed       | 285       |\n",
      "| misc/total_timesteps    | 8.03e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 340      |\n",
      "| loss/approxkl           | 2.54e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00435  |\n",
      "| loss/policy_loss        | 1.47e-07 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0.00764  |\n",
      "| misc/nupdates           | 2.52e+03 |\n",
      "| misc/serial_timesteps   | 8.06e+04 |\n",
      "| misc/time_elapsed       | 286      |\n",
      "| misc/total_timesteps    | 8.06e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 367      |\n",
      "| loss/approxkl           | 6.26e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00485  |\n",
      "| loss/policy_loss        | 1.21e-08 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.53e+03 |\n",
      "| misc/serial_timesteps   | 8.1e+04  |\n",
      "| misc/time_elapsed       | 287      |\n",
      "| misc/total_timesteps    | 8.1e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.36      |\n",
      "| fps                     | 347       |\n",
      "| loss/approxkl           | 2.1e-09   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.009     |\n",
      "| loss/policy_loss        | -1.02e-08 |\n",
      "| loss/value_loss         | 0.113     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.54e+03  |\n",
      "| misc/serial_timesteps   | 8.13e+04  |\n",
      "| misc/time_elapsed       | 288       |\n",
      "| misc/total_timesteps    | 8.13e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 365      |\n",
      "| loss/approxkl           | 3.58e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.002    |\n",
      "| loss/policy_loss        | 4.66e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.55e+03 |\n",
      "| misc/serial_timesteps   | 8.16e+04 |\n",
      "| misc/time_elapsed       | 288      |\n",
      "| misc/total_timesteps    | 8.16e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 363       |\n",
      "| loss/approxkl           | 1.18e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00258   |\n",
      "| loss/policy_loss        | -5.59e-09 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.56e+03  |\n",
      "| misc/serial_timesteps   | 8.19e+04  |\n",
      "| misc/time_elapsed       | 289       |\n",
      "| misc/total_timesteps    | 8.19e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.41      |\n",
      "| fps                     | 469       |\n",
      "| loss/approxkl           | 1.3e-09   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00316   |\n",
      "| loss/policy_loss        | -5.12e-08 |\n",
      "| loss/value_loss         | 0.118     |\n",
      "| misc/explained_variance | 0.00698   |\n",
      "| misc/nupdates           | 2.57e+03  |\n",
      "| misc/serial_timesteps   | 8.22e+04  |\n",
      "| misc/time_elapsed       | 290       |\n",
      "| misc/total_timesteps    | 8.22e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 359       |\n",
      "| loss/approxkl           | 1.31e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00356   |\n",
      "| loss/policy_loss        | -3.73e-09 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.58e+03  |\n",
      "| misc/serial_timesteps   | 8.26e+04  |\n",
      "| misc/time_elapsed       | 291       |\n",
      "| misc/total_timesteps    | 8.26e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 1.88e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0053    |\n",
      "| loss/policy_loss        | -6.52e-09 |\n",
      "| loss/value_loss         | 0.129     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.59e+03  |\n",
      "| misc/serial_timesteps   | 8.29e+04  |\n",
      "| misc/time_elapsed       | 292       |\n",
      "| misc/total_timesteps    | 8.29e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.43     |\n",
      "| fps                     | 333      |\n",
      "| loss/approxkl           | 1.62e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00493  |\n",
      "| loss/policy_loss        | 2.61e-06 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | -0.0199  |\n",
      "| misc/nupdates           | 2.6e+03  |\n",
      "| misc/serial_timesteps   | 8.32e+04 |\n",
      "| misc/time_elapsed       | 293      |\n",
      "| misc/total_timesteps    | 8.32e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 568      |\n",
      "| loss/approxkl           | 5.05e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00633  |\n",
      "| loss/policy_loss        | 1.35e-06 |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | -0.0169  |\n",
      "| misc/nupdates           | 2.61e+03 |\n",
      "| misc/serial_timesteps   | 8.35e+04 |\n",
      "| misc/time_elapsed       | 293      |\n",
      "| misc/total_timesteps    | 8.35e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.56     |\n",
      "| fps                     | 338      |\n",
      "| loss/approxkl           | 0.0033   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.00403  |\n",
      "| loss/policy_loss        | -0.00708 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0.00825  |\n",
      "| misc/nupdates           | 2.62e+03 |\n",
      "| misc/serial_timesteps   | 8.38e+04 |\n",
      "| misc/time_elapsed       | 294      |\n",
      "| misc/total_timesteps    | 8.38e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 1.04e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0042    |\n",
      "| loss/policy_loss        | -3.73e-09 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.63e+03  |\n",
      "| misc/serial_timesteps   | 8.42e+04  |\n",
      "| misc/time_elapsed       | 295       |\n",
      "| misc/total_timesteps    | 8.42e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.4      |\n",
      "| fps                     | 357      |\n",
      "| loss/approxkl           | 6.06e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00484  |\n",
      "| loss/policy_loss        | 9.78e-08 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.00317  |\n",
      "| misc/nupdates           | 2.64e+03 |\n",
      "| misc/serial_timesteps   | 8.45e+04 |\n",
      "| misc/time_elapsed       | 296      |\n",
      "| misc/total_timesteps    | 8.45e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.44     |\n",
      "| fps                     | 337      |\n",
      "| loss/approxkl           | 9.95e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00475  |\n",
      "| loss/policy_loss        | 1.44e-07 |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | 0.00146  |\n",
      "| misc/nupdates           | 2.65e+03 |\n",
      "| misc/serial_timesteps   | 8.48e+04 |\n",
      "| misc/time_elapsed       | 297      |\n",
      "| misc/total_timesteps    | 8.48e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 350       |\n",
      "| loss/approxkl           | 5.69e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00437   |\n",
      "| loss/policy_loss        | -6.35e-06 |\n",
      "| loss/value_loss         | 0.122     |\n",
      "| misc/explained_variance | 0.0158    |\n",
      "| misc/nupdates           | 2.66e+03  |\n",
      "| misc/serial_timesteps   | 8.51e+04  |\n",
      "| misc/time_elapsed       | 298       |\n",
      "| misc/total_timesteps    | 8.51e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.41      |\n",
      "| fps                     | 346       |\n",
      "| loss/approxkl           | 4.28e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00735   |\n",
      "| loss/policy_loss        | -2.66e-07 |\n",
      "| loss/value_loss         | 0.115     |\n",
      "| misc/explained_variance | -0.0041   |\n",
      "| misc/nupdates           | 2.67e+03  |\n",
      "| misc/serial_timesteps   | 8.54e+04  |\n",
      "| misc/time_elapsed       | 299       |\n",
      "| misc/total_timesteps    | 8.54e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.39      |\n",
      "| fps                     | 425       |\n",
      "| loss/approxkl           | 1.77e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0097    |\n",
      "| loss/policy_loss        | -1.52e-06 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | -0.00419  |\n",
      "| misc/nupdates           | 2.68e+03  |\n",
      "| misc/serial_timesteps   | 8.58e+04  |\n",
      "| misc/time_elapsed       | 299       |\n",
      "| misc/total_timesteps    | 8.58e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 356       |\n",
      "| loss/approxkl           | 3.28e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00488   |\n",
      "| loss/policy_loss        | -4.57e-07 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | 0.00481   |\n",
      "| misc/nupdates           | 2.69e+03  |\n",
      "| misc/serial_timesteps   | 8.61e+04  |\n",
      "| misc/time_elapsed       | 300       |\n",
      "| misc/total_timesteps    | 8.61e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.55     |\n",
      "| fps                     | 346      |\n",
      "| loss/approxkl           | 0.00347  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.00852  |\n",
      "| loss/policy_loss        | -0.00774 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.7e+03  |\n",
      "| misc/serial_timesteps   | 8.64e+04 |\n",
      "| misc/time_elapsed       | 301      |\n",
      "| misc/total_timesteps    | 8.64e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 343      |\n",
      "| loss/approxkl           | 5e-11    |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00207  |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.71e+03 |\n",
      "| misc/serial_timesteps   | 8.67e+04 |\n",
      "| misc/time_elapsed       | 302      |\n",
      "| misc/total_timesteps    | 8.67e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 344       |\n",
      "| loss/approxkl           | 1.4e-12   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00262   |\n",
      "| loss/policy_loss        | -9.03e-08 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | 0.00329   |\n",
      "| misc/nupdates           | 2.72e+03  |\n",
      "| misc/serial_timesteps   | 8.7e+04   |\n",
      "| misc/time_elapsed       | 303       |\n",
      "| misc/total_timesteps    | 8.7e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 358       |\n",
      "| loss/approxkl           | 9.05e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00323   |\n",
      "| loss/policy_loss        | -7.94e-07 |\n",
      "| loss/value_loss         | 0.122     |\n",
      "| misc/explained_variance | 0.0128    |\n",
      "| misc/nupdates           | 2.73e+03  |\n",
      "| misc/serial_timesteps   | 8.74e+04  |\n",
      "| misc/time_elapsed       | 304       |\n",
      "| misc/total_timesteps    | 8.74e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.41      |\n",
      "| fps                     | 359       |\n",
      "| loss/approxkl           | 2.11e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00421   |\n",
      "| loss/policy_loss        | -1.86e-09 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.74e+03  |\n",
      "| misc/serial_timesteps   | 8.77e+04  |\n",
      "| misc/time_elapsed       | 304       |\n",
      "| misc/total_timesteps    | 8.77e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 351       |\n",
      "| loss/approxkl           | 5.25e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00469   |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.13      |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.75e+03  |\n",
      "| misc/serial_timesteps   | 8.8e+04   |\n",
      "| misc/time_elapsed       | 305       |\n",
      "| misc/total_timesteps    | 8.8e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 361      |\n",
      "| loss/approxkl           | 1.37e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00373  |\n",
      "| loss/policy_loss        | 4.66e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.76e+03 |\n",
      "| misc/serial_timesteps   | 8.83e+04 |\n",
      "| misc/time_elapsed       | 306      |\n",
      "| misc/total_timesteps    | 8.83e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 336       |\n",
      "| loss/approxkl           | 5.85e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0044    |\n",
      "| loss/policy_loss        | -1.16e-06 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0.00646   |\n",
      "| misc/nupdates           | 2.77e+03  |\n",
      "| misc/serial_timesteps   | 8.86e+04  |\n",
      "| misc/time_elapsed       | 307       |\n",
      "| misc/total_timesteps    | 8.86e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.52     |\n",
      "| fps                     | 366      |\n",
      "| loss/approxkl           | 1.84e-08 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00963  |\n",
      "| loss/policy_loss        | -1.2e-05 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | -0.00327 |\n",
      "| misc/nupdates           | 2.78e+03 |\n",
      "| misc/serial_timesteps   | 8.9e+04  |\n",
      "| misc/time_elapsed       | 308      |\n",
      "| misc/total_timesteps    | 8.9e+04  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.37     |\n",
      "| fps                     | 362      |\n",
      "| loss/approxkl           | 0.000992 |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0143   |\n",
      "| loss/policy_loss        | 0.000675 |\n",
      "| loss/value_loss         | 0.117    |\n",
      "| misc/explained_variance | -0.00127 |\n",
      "| misc/nupdates           | 2.79e+03 |\n",
      "| misc/serial_timesteps   | 8.93e+04 |\n",
      "| misc/time_elapsed       | 309      |\n",
      "| misc/total_timesteps    | 8.93e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.42     |\n",
      "| fps                     | 361      |\n",
      "| loss/approxkl           | 8.96e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0114   |\n",
      "| loss/policy_loss        | 2.63e-07 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0.00779  |\n",
      "| misc/nupdates           | 2.8e+03  |\n",
      "| misc/serial_timesteps   | 8.96e+04 |\n",
      "| misc/time_elapsed       | 309      |\n",
      "| misc/total_timesteps    | 8.96e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.62     |\n",
      "| fps                     | 389      |\n",
      "| loss/approxkl           | 7.72e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00716  |\n",
      "| loss/policy_loss        | 1.58e-08 |\n",
      "| loss/value_loss         | 0.109    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.81e+03 |\n",
      "| misc/serial_timesteps   | 8.99e+04 |\n",
      "| misc/time_elapsed       | 310      |\n",
      "| misc/total_timesteps    | 8.99e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 344       |\n",
      "| loss/approxkl           | 7.56e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00326   |\n",
      "| loss/policy_loss        | -6.66e-08 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0.00104   |\n",
      "| misc/nupdates           | 2.82e+03  |\n",
      "| misc/serial_timesteps   | 9.02e+04  |\n",
      "| misc/time_elapsed       | 311       |\n",
      "| misc/total_timesteps    | 9.02e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 363      |\n",
      "| loss/approxkl           | 7.96e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00391  |\n",
      "| loss/policy_loss        | 4.66e-09 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.83e+03 |\n",
      "| misc/serial_timesteps   | 9.06e+04 |\n",
      "| misc/time_elapsed       | 312      |\n",
      "| misc/total_timesteps    | 9.06e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 340       |\n",
      "| loss/approxkl           | 1.59e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00408   |\n",
      "| loss/policy_loss        | -4.99e-07 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | -0.0163   |\n",
      "| misc/nupdates           | 2.84e+03  |\n",
      "| misc/serial_timesteps   | 9.09e+04  |\n",
      "| misc/time_elapsed       | 313       |\n",
      "| misc/total_timesteps    | 9.09e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 331       |\n",
      "| loss/approxkl           | 1.66e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00428   |\n",
      "| loss/policy_loss        | -7.45e-09 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.85e+03  |\n",
      "| misc/serial_timesteps   | 9.12e+04  |\n",
      "| misc/time_elapsed       | 314       |\n",
      "| misc/total_timesteps    | 9.12e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.54      |\n",
      "| fps                     | 351       |\n",
      "| loss/approxkl           | 1.33e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00361   |\n",
      "| loss/policy_loss        | -6.33e-07 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.00138  |\n",
      "| misc/nupdates           | 2.86e+03  |\n",
      "| misc/serial_timesteps   | 9.15e+04  |\n",
      "| misc/time_elapsed       | 315       |\n",
      "| misc/total_timesteps    | 9.15e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 320      |\n",
      "| loss/approxkl           | 1.36e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00484  |\n",
      "| loss/policy_loss        | 2.79e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.87e+03 |\n",
      "| misc/serial_timesteps   | 9.18e+04 |\n",
      "| misc/time_elapsed       | 316      |\n",
      "| misc/total_timesteps    | 9.18e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.44     |\n",
      "| fps                     | 357      |\n",
      "| loss/approxkl           | 1.57e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00558  |\n",
      "| loss/policy_loss        | 2.79e-09 |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | -0.0053  |\n",
      "| misc/nupdates           | 2.88e+03 |\n",
      "| misc/serial_timesteps   | 9.22e+04 |\n",
      "| misc/time_elapsed       | 316      |\n",
      "| misc/total_timesteps    | 9.22e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.4      |\n",
      "| fps                     | 357      |\n",
      "| loss/approxkl           | 3.59e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00707  |\n",
      "| loss/policy_loss        | 4.47e-08 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | -0.0133  |\n",
      "| misc/nupdates           | 2.89e+03 |\n",
      "| misc/serial_timesteps   | 9.25e+04 |\n",
      "| misc/time_elapsed       | 317      |\n",
      "| misc/total_timesteps    | 9.25e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 357       |\n",
      "| loss/approxkl           | 5.76e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00795   |\n",
      "| loss/policy_loss        | -2.79e-09 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 2.9e+03   |\n",
      "| misc/serial_timesteps   | 9.28e+04  |\n",
      "| misc/time_elapsed       | 318       |\n",
      "| misc/total_timesteps    | 9.28e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 416      |\n",
      "| loss/approxkl           | 1.25e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0056   |\n",
      "| loss/policy_loss        | 3.73e-09 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.91e+03 |\n",
      "| misc/serial_timesteps   | 9.31e+04 |\n",
      "| misc/time_elapsed       | 319      |\n",
      "| misc/total_timesteps    | 9.31e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 344       |\n",
      "| loss/approxkl           | 2.08e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0117    |\n",
      "| loss/policy_loss        | -1.45e-06 |\n",
      "| loss/value_loss         | 0.114     |\n",
      "| misc/explained_variance | 0.0225    |\n",
      "| misc/nupdates           | 2.92e+03  |\n",
      "| misc/serial_timesteps   | 9.34e+04  |\n",
      "| misc/time_elapsed       | 320       |\n",
      "| misc/total_timesteps    | 9.34e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.41     |\n",
      "| fps                     | 628      |\n",
      "| loss/approxkl           | 9.69e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0131   |\n",
      "| loss/policy_loss        | -1.5e-06 |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | -0.01    |\n",
      "| misc/nupdates           | 2.93e+03 |\n",
      "| misc/serial_timesteps   | 9.38e+04 |\n",
      "| misc/time_elapsed       | 321      |\n",
      "| misc/total_timesteps    | 9.38e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 408       |\n",
      "| loss/approxkl           | 1.51e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0109    |\n",
      "| loss/policy_loss        | -1.36e-06 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0.00849   |\n",
      "| misc/nupdates           | 2.94e+03  |\n",
      "| misc/serial_timesteps   | 9.41e+04  |\n",
      "| misc/time_elapsed       | 321       |\n",
      "| misc/total_timesteps    | 9.41e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 392       |\n",
      "| loss/approxkl           | 3.11e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00997   |\n",
      "| loss/policy_loss        | -5.49e-08 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.000987 |\n",
      "| misc/nupdates           | 2.95e+03  |\n",
      "| misc/serial_timesteps   | 9.44e+04  |\n",
      "| misc/time_elapsed       | 322       |\n",
      "| misc/total_timesteps    | 9.44e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 483       |\n",
      "| loss/approxkl           | 1.75e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0121    |\n",
      "| loss/policy_loss        | -8.46e-06 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0.00996   |\n",
      "| misc/nupdates           | 2.96e+03  |\n",
      "| misc/serial_timesteps   | 9.47e+04  |\n",
      "| misc/time_elapsed       | 323       |\n",
      "| misc/total_timesteps    | 9.47e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.39      |\n",
      "| fps                     | 446       |\n",
      "| loss/approxkl           | 4.56e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0178    |\n",
      "| loss/policy_loss        | -2.53e-06 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | -0.00903  |\n",
      "| misc/nupdates           | 2.97e+03  |\n",
      "| misc/serial_timesteps   | 9.5e+04   |\n",
      "| misc/time_elapsed       | 324       |\n",
      "| misc/total_timesteps    | 9.5e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 346       |\n",
      "| loss/approxkl           | 1.12e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0179    |\n",
      "| loss/policy_loss        | -1.39e-06 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | -0.00125  |\n",
      "| misc/nupdates           | 2.98e+03  |\n",
      "| misc/serial_timesteps   | 9.54e+04  |\n",
      "| misc/time_elapsed       | 325       |\n",
      "| misc/total_timesteps    | 9.54e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.46     |\n",
      "| fps                     | 369      |\n",
      "| loss/approxkl           | 1.99e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00836  |\n",
      "| loss/policy_loss        | 3.73e-09 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 2.99e+03 |\n",
      "| misc/serial_timesteps   | 9.57e+04 |\n",
      "| misc/time_elapsed       | 325      |\n",
      "| misc/total_timesteps    | 9.57e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.55      |\n",
      "| fps                     | 355       |\n",
      "| loss/approxkl           | 2.54e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00679   |\n",
      "| loss/policy_loss        | -9.31e-09 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3e+03     |\n",
      "| misc/serial_timesteps   | 9.6e+04   |\n",
      "| misc/time_elapsed       | 326       |\n",
      "| misc/total_timesteps    | 9.6e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 5.88e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00936   |\n",
      "| loss/policy_loss        | -2.21e-05 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0.00695   |\n",
      "| misc/nupdates           | 3.01e+03  |\n",
      "| misc/serial_timesteps   | 9.63e+04  |\n",
      "| misc/time_elapsed       | 327       |\n",
      "| misc/total_timesteps    | 9.63e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 351       |\n",
      "| loss/approxkl           | 1.07e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0068    |\n",
      "| loss/policy_loss        | -2.47e-06 |\n",
      "| loss/value_loss         | 0.122     |\n",
      "| misc/explained_variance | -0.000428 |\n",
      "| misc/nupdates           | 3.02e+03  |\n",
      "| misc/serial_timesteps   | 9.66e+04  |\n",
      "| misc/time_elapsed       | 328       |\n",
      "| misc/total_timesteps    | 9.66e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 357       |\n",
      "| loss/approxkl           | 5.51e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00913   |\n",
      "| loss/policy_loss        | -2.22e-06 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | -0.00138  |\n",
      "| misc/nupdates           | 3.03e+03  |\n",
      "| misc/serial_timesteps   | 9.7e+04   |\n",
      "| misc/time_elapsed       | 329       |\n",
      "| misc/total_timesteps    | 9.7e+04   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 349       |\n",
      "| loss/approxkl           | 1.13e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00896   |\n",
      "| loss/policy_loss        | -5.59e-09 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.04e+03  |\n",
      "| misc/serial_timesteps   | 9.73e+04  |\n",
      "| misc/time_elapsed       | 330       |\n",
      "| misc/total_timesteps    | 9.73e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.59     |\n",
      "| fps                     | 342      |\n",
      "| loss/approxkl           | 1.51e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00858  |\n",
      "| loss/policy_loss        | 1.3e-08  |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.05e+03 |\n",
      "| misc/serial_timesteps   | 9.76e+04 |\n",
      "| misc/time_elapsed       | 330      |\n",
      "| misc/total_timesteps    | 9.76e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 372       |\n",
      "| loss/approxkl           | 4.84e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0126    |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.06e+03  |\n",
      "| misc/serial_timesteps   | 9.79e+04  |\n",
      "| misc/time_elapsed       | 331       |\n",
      "| misc/total_timesteps    | 9.79e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.38      |\n",
      "| fps                     | 405       |\n",
      "| loss/approxkl           | 1.32e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0154    |\n",
      "| loss/policy_loss        | -6.52e-09 |\n",
      "| loss/value_loss         | 0.114     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.07e+03  |\n",
      "| misc/serial_timesteps   | 9.82e+04  |\n",
      "| misc/time_elapsed       | 332       |\n",
      "| misc/total_timesteps    | 9.82e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.47      |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 2.84e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.015     |\n",
      "| loss/policy_loss        | 4.56e-07  |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | -5.96e-07 |\n",
      "| misc/nupdates           | 3.08e+03  |\n",
      "| misc/serial_timesteps   | 9.86e+04  |\n",
      "| misc/time_elapsed       | 333       |\n",
      "| misc/total_timesteps    | 9.86e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 338       |\n",
      "| loss/approxkl           | 9.22e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0185    |\n",
      "| loss/policy_loss        | -2.15e-06 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | -0.000577 |\n",
      "| misc/nupdates           | 3.09e+03  |\n",
      "| misc/serial_timesteps   | 9.89e+04  |\n",
      "| misc/time_elapsed       | 334       |\n",
      "| misc/total_timesteps    | 9.89e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 341       |\n",
      "| loss/approxkl           | 2.47e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0181    |\n",
      "| loss/policy_loss        | -3.58e-05 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | -0.0107   |\n",
      "| misc/nupdates           | 3.1e+03   |\n",
      "| misc/serial_timesteps   | 9.92e+04  |\n",
      "| misc/time_elapsed       | 335       |\n",
      "| misc/total_timesteps    | 9.92e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.39      |\n",
      "| fps                     | 335       |\n",
      "| loss/approxkl           | 3.72e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0186    |\n",
      "| loss/policy_loss        | -4.06e-05 |\n",
      "| loss/value_loss         | 0.118     |\n",
      "| misc/explained_variance | -0.0135   |\n",
      "| misc/nupdates           | 3.11e+03  |\n",
      "| misc/serial_timesteps   | 9.95e+04  |\n",
      "| misc/time_elapsed       | 336       |\n",
      "| misc/total_timesteps    | 9.95e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.57     |\n",
      "| fps                     | 371      |\n",
      "| loss/approxkl           | 1.69e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0149   |\n",
      "| loss/policy_loss        | 6.25e-07 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0.00115  |\n",
      "| misc/nupdates           | 3.12e+03 |\n",
      "| misc/serial_timesteps   | 9.98e+04 |\n",
      "| misc/time_elapsed       | 336      |\n",
      "| misc/total_timesteps    | 9.98e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 344       |\n",
      "| loss/approxkl           | 3.3e-08   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0543    |\n",
      "| loss/policy_loss        | 2.1e-06   |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | -4.05e-06 |\n",
      "| misc/nupdates           | 3.13e+03  |\n",
      "| misc/serial_timesteps   | 1e+05     |\n",
      "| misc/time_elapsed       | 337       |\n",
      "| misc/total_timesteps    | 1e+05     |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.36      |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 2.53e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0126    |\n",
      "| loss/policy_loss        | -8.38e-09 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.14e+03  |\n",
      "| misc/serial_timesteps   | 1e+05     |\n",
      "| misc/time_elapsed       | 338       |\n",
      "| misc/total_timesteps    | 1e+05     |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 354       |\n",
      "| loss/approxkl           | 7.07e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00715   |\n",
      "| loss/policy_loss        | -7.41e-05 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | -0.0218   |\n",
      "| misc/nupdates           | 3.15e+03  |\n",
      "| misc/serial_timesteps   | 1.01e+05  |\n",
      "| misc/time_elapsed       | 339       |\n",
      "| misc/total_timesteps    | 1.01e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 347      |\n",
      "| loss/approxkl           | 1.06e-08 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00529  |\n",
      "| loss/policy_loss        | 3.12e-05 |\n",
      "| loss/value_loss         | 0.128    |\n",
      "| misc/explained_variance | -0.0372  |\n",
      "| misc/nupdates           | 3.16e+03 |\n",
      "| misc/serial_timesteps   | 1.01e+05 |\n",
      "| misc/time_elapsed       | 340      |\n",
      "| misc/total_timesteps    | 1.01e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.4      |\n",
      "| fps                     | 365      |\n",
      "| loss/approxkl           | 9.38e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00228  |\n",
      "| loss/policy_loss        | -3.1e-06 |\n",
      "| loss/value_loss         | 0.12     |\n",
      "| misc/explained_variance | 0.0035   |\n",
      "| misc/nupdates           | 3.17e+03 |\n",
      "| misc/serial_timesteps   | 1.01e+05 |\n",
      "| misc/time_elapsed       | 341      |\n",
      "| misc/total_timesteps    | 1.01e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 356       |\n",
      "| loss/approxkl           | 6.28e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00164   |\n",
      "| loss/policy_loss        | -6.58e-07 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0.00486   |\n",
      "| misc/nupdates           | 3.18e+03  |\n",
      "| misc/serial_timesteps   | 1.02e+05  |\n",
      "| misc/time_elapsed       | 341       |\n",
      "| misc/total_timesteps    | 1.02e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.55     |\n",
      "| fps                     | 411      |\n",
      "| loss/approxkl           | 7.78e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.000882 |\n",
      "| loss/policy_loss        | 9.31e-10 |\n",
      "| loss/value_loss         | 0.131    |\n",
      "| misc/explained_variance | 0.000215 |\n",
      "| misc/nupdates           | 3.19e+03 |\n",
      "| misc/serial_timesteps   | 1.02e+05 |\n",
      "| misc/time_elapsed       | 342      |\n",
      "| misc/total_timesteps    | 1.02e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 385      |\n",
      "| loss/approxkl           | 1.03e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00127  |\n",
      "| loss/policy_loss        | 8.38e-09 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.2e+03  |\n",
      "| misc/serial_timesteps   | 1.02e+05 |\n",
      "| misc/time_elapsed       | 343      |\n",
      "| misc/total_timesteps    | 1.02e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.37      |\n",
      "| fps                     | 352       |\n",
      "| loss/approxkl           | 3.86e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00208   |\n",
      "| loss/policy_loss        | -7.19e-07 |\n",
      "| loss/value_loss         | 0.11      |\n",
      "| misc/explained_variance | -0.00555  |\n",
      "| misc/nupdates           | 3.21e+03  |\n",
      "| misc/serial_timesteps   | 1.03e+05  |\n",
      "| misc/time_elapsed       | 344       |\n",
      "| misc/total_timesteps    | 1.03e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 384      |\n",
      "| loss/approxkl           | 5.67e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00205  |\n",
      "| loss/policy_loss        | 7.03e-08 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.00105  |\n",
      "| misc/nupdates           | 3.22e+03 |\n",
      "| misc/serial_timesteps   | 1.03e+05 |\n",
      "| misc/time_elapsed       | 345      |\n",
      "| misc/total_timesteps    | 1.03e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 343      |\n",
      "| loss/approxkl           | 1.55e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00201  |\n",
      "| loss/policy_loss        | 2.04e-07 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 5.72e-05 |\n",
      "| misc/nupdates           | 3.23e+03 |\n",
      "| misc/serial_timesteps   | 1.03e+05 |\n",
      "| misc/time_elapsed       | 346      |\n",
      "| misc/total_timesteps    | 1.03e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 354       |\n",
      "| loss/approxkl           | 4.55e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00241   |\n",
      "| loss/policy_loss        | -1.01e-06 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0.00773   |\n",
      "| misc/nupdates           | 3.24e+03  |\n",
      "| misc/serial_timesteps   | 1.04e+05  |\n",
      "| misc/time_elapsed       | 347       |\n",
      "| misc/total_timesteps    | 1.04e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 374      |\n",
      "| loss/approxkl           | 9.88e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00289  |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.13     |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.25e+03 |\n",
      "| misc/serial_timesteps   | 1.04e+05 |\n",
      "| misc/time_elapsed       | 347      |\n",
      "| misc/total_timesteps    | 1.04e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 355       |\n",
      "| loss/approxkl           | 5.42e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00275   |\n",
      "| loss/policy_loss        | -1.86e-07 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | -0.0163   |\n",
      "| misc/nupdates           | 3.26e+03  |\n",
      "| misc/serial_timesteps   | 1.04e+05  |\n",
      "| misc/time_elapsed       | 348       |\n",
      "| misc/total_timesteps    | 1.04e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 331       |\n",
      "| loss/approxkl           | 3.99e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00187   |\n",
      "| loss/policy_loss        | -7.75e-07 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0.016     |\n",
      "| misc/nupdates           | 3.27e+03  |\n",
      "| misc/serial_timesteps   | 1.05e+05  |\n",
      "| misc/time_elapsed       | 349       |\n",
      "| misc/total_timesteps    | 1.05e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 338       |\n",
      "| loss/approxkl           | 1.43e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00219   |\n",
      "| loss/policy_loss        | -1.22e-06 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | -0.0141   |\n",
      "| misc/nupdates           | 3.28e+03  |\n",
      "| misc/serial_timesteps   | 1.05e+05  |\n",
      "| misc/time_elapsed       | 350       |\n",
      "| misc/total_timesteps    | 1.05e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 346       |\n",
      "| loss/approxkl           | 2e-10     |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00235   |\n",
      "| loss/policy_loss        | -9.31e-09 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.29e+03  |\n",
      "| misc/serial_timesteps   | 1.05e+05  |\n",
      "| misc/time_elapsed       | 351       |\n",
      "| misc/total_timesteps    | 1.05e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 367      |\n",
      "| loss/approxkl           | 6.03e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00313  |\n",
      "| loss/policy_loss        | 3.53e-07 |\n",
      "| loss/value_loss         | 0.128    |\n",
      "| misc/explained_variance | -0.00375 |\n",
      "| misc/nupdates           | 3.3e+03  |\n",
      "| misc/serial_timesteps   | 1.06e+05 |\n",
      "| misc/time_elapsed       | 352      |\n",
      "| misc/total_timesteps    | 1.06e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 350       |\n",
      "| loss/approxkl           | 9.82e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.000965  |\n",
      "| loss/policy_loss        | -1.17e-07 |\n",
      "| loss/value_loss         | 0.124     |\n",
      "| misc/explained_variance | 0.00581   |\n",
      "| misc/nupdates           | 3.31e+03  |\n",
      "| misc/serial_timesteps   | 1.06e+05  |\n",
      "| misc/time_elapsed       | 352       |\n",
      "| misc/total_timesteps    | 1.06e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.42      |\n",
      "| fps                     | 433       |\n",
      "| loss/approxkl           | 2.89e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00099   |\n",
      "| loss/policy_loss        | -1.21e-08 |\n",
      "| loss/value_loss         | 0.116     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.32e+03  |\n",
      "| misc/serial_timesteps   | 1.06e+05  |\n",
      "| misc/time_elapsed       | 353       |\n",
      "| misc/total_timesteps    | 1.06e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.5       |\n",
      "| fps                     | 354       |\n",
      "| loss/approxkl           | 1.39e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00113   |\n",
      "| loss/policy_loss        | -7.45e-09 |\n",
      "| loss/value_loss         | 0.125     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.33e+03  |\n",
      "| misc/serial_timesteps   | 1.07e+05  |\n",
      "| misc/time_elapsed       | 354       |\n",
      "| misc/total_timesteps    | 1.07e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.52      |\n",
      "| fps                     | 360       |\n",
      "| loss/approxkl           | 9.97e-13  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00101   |\n",
      "| loss/policy_loss        | -9.31e-10 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.34e+03  |\n",
      "| misc/serial_timesteps   | 1.07e+05  |\n",
      "| misc/time_elapsed       | 355       |\n",
      "| misc/total_timesteps    | 1.07e+05  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 351       |\n",
      "| loss/approxkl           | 1.74e-12  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00131   |\n",
      "| loss/policy_loss        | -5.63e-08 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0.0131    |\n",
      "| misc/nupdates           | 3.35e+03  |\n",
      "| misc/serial_timesteps   | 1.07e+05  |\n",
      "| misc/time_elapsed       | 356       |\n",
      "| misc/total_timesteps    | 1.07e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.55      |\n",
      "| fps                     | 345       |\n",
      "| loss/approxkl           | 1.78e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00128   |\n",
      "| loss/policy_loss        | -1.86e-09 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.36e+03  |\n",
      "| misc/serial_timesteps   | 1.08e+05  |\n",
      "| misc/time_elapsed       | 357       |\n",
      "| misc/total_timesteps    | 1.08e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 351      |\n",
      "| loss/approxkl           | 0.0032   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.00144  |\n",
      "| loss/policy_loss        | -0.00422 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | -0.00129 |\n",
      "| misc/nupdates           | 3.37e+03 |\n",
      "| misc/serial_timesteps   | 1.08e+05 |\n",
      "| misc/time_elapsed       | 357      |\n",
      "| misc/total_timesteps    | 1.08e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.44     |\n",
      "| fps                     | 394      |\n",
      "| loss/approxkl           | 7.17e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00115  |\n",
      "| loss/policy_loss        | 2.29e-07 |\n",
      "| loss/value_loss         | 0.122    |\n",
      "| misc/explained_variance | -0.00247 |\n",
      "| misc/nupdates           | 3.38e+03 |\n",
      "| misc/serial_timesteps   | 1.08e+05 |\n",
      "| misc/time_elapsed       | 358      |\n",
      "| misc/total_timesteps    | 1.08e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 346      |\n",
      "| loss/approxkl           | 7.28e-14 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.000596 |\n",
      "| loss/policy_loss        | 1.4e-08  |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0.0114   |\n",
      "| misc/nupdates           | 3.39e+03 |\n",
      "| misc/serial_timesteps   | 1.08e+05 |\n",
      "| misc/time_elapsed       | 359      |\n",
      "| misc/total_timesteps    | 1.08e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 422      |\n",
      "| loss/approxkl           | 2.91e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.000895 |\n",
      "| loss/policy_loss        | 2e-08    |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0.0121   |\n",
      "| misc/nupdates           | 3.4e+03  |\n",
      "| misc/serial_timesteps   | 1.09e+05 |\n",
      "| misc/time_elapsed       | 360      |\n",
      "| misc/total_timesteps    | 1.09e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 350      |\n",
      "| loss/approxkl           | 3.73e-13 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.000918 |\n",
      "| loss/policy_loss        | 2.79e-09 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | -0.00382 |\n",
      "| misc/nupdates           | 3.41e+03 |\n",
      "| misc/serial_timesteps   | 1.09e+05 |\n",
      "| misc/time_elapsed       | 361      |\n",
      "| misc/total_timesteps    | 1.09e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.51      |\n",
      "| fps                     | 349       |\n",
      "| loss/approxkl           | 4.8e-11   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00139   |\n",
      "| loss/policy_loss        | -2.78e-07 |\n",
      "| loss/value_loss         | 0.137     |\n",
      "| misc/explained_variance | -0.0188   |\n",
      "| misc/nupdates           | 3.42e+03  |\n",
      "| misc/serial_timesteps   | 1.09e+05  |\n",
      "| misc/time_elapsed       | 362       |\n",
      "| misc/total_timesteps    | 1.09e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.5      |\n",
      "| fps                     | 351      |\n",
      "| loss/approxkl           | 3.32e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0016   |\n",
      "| loss/policy_loss        | 2.79e-09 |\n",
      "| loss/value_loss         | 0.125    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.43e+03 |\n",
      "| misc/serial_timesteps   | 1.1e+05  |\n",
      "| misc/time_elapsed       | 363      |\n",
      "| misc/total_timesteps    | 1.1e+05  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.4      |\n",
      "| fps                     | 361      |\n",
      "| loss/approxkl           | 4.84e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00249  |\n",
      "| loss/policy_loss        | 1.04e-07 |\n",
      "| loss/value_loss         | 0.129    |\n",
      "| misc/explained_variance | -0.00494 |\n",
      "| misc/nupdates           | 3.44e+03 |\n",
      "| misc/serial_timesteps   | 1.1e+05  |\n",
      "| misc/time_elapsed       | 363      |\n",
      "| misc/total_timesteps    | 1.1e+05  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.49      |\n",
      "| fps                     | 357       |\n",
      "| loss/approxkl           | 7.81e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0026    |\n",
      "| loss/policy_loss        | -3.19e-07 |\n",
      "| loss/value_loss         | 0.131     |\n",
      "| misc/explained_variance | 0.00507   |\n",
      "| misc/nupdates           | 3.45e+03  |\n",
      "| misc/serial_timesteps   | 1.1e+05   |\n",
      "| misc/time_elapsed       | 364       |\n",
      "| misc/total_timesteps    | 1.1e+05   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.45     |\n",
      "| fps                     | 381      |\n",
      "| loss/approxkl           | 2.67e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00317  |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.46e+03 |\n",
      "| misc/serial_timesteps   | 1.11e+05 |\n",
      "| misc/time_elapsed       | 365      |\n",
      "| misc/total_timesteps    | 1.11e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 347      |\n",
      "| loss/approxkl           | 9.44e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00341  |\n",
      "| loss/policy_loss        | -1.3e-08 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | 0.00933  |\n",
      "| misc/nupdates           | 3.47e+03 |\n",
      "| misc/serial_timesteps   | 1.11e+05 |\n",
      "| misc/time_elapsed       | 366      |\n",
      "| misc/total_timesteps    | 1.11e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 352       |\n",
      "| loss/approxkl           | 3.34e-11  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00149   |\n",
      "| loss/policy_loss        | -1.15e-07 |\n",
      "| loss/value_loss         | 0.128     |\n",
      "| misc/explained_variance | 0.00678   |\n",
      "| misc/nupdates           | 3.48e+03  |\n",
      "| misc/serial_timesteps   | 1.11e+05  |\n",
      "| misc/time_elapsed       | 367       |\n",
      "| misc/total_timesteps    | 1.11e+05  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.42     |\n",
      "| fps                     | 344      |\n",
      "| loss/approxkl           | 1.33e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00167  |\n",
      "| loss/policy_loss        | -3e-07   |\n",
      "| loss/value_loss         | 0.119    |\n",
      "| misc/explained_variance | 0.0104   |\n",
      "| misc/nupdates           | 3.49e+03 |\n",
      "| misc/serial_timesteps   | 1.12e+05 |\n",
      "| misc/time_elapsed       | 368      |\n",
      "| misc/total_timesteps    | 1.12e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.59      |\n",
      "| fps                     | 319       |\n",
      "| loss/approxkl           | 2.27e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00144   |\n",
      "| loss/policy_loss        | -7.03e-08 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | -0.009    |\n",
      "| misc/nupdates           | 3.5e+03   |\n",
      "| misc/serial_timesteps   | 1.12e+05  |\n",
      "| misc/time_elapsed       | 369       |\n",
      "| misc/total_timesteps    | 1.12e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 342      |\n",
      "| loss/approxkl           | 7.23e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0029   |\n",
      "| loss/policy_loss        | 1.07e-06 |\n",
      "| loss/value_loss         | 0.138    |\n",
      "| misc/explained_variance | -0.00172 |\n",
      "| misc/nupdates           | 3.51e+03 |\n",
      "| misc/serial_timesteps   | 1.12e+05 |\n",
      "| misc/time_elapsed       | 369      |\n",
      "| misc/total_timesteps    | 1.12e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.43     |\n",
      "| fps                     | 347      |\n",
      "| loss/approxkl           | 2.41e-12 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0034   |\n",
      "| loss/policy_loss        | 1.86e-09 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.52e+03 |\n",
      "| misc/serial_timesteps   | 1.13e+05 |\n",
      "| misc/time_elapsed       | 370      |\n",
      "| misc/total_timesteps    | 1.13e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 335       |\n",
      "| loss/approxkl           | 1.76e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00362   |\n",
      "| loss/policy_loss        | -1.86e-09 |\n",
      "| loss/value_loss         | 0.126     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.53e+03  |\n",
      "| misc/serial_timesteps   | 1.13e+05  |\n",
      "| misc/time_elapsed       | 371       |\n",
      "| misc/total_timesteps    | 1.13e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.55     |\n",
      "| fps                     | 361      |\n",
      "| loss/approxkl           | 3.79e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00278  |\n",
      "| loss/policy_loss        | 3.91e-07 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0.00986  |\n",
      "| misc/nupdates           | 3.54e+03 |\n",
      "| misc/serial_timesteps   | 1.13e+05 |\n",
      "| misc/time_elapsed       | 372      |\n",
      "| misc/total_timesteps    | 1.13e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 357       |\n",
      "| loss/approxkl           | 1.32e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00485   |\n",
      "| loss/policy_loss        | -1.06e-06 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | -0.00124  |\n",
      "| misc/nupdates           | 3.55e+03  |\n",
      "| misc/serial_timesteps   | 1.14e+05  |\n",
      "| misc/time_elapsed       | 373       |\n",
      "| misc/total_timesteps    | 1.14e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 337       |\n",
      "| loss/approxkl           | 1.65e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00519   |\n",
      "| loss/policy_loss        | -7.52e-06 |\n",
      "| loss/value_loss         | 0.122     |\n",
      "| misc/explained_variance | -0.000224 |\n",
      "| misc/nupdates           | 3.56e+03  |\n",
      "| misc/serial_timesteps   | 1.14e+05  |\n",
      "| misc/time_elapsed       | 374       |\n",
      "| misc/total_timesteps    | 1.14e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 354       |\n",
      "| loss/approxkl           | 8.59e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00479   |\n",
      "| loss/policy_loss        | -9.31e-09 |\n",
      "| loss/value_loss         | 0.123     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.57e+03  |\n",
      "| misc/serial_timesteps   | 1.14e+05  |\n",
      "| misc/time_elapsed       | 375       |\n",
      "| misc/total_timesteps    | 1.14e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 351      |\n",
      "| loss/approxkl           | 2.03e-10 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00513  |\n",
      "| loss/policy_loss        | 0        |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.58e+03 |\n",
      "| misc/serial_timesteps   | 1.15e+05 |\n",
      "| misc/time_elapsed       | 376      |\n",
      "| misc/total_timesteps    | 1.15e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.39      |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 3.63e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00657   |\n",
      "| loss/policy_loss        | -1.28e-06 |\n",
      "| loss/value_loss         | 0.131     |\n",
      "| misc/explained_variance | -0.0239   |\n",
      "| misc/nupdates           | 3.59e+03  |\n",
      "| misc/serial_timesteps   | 1.15e+05  |\n",
      "| misc/time_elapsed       | 376       |\n",
      "| misc/total_timesteps    | 1.15e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 396       |\n",
      "| loss/approxkl           | 5.23e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00707   |\n",
      "| loss/policy_loss        | -9.31e-09 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.6e+03   |\n",
      "| misc/serial_timesteps   | 1.15e+05  |\n",
      "| misc/time_elapsed       | 377       |\n",
      "| misc/total_timesteps    | 1.15e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.46      |\n",
      "| fps                     | 352       |\n",
      "| loss/approxkl           | 8.59e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00956   |\n",
      "| loss/policy_loss        | -9.81e-07 |\n",
      "| loss/value_loss         | 0.12      |\n",
      "| misc/explained_variance | 0.0209    |\n",
      "| misc/nupdates           | 3.61e+03  |\n",
      "| misc/serial_timesteps   | 1.16e+05  |\n",
      "| misc/time_elapsed       | 378       |\n",
      "| misc/total_timesteps    | 1.16e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 351      |\n",
      "| loss/approxkl           | 1.03e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00398  |\n",
      "| loss/policy_loss        | 6.6e-07  |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | 0.0254   |\n",
      "| misc/nupdates           | 3.62e+03 |\n",
      "| misc/serial_timesteps   | 1.16e+05 |\n",
      "| misc/time_elapsed       | 379      |\n",
      "| misc/total_timesteps    | 1.16e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.44     |\n",
      "| fps                     | 344      |\n",
      "| loss/approxkl           | 2.97e-11 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00651  |\n",
      "| loss/policy_loss        | 3.82e-07 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | -0.0219  |\n",
      "| misc/nupdates           | 3.63e+03 |\n",
      "| misc/serial_timesteps   | 1.16e+05 |\n",
      "| misc/time_elapsed       | 380      |\n",
      "| misc/total_timesteps    | 1.16e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.53     |\n",
      "| fps                     | 321      |\n",
      "| loss/approxkl           | 5.3e-10  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00478  |\n",
      "| loss/policy_loss        | 4.89e-08 |\n",
      "| loss/value_loss         | 0.123    |\n",
      "| misc/explained_variance | 0.015    |\n",
      "| misc/nupdates           | 3.64e+03 |\n",
      "| misc/serial_timesteps   | 1.16e+05 |\n",
      "| misc/time_elapsed       | 381      |\n",
      "| misc/total_timesteps    | 1.16e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.43      |\n",
      "| fps                     | 401       |\n",
      "| loss/approxkl           | 1.18e-10  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00772   |\n",
      "| loss/policy_loss        | -6.52e-09 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0         |\n",
      "| misc/nupdates           | 3.65e+03  |\n",
      "| misc/serial_timesteps   | 1.17e+05  |\n",
      "| misc/time_elapsed       | 382       |\n",
      "| misc/total_timesteps    | 1.17e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.39      |\n",
      "| fps                     | 347       |\n",
      "| loss/approxkl           | 2.38e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00937   |\n",
      "| loss/policy_loss        | -1.29e-06 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | 0.0111    |\n",
      "| misc/nupdates           | 3.66e+03  |\n",
      "| misc/serial_timesteps   | 1.17e+05  |\n",
      "| misc/time_elapsed       | 382       |\n",
      "| misc/total_timesteps    | 1.17e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.44      |\n",
      "| fps                     | 350       |\n",
      "| loss/approxkl           | 3.7e-10   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0106    |\n",
      "| loss/policy_loss        | -8.17e-07 |\n",
      "| loss/value_loss         | 0.121     |\n",
      "| misc/explained_variance | 0.0195    |\n",
      "| misc/nupdates           | 3.67e+03  |\n",
      "| misc/serial_timesteps   | 1.17e+05  |\n",
      "| misc/time_elapsed       | 383       |\n",
      "| misc/total_timesteps    | 1.17e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.48     |\n",
      "| fps                     | 347      |\n",
      "| loss/approxkl           | 0.00543  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0166   |\n",
      "| loss/policy_loss        | -0.00367 |\n",
      "| loss/value_loss         | 0.132    |\n",
      "| misc/explained_variance | -0.00801 |\n",
      "| misc/nupdates           | 3.68e+03 |\n",
      "| misc/serial_timesteps   | 1.18e+05 |\n",
      "| misc/time_elapsed       | 384      |\n",
      "| misc/total_timesteps    | 1.18e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.48      |\n",
      "| fps                     | 350       |\n",
      "| loss/approxkl           | 4.22e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0244    |\n",
      "| loss/policy_loss        | -3.18e-06 |\n",
      "| loss/value_loss         | 0.127     |\n",
      "| misc/explained_variance | -0.00678  |\n",
      "| misc/nupdates           | 3.69e+03  |\n",
      "| misc/serial_timesteps   | 1.18e+05  |\n",
      "| misc/time_elapsed       | 385       |\n",
      "| misc/total_timesteps    | 1.18e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.45      |\n",
      "| fps                     | 353       |\n",
      "| loss/approxkl           | 1.58e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0255    |\n",
      "| loss/policy_loss        | -1.06e-06 |\n",
      "| loss/value_loss         | 0.13      |\n",
      "| misc/explained_variance | 0.0107    |\n",
      "| misc/nupdates           | 3.7e+03   |\n",
      "| misc/serial_timesteps   | 1.18e+05  |\n",
      "| misc/time_elapsed       | 386       |\n",
      "| misc/total_timesteps    | 1.18e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.38     |\n",
      "| fps                     | 343      |\n",
      "| loss/approxkl           | 0.00253  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0564   |\n",
      "| loss/policy_loss        | -0.00344 |\n",
      "| loss/value_loss         | 0.124    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.71e+03 |\n",
      "| misc/serial_timesteps   | 1.19e+05 |\n",
      "| misc/time_elapsed       | 387      |\n",
      "| misc/total_timesteps    | 1.19e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.49     |\n",
      "| fps                     | 337      |\n",
      "| loss/approxkl           | 1.06e-07 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0375   |\n",
      "| loss/policy_loss        | 5.59e-09 |\n",
      "| loss/value_loss         | 0.131    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.72e+03 |\n",
      "| misc/serial_timesteps   | 1.19e+05 |\n",
      "| misc/time_elapsed       | 387      |\n",
      "| misc/total_timesteps    | 1.19e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.42     |\n",
      "| fps                     | 443      |\n",
      "| loss/approxkl           | 1.51e-08 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0151   |\n",
      "| loss/policy_loss        | 2.79e-09 |\n",
      "| loss/value_loss         | 0.127    |\n",
      "| misc/explained_variance | 0        |\n",
      "| misc/nupdates           | 3.73e+03 |\n",
      "| misc/serial_timesteps   | 1.19e+05 |\n",
      "| misc/time_elapsed       | 388      |\n",
      "| misc/total_timesteps    | 1.19e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.41      |\n",
      "| fps                     | 337       |\n",
      "| loss/approxkl           | 1.05e-09  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0156    |\n",
      "| loss/policy_loss        | -9.89e-07 |\n",
      "| loss/value_loss         | 0.115     |\n",
      "| misc/explained_variance | 0.0115    |\n",
      "| misc/nupdates           | 3.74e+03  |\n",
      "| misc/serial_timesteps   | 1.2e+05   |\n",
      "| misc/time_elapsed       | 389       |\n",
      "| misc/total_timesteps    | 1.2e+05   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.47     |\n",
      "| fps                     | 346      |\n",
      "| loss/approxkl           | 2.24e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00547  |\n",
      "| loss/policy_loss        | 5.38e-07 |\n",
      "| loss/value_loss         | 0.126    |\n",
      "| misc/explained_variance | -0.00723 |\n",
      "| misc/nupdates           | 3.75e+03 |\n",
      "| misc/serial_timesteps   | 1.2e+05  |\n",
      "| misc/time_elapsed       | 390      |\n",
      "| misc/total_timesteps    | 1.2e+05  |\n",
      "--------------------------------------\n",
      "PPO Training Time: 391.60488200187683\n"
     ]
    }
   ],
   "source": [
    "def synthetic_ppo():\n",
    "    logger.configure(dir='./logs/synthetic_ppo', format_strs=['stdout', 'tensorboard'])\n",
    "    env = DummyVecEnv([lambda: bench.Monitor(SyntheticEnv(images_per_episode=1), logger.get_dir())])\n",
    "\n",
    "    model = ppo2.learn(\n",
    "        env=env,\n",
    "        network='mlp',\n",
    "        num_layers=2,\n",
    "        num_hidden=64,\n",
    "        nsteps=32,\n",
    "        total_timesteps=int(1.2e5),\n",
    "        seed=int(time.time()))\n",
    "\n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "ppo_model = synthetic_ppo()\n",
    "print('PPO Training Time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0be5c4e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2506171289.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27880\\2506171289.py\"\u001b[1;36m, line \u001b[1;32m27\u001b[0m\n\u001b[1;33m    len(test_df\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def synthetic_ppo_eval(ppo_model):\n",
    "    attempts, correct = 0,0\n",
    "\n",
    "    env = DummyVecEnv([lambda: SyntheticEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)])\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), [False]\n",
    "            while not done[0]:\n",
    "                obs, rew, done, info = env.step(ppo_model.step(obs[None])[0])\n",
    "                if done==True:\n",
    "                    test_df = test_df.append(info, ignore_index=True)\n",
    "\n",
    "                attempts += 1\n",
    "                if rew[0] > 0:\n",
    "                    correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "        \n",
    "    return test_df\n",
    "\n",
    "test_df = synthetic_ppo_eval(ppo_model)\n",
    "len(test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f44e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
