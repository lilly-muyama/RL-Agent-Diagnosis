{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1677aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484dae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tensorflow.set_random_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d5dc7",
   "metadata": {},
   "source": [
    "#### The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3296e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No anemia': 0, 'Hemolytic anemia': 1, 'Aplastic anemia': 2, 'Anemia of chronic disease': 3, 'Vitamin B12/Folate deficiency anemia': 4, 'Iron deficiency anemia': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((26868, 6), (11515, 6), (26868,), (11515,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/anemia_synth_dataset_hb_all_filled.csv')\n",
    "#df = df.fillna(0)\n",
    "classes = list(df.label.unique())\n",
    "nums = [i for i in range(len(classes))]\n",
    "class_dict = dict(zip(classes, nums))\n",
    "print(class_dict)\n",
    "df['label'] = df['label'].replace(class_dict)\n",
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cde9b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No anemia': 0,\n",
       " 'Hemolytic anemia': 1,\n",
       " 'Aplastic anemia': 2,\n",
       " 'Anemia of chronic disease': 3,\n",
       " 'Vitamin B12/Folate deficiency anemia': 4,\n",
       " 'Iron deficiency anemia': 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4901dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list = list(class_dict.keys()) + [col  for col in df.columns if col!='label']\n",
    "len(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6dbefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No anemia',\n",
       " 'Hemolytic anemia',\n",
       " 'Aplastic anemia',\n",
       " 'Anemia of chronic disease',\n",
       " 'Vitamin B12/Folate deficiency anemia',\n",
       " 'Iron deficiency anemia',\n",
       " 'hemoglobin',\n",
       " 'ferritin',\n",
       " 'ret_count',\n",
       " 'segmented_neutrophils',\n",
       " 'tibc',\n",
       " 'mcv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16438584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 11.55128149, 165.61991033,   2.08632925,   0.        ,\n",
       "         337.702133  ,  85.58910046],\n",
       "        [  7.69898656, 102.42397261,   5.69682422,   0.        ,\n",
       "         395.64137997,  97.83724111]]),\n",
       " array([[  5.26919057, 118.39007353,   5.6224956 ,   0.        ,\n",
       "         330.73798168,  90.15481781],\n",
       "        [  9.92410545, 131.97108935,   1.5471335 ,   0.        ,\n",
       "         355.67893564,  86.93198827]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2], X_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714feb3d",
   "metadata": {},
   "source": [
    "#### The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c9c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticEnv(Env):\n",
    "    def __init__(self, X, Y, random=True):\n",
    "        super(SyntheticEnv, self).__init__()\n",
    "        self.action_space = Discrete(14)\n",
    "        self.observation_space = Box(0, 1.5, (8,))\n",
    "        self.actions = list(class_dict.keys()) + [col  for col in df.columns if col!='label']\n",
    "        self.max_steps = 10\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.sample_num = len(X)\n",
    "        self.idx = -1\n",
    "        self.x = np.zeros((8,), dtype=np.float32)\n",
    "        self.y = np.nan\n",
    "        self.state = np.zeros((8,), dtype=np.float32)\n",
    "        self.num_classes = 6\n",
    "        self.episode_length = 0\n",
    "        self.trajectory = []\n",
    "        self.total_reward = 0\n",
    "        self.random = random\n",
    "        \n",
    "    \n",
    "    def step(self, action):\n",
    "#         print('A step in the environment')\n",
    "#         print(f'State: {self.state}')\n",
    "#         print(f'action: {action}')\n",
    "        self.episode_length += 1\n",
    "        reward = 0\n",
    "        if self.episode_length == self.max_steps: # episode too long\n",
    "            #print('Reached max steps')\n",
    "            reward -=1\n",
    "            self.total_reward -=1\n",
    "            terminated = True\n",
    "            done = True\n",
    "            y_actual = self.y\n",
    "            y_pred = np.nan\n",
    "            is_success = False\n",
    "        elif action < self.num_classes: #diagnosis (terminal action)\n",
    "            #print('Terminal action')\n",
    "            if action == self.y:\n",
    "                reward +=1\n",
    "                self.total_reward += 1\n",
    "                is_success = True\n",
    "            else:\n",
    "                reward -= 1\n",
    "                self.total_reward -= 1\n",
    "                is_success = False\n",
    "            terminated = False\n",
    "            done = True\n",
    "            y_actual = self.y\n",
    "            y_pred = action\n",
    "        elif self.actions[action] in self.trajectory: #action already picked \n",
    "            #print('Repeated action')\n",
    "            terminated = False\n",
    "            reward -= 1\n",
    "            self.total_reward -= 1\n",
    "            done = False\n",
    "            y_actual = np.nan\n",
    "            y_pred = np.nan\n",
    "            is_success = None\n",
    "        else: #new feature being acquired\n",
    "            #print('Acquiring new feature')\n",
    "            terminated = False\n",
    "            reward += 1\n",
    "            self.total_reward += 1\n",
    "            done = False\n",
    "            self.state = self.get_next_state(action-self.num_classes)\n",
    "            y_actual = np.nan\n",
    "            y_pred = np.nan\n",
    "            is_success = None\n",
    "        self.trajectory.append(self.actions[action])\n",
    "        info = {'index': self.idx, 'episode_length':self.episode_length, 'reward': self.total_reward, 'y_pred': y_pred, \n",
    "                'y_actual': y_actual, 'trajectory':self.trajectory, 'terminated':terminated, 'is_success': is_success}\n",
    "#         print(f'next state:{self.state}')\n",
    "#         print(f'reward: {reward}')\n",
    "#         print(f'done: {done}')\n",
    "#         print(f'info: {info}')\n",
    "        return self.state, reward, done, info\n",
    "            \n",
    "    \n",
    "    def render(self):\n",
    "        print(f'STEP {self.episode_length} for index {self.idx}')\n",
    "        #print(f'x: {self.x}')\n",
    "        #print(f'y: {self.y}')\n",
    "        print(f'Current state: {self.state}')\n",
    "        print(f'Total reward: {self.total_reward}')\n",
    "        print(f'Trajectory: {self.trajectory}')\n",
    "        \n",
    "            \n",
    "    \n",
    "    def reset(self):\n",
    "        #print('RESETTING THE ENVIRONMENT')\n",
    "        if self.random:\n",
    "            self.idx = random.randint(0, self.sample_num-1)\n",
    "        else:\n",
    "            self.idx += 1\n",
    "            if self.idx == len(self.X):\n",
    "                raise StopIteration()\n",
    "        #print(f'New index: {self.idx}')\n",
    "        #print(f'New idx: {self.idx}')\n",
    "        self.x, self.y = self.X[self.idx], self.Y[self.idx]\n",
    "        #print(f'New x: {self.x}')\n",
    "        #print(f'New y: {self.y}')\n",
    "        self.state = np.zeros((8,), dtype=np.float32)\n",
    "        #print(f'New state: {self.state}')\n",
    "        self.trajectory = []\n",
    "        #print(f'New trajectory: {self.trajectory}')\n",
    "        self.episode_length = 0\n",
    "        #print(f'New episode length: {self.episode_length}')\n",
    "        self.total_reward = 0\n",
    "        #print(f'New total reward: {self.total_reward}')\n",
    "        return self.state\n",
    "        \n",
    "    \n",
    "    def get_next_state(self, feature_idx):\n",
    "        self.x = self.x.reshape(-1, 8)\n",
    "        x_value = self.x[0, feature_idx]\n",
    "        next_state = copy.deepcopy(self.state)\n",
    "        next_state[feature_idx] = x_value\n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_env = SyntheticEnv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fe115",
   "metadata": {},
   "source": [
    "#### The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines import bench, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da20e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_dqn():\n",
    "    env = SyntheticEnv(X_train, y_train)\n",
    "    env = bench.Monitor(env, logger.get_dir())\n",
    "    model = DQN('MlpPolicy', training_env, verbose=1, seed=SEED, n_cpu_tf_sess=1)\n",
    "    model.learn(total_timesteps=int(1.8e6), log_interval=10000)\n",
    "    #model.learn(total_timesteps=int(1.2e5), log_interval=10000)\n",
    "    #model.save('models/synthetic_stable_dqn_1.8.pkl')\n",
    "    model.save('models/synthentic_with_random_stable_dqn_18.pkl')\n",
    "    env.close()\n",
    "    return model\n",
    "\n",
    "dqn_model = stable_dqn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e1a11",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0418bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass(actual_class, pred_class, average = 'macro'):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    avg = sum(roc_auc_dict.values()) / len(roc_auc_dict)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f408d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ytest, ypred):\n",
    "    acc = accuracy_score(ytest, ypred)\n",
    "    f1 = f1_score(ytest, ypred, average ='macro', labels=np.unique(ytest))\n",
    "    try:\n",
    "        roc_auc = multiclass(ytest, ypred)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    return acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_length_reward(df):\n",
    "    length = np.mean(df.episode_length)\n",
    "    reward = np.mean(df.reward)\n",
    "    return length, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    env = SyntheticEnv(X_test, y_test, random=False)\n",
    "    count=0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            count+=1\n",
    "            if count%5000==0:\n",
    "                print(f'Count: {count}')\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                action, _states = dqn_model.predict(obs, deterministic=True)\n",
    "                obs, rew, done,info = env.step(action)\n",
    "                #if (done==True) & (np.isfinite(info['y_pred'])):\n",
    "                if done == True:\n",
    "                    test_df = test_df.append(info, ignore_index=True)\n",
    "                #print('....................TEST DF ....................')\n",
    "                #if len(test_df) != 0:\n",
    "                #    print(test_df.head())\n",
    "\n",
    "    except StopIteration:\n",
    "        print('Testing done.....')\n",
    "    return test_df\n",
    "\n",
    "test_df = synthetic_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ccf0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = test_df[test_df['y_pred'].notna()]\n",
    "success_df = y_pred_df[y_pred_df['y_pred']== y_pred_df['y_actual']]\n",
    "len(success_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dccb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('test_dfs/test_df_with_random_1.8e6.csv', index=False)\n",
    "y_pred_df.to_csv('test_dfs/y_pred_df_with_random_1.8e6.csv', index=False)\n",
    "success_df.to_csv('test_dfs/success_df_with_random_1.8e6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df.y_pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b94d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df.y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df.y_actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae641e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate = len(success_df)/len(test_df)*100\n",
    "success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860cb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg length and return \n",
    "avg_length, avg_return = get_avg_length_reward(test_df)\n",
    "avg_length, avg_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, f1, roc_auc = test(y_pred_df['y_actual'], y_pred_df['y_pred'])\n",
    "acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f03ed",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, save=False, filename=False):\n",
    "    cm_df = pd.DataFrame(cm, index = [0, 1, 2, 3, 4, 5], columns = [0, 1, 2, 3, 4, 5])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Anemia')\n",
    "    plt.xlabel('Predicted Anemia')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ada69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_pred_df['y_actual'], y_pred_df['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    inch = 2.54\n",
    "    if type(tupl[0]) == tuple:\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf01b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values(pc, fmt=\"%.2f\", **kw):    \n",
    "    pc.update_scalarmappable()\n",
    "    ax = pc.axes\n",
    "    for p, color, value in zip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.all(color[:3] > 0.5):\n",
    "            color = (0.0, 0.0, 0.0)\n",
    "        else:\n",
    "            color = (1.0, 1.0, 1.0)\n",
    "        ax.text(x, y, fmt % value, ha=\"center\", va=\"center\", color=color, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(AUC, title, xlabel, ylabel, xticklabels, yticklabels, figure_width=40, figure_height=20, correct_orientation=False, cmap='RdBu'):\n",
    "    fig, ax = plt.subplots()    \n",
    "    c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap=cmap)\n",
    "    ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_xticklabels(xticklabels, minor=False)\n",
    "    ax.set_yticklabels(yticklabels, minor=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)      \n",
    "\n",
    "    # Remove last blank column\n",
    "    plt.xlim( (0, AUC.shape[1]) )\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()    \n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    # Add color bar\n",
    "    plt.colorbar(c)\n",
    "\n",
    "    # Add text in each cell \n",
    "    show_values(c)\n",
    "\n",
    "    # Proper orientation (origin at the top left instead of bottom left)\n",
    "    if correct_orientation:\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.tick_top()       \n",
    "\n",
    "    # resize \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(cm2inch(figure_width, figure_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(classification_report, save=False, filename=False, cmap='RdBu'):\n",
    "    lines = classification_report.split('\\n')\n",
    "    class_names = list(class_dict.keys())\n",
    "    plotMat = []\n",
    "    support = []\n",
    "    #class_names = []\n",
    "    #count = 0\n",
    "    for line in lines[2 : (len(lines) - 5)]:\n",
    "        t = line.strip().split()\n",
    "        if len(t) < 2: continue\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        support.append(int(t[-1]))\n",
    "        plotMat.append(v)\n",
    "\n",
    "    xlabel = 'Metrics'\n",
    "    ylabel = 'Classes'\n",
    "    xticklabels = ['Precision', 'Recall', 'F1-score']\n",
    "    ytick_labels = [f'{class_names[i]}({sup})' for i, sup in enumerate(support) ]\n",
    "    \n",
    "    #print(len(support))\n",
    "    yticklabels = ['{0} ({1})'.format(class_names[idx], sup) for idx, sup  in enumerate(support)]\n",
    "    figure_width = 25\n",
    "    figure_height = len(class_names) + 7\n",
    "    correct_orientation = False\n",
    "    heatmap(np.array(plotMat), 'classification report', xlabel, ylabel, xticklabels, yticklabels, figure_width, figure_height, correct_orientation, cmap=cmap)\n",
    "    #plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(filename, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_pred_df['y_actual'], y_pred_df['y_pred'])\n",
    "plot_classification_report(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75541d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[2734]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460be331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#episodes that are misdiagnosed\n",
    "non_success_df = y_pred_df[y_pred_df['y_pred']!= y_pred_df['y_actual']]\n",
    "non_success_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6258f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_success_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31937442",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_non_succ_df = non_success_df[non_success_df.y_pred==1]\n",
    "b_non_succ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_non_succ_df = non_success_df[non_success_df.y_pred==2]\n",
    "c_non_succ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679be41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb007fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
