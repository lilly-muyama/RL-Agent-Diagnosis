{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3553eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import gym\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b0b99",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3545388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "input_shape = (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42a0686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset_10000.csv')\n",
    "class_dict = {'A':0, 'B':1, 'C':2}\n",
    "df['label'] = df['label'].replace(class_dict)\n",
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "#X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "#X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea5f6cc",
   "metadata": {},
   "source": [
    "#### The gym env subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afec146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticEnv2(gym.Env):\n",
    "    def __init__(self, data=(X_train, y_train)):\n",
    "        print('Instantiating environment')\n",
    "        super().__init__()\n",
    "        self.action_space = gym.spaces.Discrete(6)\n",
    "        #self.observation_space = gym.spaces.Box(low=0, high=1, shape=(1, 3), dtype=np.float32)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(3,), dtype=np.float32)\n",
    "        self.step_count = 0\n",
    "        self.X, self.Y = data\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "        #self.x, self.y = self.X[self.dataset_idx].reshape(-1, 3), self.Y[self.dataset_idx]\n",
    "        self.x, self.y = self.X[self.dataset_idx], self.Y[self.dataset_idx]\n",
    "        self.state = np.zeros((1, 3), dtype=np.float32)\n",
    "        #self.available_actions = np.zeros((1, 6), dtype=np.float32)\n",
    "        self.total_reward = 0\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        print('Resetting environment')\n",
    "        random.seed(42)\n",
    "        self.step_count = 0\n",
    "        self.total_reward = 0\n",
    "        self.state = np.zeros((1, 3), dtype=np.float32)\n",
    "        #self.available_actions = np.zeros((1,6), dtype=np.float32)\n",
    "        self.dataset_idx = random.randint(0, len(self.X)-1)\n",
    "        self.x, self.y = self.X[self.dataset_idx], self.Y[self.dataset_idx]\n",
    "        \n",
    "        return self.state\n",
    "        \n",
    "    \n",
    "    def render(self):\n",
    "        print(f': Current state of the environment: {self.state}')\n",
    "        #print(f'Available actions: {self.available_actions}')\n",
    "    \n",
    "    def step(self, action):\n",
    "        print('A step in the environment')\n",
    "        self.step_count += 1\n",
    "        if action < 3:\n",
    "            done = True\n",
    "            next_state = None\n",
    "            reward = int(action == self.y)\n",
    "            y_actual = self.y\n",
    "            y_pred = action\n",
    "        else:\n",
    "            done = False\n",
    "            next_state = self._get_next_state(action)\n",
    "            reward = 0\n",
    "            y_actual = np.nan\n",
    "            y_pred = np.nan\n",
    "        self.total_reward += reward\n",
    "        info = {'episode_length':self.step_count, 'total_reward': self.total_reward, 'y_actual':y_actual, 'y_pred': y_pred}\n",
    "        print(f'current_state:{self.state}')\n",
    "        print(f'next_state: {next_state}')\n",
    "        print(f'reward: {reward}')\n",
    "        print(f'Done: {done}')\n",
    "        print(f'Info: {info}')\n",
    "        return next_state, reward, done, info\n",
    "    \n",
    "    def _get_next_state(self, action): #_next_obs\n",
    "        print('Getting tenext state in the environment')\n",
    "        #self.available_actions[0, action] = 1\n",
    "        feature_idx = action - 3\n",
    "        self.x = self.x.reshape(-1, 3)\n",
    "        x_value = self.x[0, feature_idx]\n",
    "        next_state = copy.deepcopy(self.state)\n",
    "        next_state[0, feature_idx] = x_value\n",
    "        #print(f'Next state: {next_state}')\n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ba9ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.ppo2 import ppo2\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "from baselines import bench\n",
    "from baselines import logger\n",
    "from baselines import deepq\n",
    "from baselines.common.tf_util import make_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4682b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/synthetic_dqn2\n",
      "Instantiating environment\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\models.py:94: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 98       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 200      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 8, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 9, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 401      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 7, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 7, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 757      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 8, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 9, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 8, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 92       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 939      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 7, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.12e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 8, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 9, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.31e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 8, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 87       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.48e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.65e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 8, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 9, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 10, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 11, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 84       |\n",
      "| episodes                | 1e+03    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.82e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 1.1e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.98e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 1.2e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2.15e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 1.3e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2.32e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 8, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 8, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 9, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 1.4e+03  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.51e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 77       |\n",
      "| episodes                | 1.5e+03  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2.68e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 7, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 1.6e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2.86e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 1.7e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3.01e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 8, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 73       |\n",
      "| episodes                | 1.8e+03  |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3.19e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 1.9e+03  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.34e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 2e+03    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.52e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 2.1e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3.66e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 68       |\n",
      "| episodes                | 2.2e+03  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3.82e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 2.3e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3.95e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 66       |\n",
      "| episodes                | 2.4e+03  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4.12e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 2.5e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.25e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 2.6e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.4e+03  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 2.7e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.55e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 7, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 2.8e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.71e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 2.9e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.85e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 3e+03    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4.99e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 3.1e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.14e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 56       |\n",
      "| episodes                | 3.2e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.28e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 3.3e+03  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 5.43e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 54       |\n",
      "| episodes                | 3.4e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.56e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 3.5e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.7e+03  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 3.6e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.85e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 6, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 7, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 3.7e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5.99e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 3.8e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6.12e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 3.9e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6.25e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 47       |\n",
      "| episodes                | 4e+03    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6.38e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 4.1e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6.51e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 4.2e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6.64e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 4.3e+03  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 6.76e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 4.4e+03  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6.89e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 42       |\n",
      "| episodes                | 4.5e+03  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 7.01e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 4.6e+03  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 7.15e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 39       |\n",
      "| episodes                | 4.7e+03  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 7.28e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 4.8e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7.4e+03  |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 37       |\n",
      "| episodes                | 4.9e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7.53e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 36       |\n",
      "| episodes                | 5e+03    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7.65e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 5.1e+03  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 7.77e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 5.2e+03  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 7.9e+03  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 5, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 5.3e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8.03e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 5.4e+03  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 8.14e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 5.5e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8.27e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 5.6e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8.4e+03  |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 5.7e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8.52e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 28       |\n",
      "| episodes                | 5.8e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8.63e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 5.9e+03  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 8.76e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 6e+03    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8.88e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 25       |\n",
      "| episodes                | 6.1e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8.99e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 6.2e+03  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.1e+03  |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 6.3e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9.21e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 23       |\n",
      "| episodes                | 6.4e+03  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.33e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 6.5e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9.44e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 21       |\n",
      "| episodes                | 6.6e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9.56e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 6.7e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9.67e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 3, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 4, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 6.8e+03  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.79e+03 |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 18       |\n",
      "| episodes                | 6.9e+03  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9.9e+03  |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.78571427 0.         0.        ]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0.        0.        0.4387755]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "Getting tenext state in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: [[0. 0. 0.]]\n",
      "reward: 0\n",
      "Done: False\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': nan, 'y_pred': nan}\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 2, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 0\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 0, 'y_actual': 0, 'y_pred': 1}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 7e+03    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1e+04    |\n",
      "--------------------------------------\n",
      "A step in the environment\n",
      "current_state:[[0. 0. 0.]]\n",
      "next_state: None\n",
      "reward: 1\n",
      "Done: True\n",
      "Info: {'episode_length': 1, 'total_reward': 1, 'y_actual': 0, 'y_pred': 0}\n",
      "Resetting environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\deepq\\replay_buffer.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(obses_t), np.array(actions), np.array(rewards), np.array(obses_tp1), np.array(dones)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 32 into shape (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16900\\12458474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mdqn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msynthetic_dqn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DQN Training Time:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16900\\12458474.py\u001b[0m in \u001b[0;36msynthetic_dqn2\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mtrain_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mlearning_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mtarget_network_update_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\deepq\\deepq.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(env, network, seed, lr, total_timesteps, buffer_size, exploration_fraction, exploration_final_eps, train_freq, batch_size, print_freq, checkpoint_freq, checkpoint_path, learning_starts, gamma, target_network_update_freq, prioritized_replay, prioritized_replay_alpha, prioritized_replay_beta0, prioritized_replay_beta_iters, prioritized_replay_eps, param_noise, callback, load_path, **network_kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m                     \u001b[0mobses_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobses_tp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                     \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                 \u001b[0mtd_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobses_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobses_tp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mprioritized_replay\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mnew_priorities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtd_errors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprioritized_replay_eps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\tf_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgivens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgivens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\tf_util.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;31m# Update the args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minpt_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minpt_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\tf_util.py\u001b[0m in \u001b[0;36m_feed_input\u001b[1;34m(self, feed_dict, inpt, value)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_feed_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'make_feed_dict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_feed_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minpt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madjust_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\deepq\\utils.py\u001b[0m in \u001b[0;36mmake_feed_dict\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_feed_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_placeholder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0madjust_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_placeholder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\tf_util.py\u001b[0m in \u001b[0;36madjust_shape\u001b[1;34m(placeholder, data)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;34m'Shape of data {} is not compatible with shape of the placeholder {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaceholder_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaceholder_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    296\u001b[0m            [5, 6]])\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 32 into shape (3)"
     ]
    }
   ],
   "source": [
    "def synthetic_dqn2():\n",
    "    logger.configure(dir='./logs/synthetic_dqn2', format_strs=['stdout', 'tensorboard'])\n",
    "    env = SyntheticEnv2()\n",
    "    env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "    model = deepq.learn(\n",
    "        env,\n",
    "        'mlp',\n",
    "        num_layers=3, #change number of layers\n",
    "        num_hidden=64,\n",
    "        activation=tf.nn.relu,\n",
    "        hiddens=[32],\n",
    "        dueling=False, \n",
    "        lr=1e-4,\n",
    "        total_timesteps=int(1.2e5),\n",
    "        buffer_size=10000,\n",
    "        exploration_fraction=0.1,\n",
    "        exploration_final_eps=0.01,\n",
    "        train_freq=4,\n",
    "        learning_starts=10000,\n",
    "        target_network_update_freq=1000,\n",
    "    )\n",
    "\n",
    "    model.save('models/dqn_synth2_real.pkl')\n",
    "    env.close()\n",
    "\n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "dqn_model = synthetic_dqn2()\n",
    "print(\"DQN Training Time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172e2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
