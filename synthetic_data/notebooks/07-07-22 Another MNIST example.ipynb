{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c151694e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "#import keras\n",
    "#from keras import layers\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fc0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.ppo2 import ppo2\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "from baselines import bench\n",
    "from baselines import logger\n",
    "from baselines import deepq\n",
    "from baselines.common.tf_util import make_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09901a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be539b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690b8913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545f6036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f862bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65dff119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94ae2925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c510de54",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: Tensor(\"input_7:0\", shape=(?, 28, 28, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_304\\957166053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training Time:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mkeras_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_304\\957166053.py\u001b[0m in \u001b[0;36mkeras_train\u001b[1;34m(batch_size, epochs)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         ]\n\u001b[0;32m     13\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m       \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m       \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    143\u001b[0m       raise TypeError('The added layer must be '\n\u001b[0;32m    144\u001b[0m                       \u001b[1;34m'an instance of class Layer. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                       'Found: ' + str(layer))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: Tensor(\"input_7:0\", shape=(?, 28, 28, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Baseline model traditional supervise learning uing NN classifier\n",
    "def keras_train(batch_size=32, epochs=2):\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            #keras.InputLayer(input_shape=input_shape),\n",
    "            #model.add(InputLayer(input_shape=shape, name=name))\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train_one_hot, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "    end_time = time.time()\n",
    "\n",
    "    score = model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print('Training Time:', end_time - start_time)\n",
    "\n",
    "keras_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a41f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(10)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1,\n",
    "                                                shape=(28, 28, 1),\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y[next_obs_idx])\n",
    "            obs = self.x[next_obs_idx]\n",
    "\n",
    "        else:\n",
    "            obs = self.x[self.dataset_idx]\n",
    "            self.expected_action = int(self.y[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e449a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/mnist_dqn\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\baselines\\common\\models.py:94: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 99       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 98       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 98       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 198      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 97       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 298      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 398      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 498      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 598      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 94       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 698      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 798      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 92       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 898      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 91       |\n",
      "| episodes                | 1e+03    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 998      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1.1e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1.2e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 1.3e+03  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 1.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 88       |\n",
      "| episodes                | 1.4e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 87       |\n",
      "| episodes                | 1.5e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 1.6e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 1.7e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 1.8e+03  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 1.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 84       |\n",
      "| episodes                | 1.9e+03  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 2e+03    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 2.1e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2.2e+03  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 2.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2.3e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2.4e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 2.5e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 2.6e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 77       |\n",
      "| episodes                | 2.7e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 2.8e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 2.9e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 3e+03    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 3e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 74       |\n",
      "| episodes                | 3.1e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 3.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 73       |\n",
      "| episodes                | 3.2e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 3.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3.3e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 3.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3.4e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 3.4e+03  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3.5e+03  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 3.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3.6e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 3.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 3.7e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 3.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 68       |\n",
      "| episodes                | 3.8e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 3.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 3.9e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 3.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 4e+03    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 4e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 66       |\n",
      "| episodes                | 4.1e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 4.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 4.2e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 4.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 4.3e+03  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 4.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4.4e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 4.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4.5e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 4.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4.6e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 4.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4.7e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 4.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4.8e+03  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 4.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 4.9e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 4.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 5e+03    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 5e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 5.1e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 5.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 5.2e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 5.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 56       |\n",
      "| episodes                | 5.3e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 5.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 5.4e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 5.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 54       |\n",
      "| episodes                | 5.5e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 5.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5.6e+03  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 5.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5.7e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 5.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5.8e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 5.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5.9e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 5.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 6e+03    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 6.1e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 6.2e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 6.3e+03  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 6.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 47       |\n",
      "| episodes                | 6.4e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 6.5e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 6.6e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6.7e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6.8e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6.9e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 6.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 42       |\n",
      "| episodes                | 7e+03    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7e+03    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 7.1e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 7.2e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 39       |\n",
      "| episodes                | 7.3e+03  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 7.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 7.4e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 7.5e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 37       |\n",
      "| episodes                | 7.6e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 36       |\n",
      "| episodes                | 7.7e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7.8e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 7.9e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 8e+03    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 8.1e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 8.2e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 8.3e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 8.4e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 8.5e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 8.6e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 28       |\n",
      "| episodes                | 8.7e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 8.8e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8.9e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 25       |\n",
      "| episodes                | 9e+03    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 9e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 9.1e+03  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 9.1e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 9.2e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 9.2e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 23       |\n",
      "| episodes                | 9.3e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 9.3e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 9.4e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 9.4e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 21       |\n",
      "| episodes                | 9.5e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 9.5e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 9.6e+03  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 9.6e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 9.7e+03  |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 9.7e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 9.8e+03  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 9.8e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 18       |\n",
      "| episodes                | 9.9e+03  |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 9.9e+03  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 1e+04    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 1.01e+04 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 15       |\n",
      "| episodes                | 1.02e+04 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 15       |\n",
      "| episodes                | 1.03e+04 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 1.04e+04 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 13       |\n",
      "| episodes                | 1.05e+04 |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 1.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 1.06e+04 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.06e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 11       |\n",
      "| episodes                | 1.07e+04 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 1.08e+04 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 1.09e+04 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 1.1e+04  |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 1.11e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 1.12e+04 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 1.13e+04 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1.14e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 1.15e+04 |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 1.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 4        |\n",
      "| episodes                | 1.16e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 1.17e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1.18e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+04 |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+04  |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 1.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.21e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.22e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.23e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.24e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.25e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.26e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.27e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.28e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.29e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.3e+04  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.31e+04 |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.32e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.33e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.34e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.35e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.36e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.37e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.38e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.39e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.4e+04  |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.41e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.42e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.42e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.43e+04 |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.44e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.45e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.46e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.47e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.48e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.49e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.5e+04  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.51e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.52e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.53e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.54e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.55e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.56e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.57e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.58e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.59e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.6e+04  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.61e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.62e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.63e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.64e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.65e+04 |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.66e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.67e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.68e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.69e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.7e+04  |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.71e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.72e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.73e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.74e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.75e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.76e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.77e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.78e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.78e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.79e+04 |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.8e+04  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.81e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.82e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.83e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.84e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.85e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.86e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.87e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.88e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.89e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.9e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.91e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.92e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.93e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.94e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.95e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.96e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.97e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.98e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.99e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2e+04    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2e+04    |\n",
      "--------------------------------------\n",
      "Saving model due to mean reward increase: None -> 0.8\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.01e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.02e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.03e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.04e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.05e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.06e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.07e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.08e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.09e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.1e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.11e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.12e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.13e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.13e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.14e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.15e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.16e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.17e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.18e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.19e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.2e+04  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.21e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.22e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.23e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.24e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.25e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.26e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.27e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.28e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.29e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.3e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.31e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.32e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.33e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.34e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.35e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.36e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.37e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.38e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.39e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.4e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.41e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.42e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.43e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.44e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.45e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.46e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.47e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.48e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.49e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.49e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.5e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.51e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.52e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.53e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.54e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.55e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.56e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.57e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.58e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.59e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.6e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.61e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.62e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.63e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.64e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.65e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.66e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.67e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.68e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.69e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 2.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.7e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.71e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.72e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.73e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.74e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.75e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.76e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.77e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.78e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.79e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.8e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.81e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.82e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.83e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.84e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.85e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.85e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.86e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.87e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.88e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.89e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.9e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 2.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.91e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.92e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.93e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.94e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.95e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.96e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.97e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.98e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 2.99e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3e+04    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3e+04    |\n",
      "--------------------------------------\n",
      "Saving model due to mean reward increase: 0.8 -> 0.9\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.01e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.02e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.03e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.04e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.05e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.06e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.07e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.08e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.09e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.1e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.11e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.12e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.13e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.14e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.15e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.16e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.17e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.18e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.19e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.2e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.2e+04  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.21e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.22e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.23e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.24e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.25e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.26e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.27e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.28e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.29e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.3e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.31e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.32e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.33e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.34e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.35e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.36e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.37e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.38e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.39e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.4e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.41e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.42e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.43e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.44e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.45e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.46e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.47e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.48e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.49e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.5e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.51e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.52e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.53e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.54e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.55e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.56e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.56e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.57e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.58e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.59e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.6e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.61e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.62e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.63e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.64e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.65e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.66e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.67e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.68e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.69e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.7e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.71e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.72e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.73e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.74e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.75e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.76e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.77e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.78e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.79e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.8e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.81e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.82e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.83e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.84e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.85e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.86e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.87e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.88e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.89e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.9e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.91e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.92e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.92e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.93e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.94e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.95e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.96e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.97e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.98e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 3.99e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4e+04    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.01e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.02e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.03e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.04e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.05e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.06e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.07e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.08e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.09e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.1e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.11e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.12e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.13e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.14e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.15e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.16e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.17e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.18e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.19e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.2e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.21e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.22e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.23e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.24e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.25e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.26e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.27e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.28e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.28e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.29e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.3e+04  |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.31e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.32e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.33e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.34e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.35e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.36e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.37e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.38e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.39e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.4e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.41e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.42e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.43e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.44e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.45e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.46e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.47e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.48e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.49e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.5e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.51e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.52e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.53e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.54e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.55e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.56e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.57e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.58e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.59e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.6e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.61e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.62e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.63e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.64e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.64e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.65e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.66e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.67e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.68e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.69e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.7e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.71e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.72e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.73e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.74e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.75e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.76e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.77e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.78e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.79e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.8e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.81e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.82e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.83e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.84e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.85e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.86e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.87e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.88e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.89e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.9e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.91e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.92e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.93e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.94e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.95e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.96e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.97e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.98e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 4.99e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5e+04    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5e+04    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.01e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.02e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.03e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.04e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.05e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.06e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.07e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.08e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.09e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.1e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.11e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.12e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.13e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.14e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.15e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.16e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.17e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.18e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.19e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.2e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.21e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.22e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.23e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.24e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.25e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.26e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.27e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.28e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.29e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.3e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.31e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.32e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.33e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.34e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.35e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.36e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.36e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.37e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.38e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.39e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.4e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.41e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.42e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.43e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.44e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.45e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.46e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.47e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.48e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.49e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.5e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.51e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.52e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.53e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.54e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.55e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.56e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.57e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.58e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.59e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.6e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.61e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.62e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.63e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.64e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.65e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.66e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.67e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.68e+04 |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.69e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.7e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.71e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.72e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.72e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.73e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.74e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.75e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.76e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.77e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.78e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.79e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.8e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.81e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.82e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.83e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.84e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.85e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.86e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.87e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.88e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.89e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.9e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.91e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.92e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.93e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.94e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.95e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.96e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.97e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.98e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 5.99e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6e+04    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.01e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.02e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.03e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.04e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.05e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.06e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.07e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.08e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.08e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.09e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.1e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.11e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.12e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.13e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.14e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.15e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.16e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.17e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.18e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.19e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.2e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.21e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.22e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.23e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.24e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.25e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.26e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.27e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.28e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.29e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.3e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.31e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.32e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.33e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.34e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.35e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.36e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.37e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.38e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.39e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.4e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.41e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.42e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.43e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.44e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.44e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.45e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.46e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.47e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.48e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.49e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.5e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.51e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.52e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.53e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.54e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.55e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.56e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.57e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.58e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.59e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.6e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.61e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.62e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.63e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.64e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.65e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.66e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.67e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.68e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.69e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.7e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.71e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.72e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.73e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.74e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.75e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.76e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.77e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.78e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.79e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.8e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.8e+04  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.81e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.82e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.83e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.84e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.85e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.86e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.87e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.88e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.89e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.9e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.91e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.92e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.93e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.94e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.95e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.96e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.97e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.98e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 6.99e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7e+04    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7e+04    |\n",
      "--------------------------------------\n",
      "Saving model due to mean reward increase: 0.9 -> 1.0\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.01e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.02e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.03e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.04e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.05e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.06e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.07e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.08e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.09e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.1e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.11e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.12e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.13e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.14e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.15e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.15e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.16e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.17e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.18e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.19e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.2e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.21e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.22e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.23e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.24e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.25e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.26e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.27e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.28e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.29e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.3e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.31e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.32e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.33e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.34e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.35e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.36e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.37e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.38e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.39e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.4e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.41e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.42e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.43e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.44e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.45e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.46e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.47e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.48e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.49e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.5e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.51e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.51e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.52e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.53e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.54e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.55e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.56e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.57e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.58e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.59e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.6e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.61e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.62e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.63e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.64e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.65e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.66e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.67e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.68e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.69e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.7e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.71e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.72e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.73e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.74e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.75e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.76e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.77e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.78e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.79e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.8e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.81e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.82e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.83e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.84e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.85e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.86e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.87e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.87e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.88e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.89e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.9e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.91e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.92e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.93e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.94e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.95e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.96e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.97e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.98e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 7.99e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8e+04    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.01e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.02e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.03e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.04e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.05e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.06e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.07e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.08e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.09e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.1e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.11e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.12e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.13e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.14e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.15e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.16e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.17e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.18e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.19e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.2e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.21e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.22e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.23e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.23e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.24e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.25e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.26e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.27e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.28e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.29e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.3e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.31e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.31e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.32e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.33e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.34e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.35e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.36e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.37e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.38e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.39e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.4e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.41e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.42e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.43e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.44e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.45e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.46e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.47e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.48e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.49e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.5e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.51e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.52e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.53e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.54e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.55e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.56e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.57e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.58e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.59e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.59e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.6e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.61e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.62e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.63e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.64e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.65e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.66e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.67e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.67e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.68e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.69e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.7e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.71e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.72e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.73e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.74e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.75e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.76e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.77e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.78e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.79e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.8e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.81e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.82e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.83e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.84e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.85e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.86e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.87e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.88e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.89e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.9e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.91e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.92e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.93e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.94e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.95e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.95e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.96e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.97e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.98e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 8.99e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9e+04    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.01e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.01e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.02e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.02e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.03e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.03e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.04e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.04e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.05e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.05e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.06e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.06e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.07e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.07e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.08e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.08e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.09e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.09e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.1e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.1e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.11e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.11e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.12e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.12e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.13e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.13e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.14e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.14e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.15e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.15e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.16e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.16e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.17e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.17e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.18e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.18e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.19e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.19e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.2e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.2e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.21e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.21e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.22e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.22e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.23e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.23e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.24e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.24e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.25e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.25e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.26e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.26e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.27e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.27e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.28e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.28e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.29e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.29e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.3e+04  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.3e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.31e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.31e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.32e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.32e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.33e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.33e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.34e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.34e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.35e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.35e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.36e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.36e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.37e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.37e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.38e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.38e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.39e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.39e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.4e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.4e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.41e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.41e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.42e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.43e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.43e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.44e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.44e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.45e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.45e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.46e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.46e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.47e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.47e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.48e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.48e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.49e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.49e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.5e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.5e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.51e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.51e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.52e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.52e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.53e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.53e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.54e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.54e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.55e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.55e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.56e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.56e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.57e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.57e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.58e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.58e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.59e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.59e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.6e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.6e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.61e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.61e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.62e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.62e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.63e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.63e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.64e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.64e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.65e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.65e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.66e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.66e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.67e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.67e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.68e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.68e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.69e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.69e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.7e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.7e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.71e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.71e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.72e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.72e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.73e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.73e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.74e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.74e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.75e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.75e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.76e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.76e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.77e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.77e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.78e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.78e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.79e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.79e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.8e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.8e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.81e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.81e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.82e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.82e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.83e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.83e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.84e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.84e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.85e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.85e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.86e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.86e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.87e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.87e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.88e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.88e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.89e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.89e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.9e+04  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.9e+04  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.91e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.91e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.92e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.92e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.93e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.93e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.94e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.94e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.95e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.95e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.96e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.96e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.97e+04 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9.97e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.98e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.98e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 9.99e+04 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9.99e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1e+05    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.00e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1e+05    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.01e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.01e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.02e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.02e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.03e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.03e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.04e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.04e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.05e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.05e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.06e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.06e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.07e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.07e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.08e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.08e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.09e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.09e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.1e+05  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.10e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.1e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.11e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.11e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.12e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.12e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.13e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.13e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.14e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.14e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.15e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.15e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.16e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.16e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.17e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.18e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.18e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.19e+05 |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.19e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1.2e+05  |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1.2e+05  |\n",
      "--------------------------------------\n",
      "Restored model with mean reward: 1.0\n",
      "DQN Training Time: 255.617821931839\n"
     ]
    }
   ],
   "source": [
    "def mnist_dqn():\n",
    "    logger.configure(dir='./logs/mnist_dqn', format_strs=['stdout', 'tensorboard'])\n",
    "    env = MnistEnv(images_per_episode=1)\n",
    "    env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "    model = deepq.learn(\n",
    "        env,\n",
    "        \"mlp\",\n",
    "        num_layers=1,\n",
    "        num_hidden=64,\n",
    "        activation=tf.nn.relu,\n",
    "        hiddens=[32],\n",
    "        dueling=True,\n",
    "        lr=1e-4,\n",
    "        total_timesteps=int(1.2e5),\n",
    "        buffer_size=10000,\n",
    "        exploration_fraction=0.1,\n",
    "        exploration_final_eps=0.01,\n",
    "        train_freq=4,\n",
    "        learning_starts=10000,\n",
    "        target_network_update_freq=1000,\n",
    "    )\n",
    "\n",
    "    model.save('dqn_mnist.pkl')\n",
    "    env.close()\n",
    "\n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "dqn_model = mnist_dqn()\n",
    "print(\"DQN Training Time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b342a97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 93.55871174234846%\n"
     ]
    }
   ],
   "source": [
    "def mnist_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "\n",
    "    env = MnistEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                obs, rew, done, _ = env.step(dqn_model(obs[None])[0])\n",
    "\n",
    "                attempts += 1\n",
    "                if rew > 0:\n",
    "                    correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "mnist_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f741e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/mnist_ppo\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.219    |\n",
      "| fps                     | 79       |\n",
      "| loss/approxkl           | 0.000137 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 2.3      |\n",
      "| loss/policy_loss        | -0.00857 |\n",
      "| loss/value_loss         | 0.0874   |\n",
      "| misc/explained_variance | -0.31    |\n",
      "| misc/nupdates           | 1        |\n",
      "| misc/serial_timesteps   | 32       |\n",
      "| misc/time_elapsed       | 0.402    |\n",
      "| misc/total_timesteps    | 32       |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.12     |\n",
      "| fps                     | 172      |\n",
      "| loss/approxkl           | 0.000397 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 2.26     |\n",
      "| loss/policy_loss        | -0.00421 |\n",
      "| loss/value_loss         | 0.048    |\n",
      "| misc/explained_variance | -0.378   |\n",
      "| misc/nupdates           | 10       |\n",
      "| misc/serial_timesteps   | 320      |\n",
      "| misc/time_elapsed       | 1.73     |\n",
      "| misc/total_timesteps    | 320      |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.12     |\n",
      "| fps                     | 174      |\n",
      "| loss/approxkl           | 0.000361 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 2.28     |\n",
      "| loss/policy_loss        | -0.0141  |\n",
      "| loss/value_loss         | 0.0362   |\n",
      "| misc/explained_variance | -0.374   |\n",
      "| misc/nupdates           | 20       |\n",
      "| misc/serial_timesteps   | 640      |\n",
      "| misc/time_elapsed       | 3.37     |\n",
      "| misc/total_timesteps    | 640      |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.15     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.00159  |\n",
      "| loss/clipfrac           | 0.00781  |\n",
      "| loss/policy_entropy     | 2.25     |\n",
      "| loss/policy_loss        | -0.0237  |\n",
      "| loss/value_loss         | 0.0742   |\n",
      "| misc/explained_variance | -0.0868  |\n",
      "| misc/nupdates           | 30       |\n",
      "| misc/serial_timesteps   | 960      |\n",
      "| misc/time_elapsed       | 5.01     |\n",
      "| misc/total_timesteps    | 960      |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.16     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.00315  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 2.1      |\n",
      "| loss/policy_loss        | -0.0349  |\n",
      "| loss/value_loss         | 0.038    |\n",
      "| misc/explained_variance | -0.0296  |\n",
      "| misc/nupdates           | 40       |\n",
      "| misc/serial_timesteps   | 1.28e+03 |\n",
      "| misc/time_elapsed       | 6.65     |\n",
      "| misc/total_timesteps    | 1.28e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.25     |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.00766  |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 2.04     |\n",
      "| loss/policy_loss        | -0.0441  |\n",
      "| loss/value_loss         | 0.0781   |\n",
      "| misc/explained_variance | -0.0684  |\n",
      "| misc/nupdates           | 50       |\n",
      "| misc/serial_timesteps   | 1.6e+03  |\n",
      "| misc/time_elapsed       | 8.24     |\n",
      "| misc/total_timesteps    | 1.6e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.29     |\n",
      "| fps                     | 202      |\n",
      "| loss/approxkl           | 0.00726  |\n",
      "| loss/clipfrac           | 0.117    |\n",
      "| loss/policy_entropy     | 1.39     |\n",
      "| loss/policy_loss        | -0.0446  |\n",
      "| loss/value_loss         | 0.103    |\n",
      "| misc/explained_variance | 0.0995   |\n",
      "| misc/nupdates           | 60       |\n",
      "| misc/serial_timesteps   | 1.92e+03 |\n",
      "| misc/time_elapsed       | 9.77     |\n",
      "| misc/total_timesteps    | 1.92e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.42     |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.0053   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 1.11     |\n",
      "| loss/policy_loss        | -0.0331  |\n",
      "| loss/value_loss         | 0.0489   |\n",
      "| misc/explained_variance | 0.547    |\n",
      "| misc/nupdates           | 70       |\n",
      "| misc/serial_timesteps   | 2.24e+03 |\n",
      "| misc/time_elapsed       | 11.4     |\n",
      "| misc/total_timesteps    | 2.24e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.39     |\n",
      "| fps                     | 192      |\n",
      "| loss/approxkl           | 0.0132   |\n",
      "| loss/clipfrac           | 0.141    |\n",
      "| loss/policy_entropy     | 1.19     |\n",
      "| loss/policy_loss        | -0.0359  |\n",
      "| loss/value_loss         | 0.0415   |\n",
      "| misc/explained_variance | 0.648    |\n",
      "| misc/nupdates           | 80       |\n",
      "| misc/serial_timesteps   | 2.56e+03 |\n",
      "| misc/time_elapsed       | 13       |\n",
      "| misc/total_timesteps    | 2.56e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.41     |\n",
      "| fps                     | 178      |\n",
      "| loss/approxkl           | 0.0209   |\n",
      "| loss/clipfrac           | 0.164    |\n",
      "| loss/policy_entropy     | 1.05     |\n",
      "| loss/policy_loss        | -0.0503  |\n",
      "| loss/value_loss         | 0.0681   |\n",
      "| misc/explained_variance | 0.411    |\n",
      "| misc/nupdates           | 90       |\n",
      "| misc/serial_timesteps   | 2.88e+03 |\n",
      "| misc/time_elapsed       | 14.7     |\n",
      "| misc/total_timesteps    | 2.88e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.51     |\n",
      "| fps                     | 194      |\n",
      "| loss/approxkl           | 0.012    |\n",
      "| loss/clipfrac           | 0.18     |\n",
      "| loss/policy_entropy     | 1.02     |\n",
      "| loss/policy_loss        | -0.0541  |\n",
      "| loss/value_loss         | 0.066    |\n",
      "| misc/explained_variance | 0.534    |\n",
      "| misc/nupdates           | 100      |\n",
      "| misc/serial_timesteps   | 3.2e+03  |\n",
      "| misc/time_elapsed       | 16.3     |\n",
      "| misc/total_timesteps    | 3.2e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.57     |\n",
      "| fps                     | 202      |\n",
      "| loss/approxkl           | 0.0069   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.845    |\n",
      "| loss/policy_loss        | -0.0274  |\n",
      "| loss/value_loss         | 0.0931   |\n",
      "| misc/explained_variance | 0.188    |\n",
      "| misc/nupdates           | 110      |\n",
      "| misc/serial_timesteps   | 3.52e+03 |\n",
      "| misc/time_elapsed       | 17.7     |\n",
      "| misc/total_timesteps    | 3.52e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.6      |\n",
      "| fps                     | 204      |\n",
      "| loss/approxkl           | 0.0118   |\n",
      "| loss/clipfrac           | 0.117    |\n",
      "| loss/policy_entropy     | 0.823    |\n",
      "| loss/policy_loss        | -0.0374  |\n",
      "| loss/value_loss         | 0.0882   |\n",
      "| misc/explained_variance | 0.255    |\n",
      "| misc/nupdates           | 120      |\n",
      "| misc/serial_timesteps   | 3.84e+03 |\n",
      "| misc/time_elapsed       | 19.1     |\n",
      "| misc/total_timesteps    | 3.84e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.63     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.00956  |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.636    |\n",
      "| loss/policy_loss        | -0.0427  |\n",
      "| loss/value_loss         | 0.0562   |\n",
      "| misc/explained_variance | 0.511    |\n",
      "| misc/nupdates           | 130      |\n",
      "| misc/serial_timesteps   | 4.16e+03 |\n",
      "| misc/time_elapsed       | 20.7     |\n",
      "| misc/total_timesteps    | 4.16e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.75     |\n",
      "| fps                     | 174      |\n",
      "| loss/approxkl           | 0.00706  |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.634    |\n",
      "| loss/policy_loss        | -0.0279  |\n",
      "| loss/value_loss         | 0.039    |\n",
      "| misc/explained_variance | 0.521    |\n",
      "| misc/nupdates           | 140      |\n",
      "| misc/serial_timesteps   | 4.48e+03 |\n",
      "| misc/time_elapsed       | 22.2     |\n",
      "| misc/total_timesteps    | 4.48e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.54     |\n",
      "| fps                     | 194      |\n",
      "| loss/approxkl           | 0.00994  |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.704    |\n",
      "| loss/policy_loss        | -0.0367  |\n",
      "| loss/value_loss         | 0.085    |\n",
      "| misc/explained_variance | 0.251    |\n",
      "| misc/nupdates           | 150      |\n",
      "| misc/serial_timesteps   | 4.8e+03  |\n",
      "| misc/time_elapsed       | 23.8     |\n",
      "| misc/total_timesteps    | 4.8e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.67     |\n",
      "| fps                     | 313      |\n",
      "| loss/approxkl           | 0.00768  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.634    |\n",
      "| loss/policy_loss        | -0.0296  |\n",
      "| loss/value_loss         | 0.0784   |\n",
      "| misc/explained_variance | 0.245    |\n",
      "| misc/nupdates           | 160      |\n",
      "| misc/serial_timesteps   | 5.12e+03 |\n",
      "| misc/time_elapsed       | 25.1     |\n",
      "| misc/total_timesteps    | 5.12e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.75     |\n",
      "| fps                     | 193      |\n",
      "| loss/approxkl           | 0.0208   |\n",
      "| loss/clipfrac           | 0.133    |\n",
      "| loss/policy_entropy     | 0.603    |\n",
      "| loss/policy_loss        | -0.0433  |\n",
      "| loss/value_loss         | 0.0533   |\n",
      "| misc/explained_variance | 0.523    |\n",
      "| misc/nupdates           | 170      |\n",
      "| misc/serial_timesteps   | 5.44e+03 |\n",
      "| misc/time_elapsed       | 26.7     |\n",
      "| misc/total_timesteps    | 5.44e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.62     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0122   |\n",
      "| loss/clipfrac           | 0.133    |\n",
      "| loss/policy_entropy     | 0.62     |\n",
      "| loss/policy_loss        | -0.0411  |\n",
      "| loss/value_loss         | 0.0817   |\n",
      "| misc/explained_variance | 0.369    |\n",
      "| misc/nupdates           | 180      |\n",
      "| misc/serial_timesteps   | 5.76e+03 |\n",
      "| misc/time_elapsed       | 28.3     |\n",
      "| misc/total_timesteps    | 5.76e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.63     |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 0.0054   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.612    |\n",
      "| loss/policy_loss        | -0.0277  |\n",
      "| loss/value_loss         | 0.0552   |\n",
      "| misc/explained_variance | 0.513    |\n",
      "| misc/nupdates           | 190      |\n",
      "| misc/serial_timesteps   | 6.08e+03 |\n",
      "| misc/time_elapsed       | 29.9     |\n",
      "| misc/total_timesteps    | 6.08e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.64     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 0.0185   |\n",
      "| loss/clipfrac           | 0.141    |\n",
      "| loss/policy_entropy     | 0.506    |\n",
      "| loss/policy_loss        | -0.0316  |\n",
      "| loss/value_loss         | 0.058    |\n",
      "| misc/explained_variance | 0.494    |\n",
      "| misc/nupdates           | 200      |\n",
      "| misc/serial_timesteps   | 6.4e+03  |\n",
      "| misc/time_elapsed       | 31.5     |\n",
      "| misc/total_timesteps    | 6.4e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.71     |\n",
      "| fps                     | 200      |\n",
      "| loss/approxkl           | 0.0053   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.414    |\n",
      "| loss/policy_loss        | -0.0189  |\n",
      "| loss/value_loss         | 0.0327   |\n",
      "| misc/explained_variance | 0.617    |\n",
      "| misc/nupdates           | 210      |\n",
      "| misc/serial_timesteps   | 6.72e+03 |\n",
      "| misc/time_elapsed       | 32.9     |\n",
      "| misc/total_timesteps    | 6.72e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.65     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 0.0149   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.418    |\n",
      "| loss/policy_loss        | -0.0429  |\n",
      "| loss/value_loss         | 0.0811   |\n",
      "| misc/explained_variance | 0.136    |\n",
      "| misc/nupdates           | 220      |\n",
      "| misc/serial_timesteps   | 7.04e+03 |\n",
      "| misc/time_elapsed       | 34.4     |\n",
      "| misc/total_timesteps    | 7.04e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.72     |\n",
      "| fps                     | 209      |\n",
      "| loss/approxkl           | 0.00957  |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.416    |\n",
      "| loss/policy_loss        | -0.0173  |\n",
      "| loss/value_loss         | 0.0349   |\n",
      "| misc/explained_variance | 0.504    |\n",
      "| misc/nupdates           | 230      |\n",
      "| misc/serial_timesteps   | 7.36e+03 |\n",
      "| misc/time_elapsed       | 35.9     |\n",
      "| misc/total_timesteps    | 7.36e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.77     |\n",
      "| fps                     | 204      |\n",
      "| loss/approxkl           | 0.0158   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.478    |\n",
      "| loss/policy_loss        | -0.0294  |\n",
      "| loss/value_loss         | 0.0698   |\n",
      "| misc/explained_variance | 0.423    |\n",
      "| misc/nupdates           | 240      |\n",
      "| misc/serial_timesteps   | 7.68e+03 |\n",
      "| misc/time_elapsed       | 37.3     |\n",
      "| misc/total_timesteps    | 7.68e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.68     |\n",
      "| fps                     | 204      |\n",
      "| loss/approxkl           | 0.00829  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.369    |\n",
      "| loss/policy_loss        | -0.0277  |\n",
      "| loss/value_loss         | 0.077    |\n",
      "| misc/explained_variance | 0.163    |\n",
      "| misc/nupdates           | 250      |\n",
      "| misc/serial_timesteps   | 8e+03    |\n",
      "| misc/time_elapsed       | 38.7     |\n",
      "| misc/total_timesteps    | 8e+03    |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.67     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 0.0187   |\n",
      "| loss/clipfrac           | 0.125    |\n",
      "| loss/policy_entropy     | 0.388    |\n",
      "| loss/policy_loss        | -0.034   |\n",
      "| loss/value_loss         | 0.0378   |\n",
      "| misc/explained_variance | 0.5      |\n",
      "| misc/nupdates           | 260      |\n",
      "| misc/serial_timesteps   | 8.32e+03 |\n",
      "| misc/time_elapsed       | 40.2     |\n",
      "| misc/total_timesteps    | 8.32e+03 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.74     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 0.00882  |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.322    |\n",
      "| loss/policy_loss        | -0.0249  |\n",
      "| loss/value_loss         | 0.0493   |\n",
      "| misc/explained_variance | 0.489    |\n",
      "| misc/nupdates           | 270      |\n",
      "| misc/serial_timesteps   | 8.64e+03 |\n",
      "| misc/time_elapsed       | 41.7     |\n",
      "| misc/total_timesteps    | 8.64e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.67     |\n",
      "| fps                     | 194      |\n",
      "| loss/approxkl           | 0.0156   |\n",
      "| loss/clipfrac           | 0.117    |\n",
      "| loss/policy_entropy     | 0.517    |\n",
      "| loss/policy_loss        | -0.0462  |\n",
      "| loss/value_loss         | 0.0662   |\n",
      "| misc/explained_variance | 0.452    |\n",
      "| misc/nupdates           | 280      |\n",
      "| misc/serial_timesteps   | 8.96e+03 |\n",
      "| misc/time_elapsed       | 43.2     |\n",
      "| misc/total_timesteps    | 8.96e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.66     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 0.0276   |\n",
      "| loss/clipfrac           | 0.102    |\n",
      "| loss/policy_entropy     | 0.344    |\n",
      "| loss/policy_loss        | -0.0429  |\n",
      "| loss/value_loss         | 0.0381   |\n",
      "| misc/explained_variance | 0.573    |\n",
      "| misc/nupdates           | 290      |\n",
      "| misc/serial_timesteps   | 9.28e+03 |\n",
      "| misc/time_elapsed       | 44.7     |\n",
      "| misc/total_timesteps    | 9.28e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.71     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 0.0128   |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.424    |\n",
      "| loss/policy_loss        | -0.0276  |\n",
      "| loss/value_loss         | 0.0304   |\n",
      "| misc/explained_variance | 0.7      |\n",
      "| misc/nupdates           | 300      |\n",
      "| misc/serial_timesteps   | 9.6e+03  |\n",
      "| misc/time_elapsed       | 46.2     |\n",
      "| misc/total_timesteps    | 9.6e+03  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.73     |\n",
      "| fps                     | 206      |\n",
      "| loss/approxkl           | 0.013    |\n",
      "| loss/clipfrac           | 0.141    |\n",
      "| loss/policy_entropy     | 0.422    |\n",
      "| loss/policy_loss        | -0.0363  |\n",
      "| loss/value_loss         | 0.0608   |\n",
      "| misc/explained_variance | 0.488    |\n",
      "| misc/nupdates           | 310      |\n",
      "| misc/serial_timesteps   | 9.92e+03 |\n",
      "| misc/time_elapsed       | 47.7     |\n",
      "| misc/total_timesteps    | 9.92e+03 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.75     |\n",
      "| fps                     | 209      |\n",
      "| loss/approxkl           | 0.0214   |\n",
      "| loss/clipfrac           | 0.148    |\n",
      "| loss/policy_entropy     | 0.39     |\n",
      "| loss/policy_loss        | -0.0412  |\n",
      "| loss/value_loss         | 0.0456   |\n",
      "| misc/explained_variance | 0.565    |\n",
      "| misc/nupdates           | 320      |\n",
      "| misc/serial_timesteps   | 1.02e+04 |\n",
      "| misc/time_elapsed       | 49.1     |\n",
      "| misc/total_timesteps    | 1.02e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.76     |\n",
      "| fps                     | 216      |\n",
      "| loss/approxkl           | 0.00487  |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.236    |\n",
      "| loss/policy_loss        | -0.0202  |\n",
      "| loss/value_loss         | 0.0581   |\n",
      "| misc/explained_variance | 0.385    |\n",
      "| misc/nupdates           | 330      |\n",
      "| misc/serial_timesteps   | 1.06e+04 |\n",
      "| misc/time_elapsed       | 50.6     |\n",
      "| misc/total_timesteps    | 1.06e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.67     |\n",
      "| fps                     | 214      |\n",
      "| loss/approxkl           | 0.0233   |\n",
      "| loss/clipfrac           | 0.172    |\n",
      "| loss/policy_entropy     | 0.403    |\n",
      "| loss/policy_loss        | -0.0562  |\n",
      "| loss/value_loss         | 0.0415   |\n",
      "| misc/explained_variance | 0.565    |\n",
      "| misc/nupdates           | 340      |\n",
      "| misc/serial_timesteps   | 1.09e+04 |\n",
      "| misc/time_elapsed       | 52       |\n",
      "| misc/total_timesteps    | 1.09e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.72     |\n",
      "| fps                     | 216      |\n",
      "| loss/approxkl           | 0.0222   |\n",
      "| loss/clipfrac           | 0.117    |\n",
      "| loss/policy_entropy     | 0.359    |\n",
      "| loss/policy_loss        | -0.0294  |\n",
      "| loss/value_loss         | 0.0596   |\n",
      "| misc/explained_variance | 0.505    |\n",
      "| misc/nupdates           | 350      |\n",
      "| misc/serial_timesteps   | 1.12e+04 |\n",
      "| misc/time_elapsed       | 53.5     |\n",
      "| misc/total_timesteps    | 1.12e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.75     |\n",
      "| fps                     | 190      |\n",
      "| loss/approxkl           | 0.00521  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.318    |\n",
      "| loss/policy_loss        | -0.0302  |\n",
      "| loss/value_loss         | 0.0427   |\n",
      "| misc/explained_variance | 0.456    |\n",
      "| misc/nupdates           | 360      |\n",
      "| misc/serial_timesteps   | 1.15e+04 |\n",
      "| misc/time_elapsed       | 54.9     |\n",
      "| misc/total_timesteps    | 1.15e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.67     |\n",
      "| fps                     | 212      |\n",
      "| loss/approxkl           | 0.0325   |\n",
      "| loss/clipfrac           | 0.133    |\n",
      "| loss/policy_entropy     | 0.409    |\n",
      "| loss/policy_loss        | -0.031   |\n",
      "| loss/value_loss         | 0.0301   |\n",
      "| misc/explained_variance | 0.735    |\n",
      "| misc/nupdates           | 370      |\n",
      "| misc/serial_timesteps   | 1.18e+04 |\n",
      "| misc/time_elapsed       | 56.5     |\n",
      "| misc/total_timesteps    | 1.18e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.71     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.00509  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.302    |\n",
      "| loss/policy_loss        | -0.0159  |\n",
      "| loss/value_loss         | 0.0332   |\n",
      "| misc/explained_variance | 0.655    |\n",
      "| misc/nupdates           | 380      |\n",
      "| misc/serial_timesteps   | 1.22e+04 |\n",
      "| misc/time_elapsed       | 57.9     |\n",
      "| misc/total_timesteps    | 1.22e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.79     |\n",
      "| fps                     | 313      |\n",
      "| loss/approxkl           | 0.0147   |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.269    |\n",
      "| loss/policy_loss        | -0.0248  |\n",
      "| loss/value_loss         | 0.0281   |\n",
      "| misc/explained_variance | 0.617    |\n",
      "| misc/nupdates           | 390      |\n",
      "| misc/serial_timesteps   | 1.25e+04 |\n",
      "| misc/time_elapsed       | 59.3     |\n",
      "| misc/total_timesteps    | 1.25e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.66     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0068   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.295    |\n",
      "| loss/policy_loss        | -0.0276  |\n",
      "| loss/value_loss         | 0.0373   |\n",
      "| misc/explained_variance | 0.606    |\n",
      "| misc/nupdates           | 400      |\n",
      "| misc/serial_timesteps   | 1.28e+04 |\n",
      "| misc/time_elapsed       | 60.7     |\n",
      "| misc/total_timesteps    | 1.28e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.7      |\n",
      "| fps                     | 327      |\n",
      "| loss/approxkl           | 0.0113   |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.32     |\n",
      "| loss/policy_loss        | -0.0361  |\n",
      "| loss/value_loss         | 0.0435   |\n",
      "| misc/explained_variance | 0.576    |\n",
      "| misc/nupdates           | 410      |\n",
      "| misc/serial_timesteps   | 1.31e+04 |\n",
      "| misc/time_elapsed       | 62.2     |\n",
      "| misc/total_timesteps    | 1.31e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.7      |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.00909  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.255    |\n",
      "| loss/policy_loss        | -0.027   |\n",
      "| loss/value_loss         | 0.0552   |\n",
      "| misc/explained_variance | 0.536    |\n",
      "| misc/nupdates           | 420      |\n",
      "| misc/serial_timesteps   | 1.34e+04 |\n",
      "| misc/time_elapsed       | 63.7     |\n",
      "| misc/total_timesteps    | 1.34e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.73     |\n",
      "| fps                     | 192      |\n",
      "| loss/approxkl           | 0.0125   |\n",
      "| loss/clipfrac           | 0.102    |\n",
      "| loss/policy_entropy     | 0.293    |\n",
      "| loss/policy_loss        | -0.0325  |\n",
      "| loss/value_loss         | 0.0258   |\n",
      "| misc/explained_variance | 0.708    |\n",
      "| misc/nupdates           | 430      |\n",
      "| misc/serial_timesteps   | 1.38e+04 |\n",
      "| misc/time_elapsed       | 65.3     |\n",
      "| misc/total_timesteps    | 1.38e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.7      |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.014    |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.383    |\n",
      "| loss/policy_loss        | -0.0328  |\n",
      "| loss/value_loss         | 0.037    |\n",
      "| misc/explained_variance | 0.705    |\n",
      "| misc/nupdates           | 440      |\n",
      "| misc/serial_timesteps   | 1.41e+04 |\n",
      "| misc/time_elapsed       | 66.9     |\n",
      "| misc/total_timesteps    | 1.41e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.68     |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.0146   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.282    |\n",
      "| loss/policy_loss        | -0.0323  |\n",
      "| loss/value_loss         | 0.0268   |\n",
      "| misc/explained_variance | 0.659    |\n",
      "| misc/nupdates           | 450      |\n",
      "| misc/serial_timesteps   | 1.44e+04 |\n",
      "| misc/time_elapsed       | 68.5     |\n",
      "| misc/total_timesteps    | 1.44e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.72     |\n",
      "| fps                     | 236      |\n",
      "| loss/approxkl           | 0.0219   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.254    |\n",
      "| loss/policy_loss        | -0.0271  |\n",
      "| loss/value_loss         | 0.0267   |\n",
      "| misc/explained_variance | 0.659    |\n",
      "| misc/nupdates           | 460      |\n",
      "| misc/serial_timesteps   | 1.47e+04 |\n",
      "| misc/time_elapsed       | 69.7     |\n",
      "| misc/total_timesteps    | 1.47e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.84     |\n",
      "| fps                     | 197      |\n",
      "| loss/approxkl           | 0.016    |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.321    |\n",
      "| loss/policy_loss        | -0.0323  |\n",
      "| loss/value_loss         | 0.04     |\n",
      "| misc/explained_variance | 0.446    |\n",
      "| misc/nupdates           | 470      |\n",
      "| misc/serial_timesteps   | 1.5e+04  |\n",
      "| misc/time_elapsed       | 71       |\n",
      "| misc/total_timesteps    | 1.5e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.76     |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.00667  |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.291    |\n",
      "| loss/policy_loss        | -0.0219  |\n",
      "| loss/value_loss         | 0.0369   |\n",
      "| misc/explained_variance | 0.566    |\n",
      "| misc/nupdates           | 480      |\n",
      "| misc/serial_timesteps   | 1.54e+04 |\n",
      "| misc/time_elapsed       | 72.6     |\n",
      "| misc/total_timesteps    | 1.54e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.71     |\n",
      "| fps                     | 249      |\n",
      "| loss/approxkl           | 0.0227   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.314    |\n",
      "| loss/policy_loss        | -0.0371  |\n",
      "| loss/value_loss         | 0.0299   |\n",
      "| misc/explained_variance | 0.703    |\n",
      "| misc/nupdates           | 490      |\n",
      "| misc/serial_timesteps   | 1.57e+04 |\n",
      "| misc/time_elapsed       | 73.8     |\n",
      "| misc/total_timesteps    | 1.57e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.79     |\n",
      "| fps                     | 204      |\n",
      "| loss/approxkl           | 0.0107   |\n",
      "| loss/clipfrac           | 0.102    |\n",
      "| loss/policy_entropy     | 0.268    |\n",
      "| loss/policy_loss        | -0.0316  |\n",
      "| loss/value_loss         | 0.0137   |\n",
      "| misc/explained_variance | 0.793    |\n",
      "| misc/nupdates           | 500      |\n",
      "| misc/serial_timesteps   | 1.6e+04  |\n",
      "| misc/time_elapsed       | 75.1     |\n",
      "| misc/total_timesteps    | 1.6e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.8      |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 0.0131   |\n",
      "| loss/clipfrac           | 0.125    |\n",
      "| loss/policy_entropy     | 0.283    |\n",
      "| loss/policy_loss        | -0.0367  |\n",
      "| loss/value_loss         | 0.0349   |\n",
      "| misc/explained_variance | 0.355    |\n",
      "| misc/nupdates           | 510      |\n",
      "| misc/serial_timesteps   | 1.63e+04 |\n",
      "| misc/time_elapsed       | 76.6     |\n",
      "| misc/total_timesteps    | 1.63e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.73     |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 0.00598  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.262    |\n",
      "| loss/policy_loss        | -0.022   |\n",
      "| loss/value_loss         | 0.0289   |\n",
      "| misc/explained_variance | 0.673    |\n",
      "| misc/nupdates           | 520      |\n",
      "| misc/serial_timesteps   | 1.66e+04 |\n",
      "| misc/time_elapsed       | 78.1     |\n",
      "| misc/total_timesteps    | 1.66e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.76     |\n",
      "| fps                     | 213      |\n",
      "| loss/approxkl           | 0.014    |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.205    |\n",
      "| loss/policy_loss        | -0.0318  |\n",
      "| loss/value_loss         | 0.0359   |\n",
      "| misc/explained_variance | 0.518    |\n",
      "| misc/nupdates           | 530      |\n",
      "| misc/serial_timesteps   | 1.7e+04  |\n",
      "| misc/time_elapsed       | 79.5     |\n",
      "| misc/total_timesteps    | 1.7e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.71     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 0.0344   |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.215    |\n",
      "| loss/policy_loss        | -0.0391  |\n",
      "| loss/value_loss         | 0.0491   |\n",
      "| misc/explained_variance | 0.526    |\n",
      "| misc/nupdates           | 540      |\n",
      "| misc/serial_timesteps   | 1.73e+04 |\n",
      "| misc/time_elapsed       | 80.9     |\n",
      "| misc/total_timesteps    | 1.73e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.77     |\n",
      "| fps                     | 215      |\n",
      "| loss/approxkl           | 0.0516   |\n",
      "| loss/clipfrac           | 0.211    |\n",
      "| loss/policy_entropy     | 0.267    |\n",
      "| loss/policy_loss        | -0.0589  |\n",
      "| loss/value_loss         | 0.052    |\n",
      "| misc/explained_variance | 0.437    |\n",
      "| misc/nupdates           | 550      |\n",
      "| misc/serial_timesteps   | 1.76e+04 |\n",
      "| misc/time_elapsed       | 82.4     |\n",
      "| misc/total_timesteps    | 1.76e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.74     |\n",
      "| fps                     | 211      |\n",
      "| loss/approxkl           | 0.012    |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.378    |\n",
      "| loss/policy_loss        | -0.0219  |\n",
      "| loss/value_loss         | 0.032    |\n",
      "| misc/explained_variance | 0.688    |\n",
      "| misc/nupdates           | 560      |\n",
      "| misc/serial_timesteps   | 1.79e+04 |\n",
      "| misc/time_elapsed       | 83.7     |\n",
      "| misc/total_timesteps    | 1.79e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.78     |\n",
      "| fps                     | 217      |\n",
      "| loss/approxkl           | 0.00905  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.23     |\n",
      "| loss/policy_loss        | -0.0208  |\n",
      "| loss/value_loss         | 0.0298   |\n",
      "| misc/explained_variance | 0.672    |\n",
      "| misc/nupdates           | 570      |\n",
      "| misc/serial_timesteps   | 1.82e+04 |\n",
      "| misc/time_elapsed       | 85.1     |\n",
      "| misc/total_timesteps    | 1.82e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.77     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 0.00759  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.163    |\n",
      "| loss/policy_loss        | -0.0308  |\n",
      "| loss/value_loss         | 0.0493   |\n",
      "| misc/explained_variance | 0.288    |\n",
      "| misc/nupdates           | 580      |\n",
      "| misc/serial_timesteps   | 1.86e+04 |\n",
      "| misc/time_elapsed       | 86.7     |\n",
      "| misc/total_timesteps    | 1.86e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.66     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 0.0363   |\n",
      "| loss/clipfrac           | 0.164    |\n",
      "| loss/policy_entropy     | 0.417    |\n",
      "| loss/policy_loss        | -0.0458  |\n",
      "| loss/value_loss         | 0.0469   |\n",
      "| misc/explained_variance | 0.57     |\n",
      "| misc/nupdates           | 590      |\n",
      "| misc/serial_timesteps   | 1.89e+04 |\n",
      "| misc/time_elapsed       | 88.1     |\n",
      "| misc/total_timesteps    | 1.89e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.85     |\n",
      "| fps                     | 193      |\n",
      "| loss/approxkl           | 0.00766  |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.15     |\n",
      "| loss/policy_loss        | -0.0235  |\n",
      "| loss/value_loss         | 0.0274   |\n",
      "| misc/explained_variance | 0.527    |\n",
      "| misc/nupdates           | 600      |\n",
      "| misc/serial_timesteps   | 1.92e+04 |\n",
      "| misc/time_elapsed       | 89.6     |\n",
      "| misc/total_timesteps    | 1.92e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.67     |\n",
      "| fps                     | 192      |\n",
      "| loss/approxkl           | 0.0388   |\n",
      "| loss/clipfrac           | 0.156    |\n",
      "| loss/policy_entropy     | 0.331    |\n",
      "| loss/policy_loss        | -0.0426  |\n",
      "| loss/value_loss         | 0.0355   |\n",
      "| misc/explained_variance | 0.684    |\n",
      "| misc/nupdates           | 610      |\n",
      "| misc/serial_timesteps   | 1.95e+04 |\n",
      "| misc/time_elapsed       | 91.1     |\n",
      "| misc/total_timesteps    | 1.95e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.81     |\n",
      "| fps                     | 212      |\n",
      "| loss/approxkl           | 0.0385   |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.179    |\n",
      "| loss/policy_loss        | -0.0187  |\n",
      "| loss/value_loss         | 0.0177   |\n",
      "| misc/explained_variance | 0.789    |\n",
      "| misc/nupdates           | 620      |\n",
      "| misc/serial_timesteps   | 1.98e+04 |\n",
      "| misc/time_elapsed       | 92.6     |\n",
      "| misc/total_timesteps    | 1.98e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.75     |\n",
      "| fps                     | 201      |\n",
      "| loss/approxkl           | 0.0161   |\n",
      "| loss/clipfrac           | 0.141    |\n",
      "| loss/policy_entropy     | 0.222    |\n",
      "| loss/policy_loss        | -0.0434  |\n",
      "| loss/value_loss         | 0.0736   |\n",
      "| misc/explained_variance | 0.254    |\n",
      "| misc/nupdates           | 630      |\n",
      "| misc/serial_timesteps   | 2.02e+04 |\n",
      "| misc/time_elapsed       | 94.1     |\n",
      "| misc/total_timesteps    | 2.02e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.73     |\n",
      "| fps                     | 209      |\n",
      "| loss/approxkl           | 0.0283   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.187    |\n",
      "| loss/policy_loss        | -0.0236  |\n",
      "| loss/value_loss         | 0.0144   |\n",
      "| misc/explained_variance | 0.841    |\n",
      "| misc/nupdates           | 640      |\n",
      "| misc/serial_timesteps   | 2.05e+04 |\n",
      "| misc/time_elapsed       | 95.5     |\n",
      "| misc/total_timesteps    | 2.05e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.79     |\n",
      "| fps                     | 208      |\n",
      "| loss/approxkl           | 0.0264   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.221    |\n",
      "| loss/policy_loss        | -0.0315  |\n",
      "| loss/value_loss         | 0.0195   |\n",
      "| misc/explained_variance | 0.764    |\n",
      "| misc/nupdates           | 650      |\n",
      "| misc/serial_timesteps   | 2.08e+04 |\n",
      "| misc/time_elapsed       | 97       |\n",
      "| misc/total_timesteps    | 2.08e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.75     |\n",
      "| fps                     | 207      |\n",
      "| loss/approxkl           | 0.0267   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.215    |\n",
      "| loss/policy_loss        | -0.0241  |\n",
      "| loss/value_loss         | 0.0405   |\n",
      "| misc/explained_variance | 0.591    |\n",
      "| misc/nupdates           | 660      |\n",
      "| misc/serial_timesteps   | 2.11e+04 |\n",
      "| misc/time_elapsed       | 98.3     |\n",
      "| misc/total_timesteps    | 2.11e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.77     |\n",
      "| fps                     | 203      |\n",
      "| loss/approxkl           | 0.0355   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.166    |\n",
      "| loss/policy_loss        | -0.034   |\n",
      "| loss/value_loss         | 0.0329   |\n",
      "| misc/explained_variance | 0.368    |\n",
      "| misc/nupdates           | 670      |\n",
      "| misc/serial_timesteps   | 2.14e+04 |\n",
      "| misc/time_elapsed       | 99.7     |\n",
      "| misc/total_timesteps    | 2.14e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.8      |\n",
      "| fps                     | 223      |\n",
      "| loss/approxkl           | 0.0183   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.232    |\n",
      "| loss/policy_loss        | -0.0245  |\n",
      "| loss/value_loss         | 0.0237   |\n",
      "| misc/explained_variance | 0.713    |\n",
      "| misc/nupdates           | 680      |\n",
      "| misc/serial_timesteps   | 2.18e+04 |\n",
      "| misc/time_elapsed       | 101      |\n",
      "| misc/total_timesteps    | 2.18e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.81     |\n",
      "| fps                     | 200      |\n",
      "| loss/approxkl           | 0.0152   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.266    |\n",
      "| loss/policy_loss        | -0.0228  |\n",
      "| loss/value_loss         | 0.0278   |\n",
      "| misc/explained_variance | 0.746    |\n",
      "| misc/nupdates           | 690      |\n",
      "| misc/serial_timesteps   | 2.21e+04 |\n",
      "| misc/time_elapsed       | 103      |\n",
      "| misc/total_timesteps    | 2.21e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.68     |\n",
      "| fps                     | 212      |\n",
      "| loss/approxkl           | 0.0158   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.219    |\n",
      "| loss/policy_loss        | -0.0232  |\n",
      "| loss/value_loss         | 0.0422   |\n",
      "| misc/explained_variance | 0.532    |\n",
      "| misc/nupdates           | 700      |\n",
      "| misc/serial_timesteps   | 2.24e+04 |\n",
      "| misc/time_elapsed       | 104      |\n",
      "| misc/total_timesteps    | 2.24e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.67     |\n",
      "| fps                     | 268      |\n",
      "| loss/approxkl           | 0.0302   |\n",
      "| loss/clipfrac           | 0.18     |\n",
      "| loss/policy_entropy     | 0.387    |\n",
      "| loss/policy_loss        | -0.0499  |\n",
      "| loss/value_loss         | 0.0374   |\n",
      "| misc/explained_variance | 0.709    |\n",
      "| misc/nupdates           | 710      |\n",
      "| misc/serial_timesteps   | 2.27e+04 |\n",
      "| misc/time_elapsed       | 105      |\n",
      "| misc/total_timesteps    | 2.27e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.7      |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 0.0258   |\n",
      "| loss/clipfrac           | 0.117    |\n",
      "| loss/policy_entropy     | 0.281    |\n",
      "| loss/policy_loss        | -0.0382  |\n",
      "| loss/value_loss         | 0.035    |\n",
      "| misc/explained_variance | 0.653    |\n",
      "| misc/nupdates           | 720      |\n",
      "| misc/serial_timesteps   | 2.3e+04  |\n",
      "| misc/time_elapsed       | 107      |\n",
      "| misc/total_timesteps    | 2.3e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.68     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0133   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.238    |\n",
      "| loss/policy_loss        | -0.0322  |\n",
      "| loss/value_loss         | 0.0466   |\n",
      "| misc/explained_variance | 0.482    |\n",
      "| misc/nupdates           | 730      |\n",
      "| misc/serial_timesteps   | 2.34e+04 |\n",
      "| misc/time_elapsed       | 108      |\n",
      "| misc/total_timesteps    | 2.34e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.76     |\n",
      "| fps                     | 306      |\n",
      "| loss/approxkl           | 0.00662  |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.323    |\n",
      "| loss/policy_loss        | -0.0222  |\n",
      "| loss/value_loss         | 0.0118   |\n",
      "| misc/explained_variance | 0.888    |\n",
      "| misc/nupdates           | 740      |\n",
      "| misc/serial_timesteps   | 2.37e+04 |\n",
      "| misc/time_elapsed       | 109      |\n",
      "| misc/total_timesteps    | 2.37e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.71     |\n",
      "| fps                     | 241      |\n",
      "| loss/approxkl           | 0.0109   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.212    |\n",
      "| loss/policy_loss        | -0.0188  |\n",
      "| loss/value_loss         | 0.0256   |\n",
      "| misc/explained_variance | 0.756    |\n",
      "| misc/nupdates           | 750      |\n",
      "| misc/serial_timesteps   | 2.4e+04  |\n",
      "| misc/time_elapsed       | 111      |\n",
      "| misc/total_timesteps    | 2.4e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.77     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 0.00865  |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.215    |\n",
      "| loss/policy_loss        | -0.0317  |\n",
      "| loss/value_loss         | 0.019    |\n",
      "| misc/explained_variance | 0.753    |\n",
      "| misc/nupdates           | 760      |\n",
      "| misc/serial_timesteps   | 2.43e+04 |\n",
      "| misc/time_elapsed       | 112      |\n",
      "| misc/total_timesteps    | 2.43e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.77     |\n",
      "| fps                     | 204      |\n",
      "| loss/approxkl           | 0.00896  |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.353    |\n",
      "| loss/policy_loss        | -0.0258  |\n",
      "| loss/value_loss         | 0.029    |\n",
      "| misc/explained_variance | 0.699    |\n",
      "| misc/nupdates           | 770      |\n",
      "| misc/serial_timesteps   | 2.46e+04 |\n",
      "| misc/time_elapsed       | 113      |\n",
      "| misc/total_timesteps    | 2.46e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.73     |\n",
      "| fps                     | 196      |\n",
      "| loss/approxkl           | 0.0148   |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.393    |\n",
      "| loss/policy_loss        | -0.0311  |\n",
      "| loss/value_loss         | 0.0475   |\n",
      "| misc/explained_variance | 0.49     |\n",
      "| misc/nupdates           | 780      |\n",
      "| misc/serial_timesteps   | 2.5e+04  |\n",
      "| misc/time_elapsed       | 115      |\n",
      "| misc/total_timesteps    | 2.5e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.82     |\n",
      "| fps                     | 201      |\n",
      "| loss/approxkl           | 0.00934  |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.246    |\n",
      "| loss/policy_loss        | -0.0299  |\n",
      "| loss/value_loss         | 0.0228   |\n",
      "| misc/explained_variance | 0.614    |\n",
      "| misc/nupdates           | 790      |\n",
      "| misc/serial_timesteps   | 2.53e+04 |\n",
      "| misc/time_elapsed       | 117      |\n",
      "| misc/total_timesteps    | 2.53e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.74     |\n",
      "| fps                     | 190      |\n",
      "| loss/approxkl           | 0.0234   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.32     |\n",
      "| loss/policy_loss        | -0.0405  |\n",
      "| loss/value_loss         | 0.027    |\n",
      "| misc/explained_variance | 0.687    |\n",
      "| misc/nupdates           | 800      |\n",
      "| misc/serial_timesteps   | 2.56e+04 |\n",
      "| misc/time_elapsed       | 118      |\n",
      "| misc/total_timesteps    | 2.56e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.8      |\n",
      "| fps                     | 229      |\n",
      "| loss/approxkl           | 0.00536  |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.233    |\n",
      "| loss/policy_loss        | -0.0163  |\n",
      "| loss/value_loss         | 0.0205   |\n",
      "| misc/explained_variance | 0.739    |\n",
      "| misc/nupdates           | 810      |\n",
      "| misc/serial_timesteps   | 2.59e+04 |\n",
      "| misc/time_elapsed       | 119      |\n",
      "| misc/total_timesteps    | 2.59e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.74     |\n",
      "| fps                     | 284      |\n",
      "| loss/approxkl           | 0.0152   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.234    |\n",
      "| loss/policy_loss        | -0.0217  |\n",
      "| loss/value_loss         | 0.0404   |\n",
      "| misc/explained_variance | 0.561    |\n",
      "| misc/nupdates           | 820      |\n",
      "| misc/serial_timesteps   | 2.62e+04 |\n",
      "| misc/time_elapsed       | 121      |\n",
      "| misc/total_timesteps    | 2.62e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.74     |\n",
      "| fps                     | 203      |\n",
      "| loss/approxkl           | 0.00143  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.163    |\n",
      "| loss/policy_loss        | -0.00558 |\n",
      "| loss/value_loss         | 0.0246   |\n",
      "| misc/explained_variance | 0.519    |\n",
      "| misc/nupdates           | 830      |\n",
      "| misc/serial_timesteps   | 2.66e+04 |\n",
      "| misc/time_elapsed       | 122      |\n",
      "| misc/total_timesteps    | 2.66e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.75     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 0.0222   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.392    |\n",
      "| loss/policy_loss        | -0.0343  |\n",
      "| loss/value_loss         | 0.0425   |\n",
      "| misc/explained_variance | 0.553    |\n",
      "| misc/nupdates           | 840      |\n",
      "| misc/serial_timesteps   | 2.69e+04 |\n",
      "| misc/time_elapsed       | 124      |\n",
      "| misc/total_timesteps    | 2.69e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.83     |\n",
      "| fps                     | 310      |\n",
      "| loss/approxkl           | 0.0107   |\n",
      "| loss/clipfrac           | 0.102    |\n",
      "| loss/policy_entropy     | 0.292    |\n",
      "| loss/policy_loss        | -0.045   |\n",
      "| loss/value_loss         | 0.035    |\n",
      "| misc/explained_variance | 0.528    |\n",
      "| misc/nupdates           | 850      |\n",
      "| misc/serial_timesteps   | 2.72e+04 |\n",
      "| misc/time_elapsed       | 125      |\n",
      "| misc/total_timesteps    | 2.72e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.79     |\n",
      "| fps                     | 311      |\n",
      "| loss/approxkl           | 0.0232   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.321    |\n",
      "| loss/policy_loss        | -0.0268  |\n",
      "| loss/value_loss         | 0.0448   |\n",
      "| misc/explained_variance | 0.527    |\n",
      "| misc/nupdates           | 860      |\n",
      "| misc/serial_timesteps   | 2.75e+04 |\n",
      "| misc/time_elapsed       | 126      |\n",
      "| misc/total_timesteps    | 2.75e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.76     |\n",
      "| fps                     | 298      |\n",
      "| loss/approxkl           | 0.0133   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.221    |\n",
      "| loss/policy_loss        | -0.0294  |\n",
      "| loss/value_loss         | 0.0415   |\n",
      "| misc/explained_variance | 0.409    |\n",
      "| misc/nupdates           | 870      |\n",
      "| misc/serial_timesteps   | 2.78e+04 |\n",
      "| misc/time_elapsed       | 127      |\n",
      "| misc/total_timesteps    | 2.78e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.77     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.0159   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.242    |\n",
      "| loss/policy_loss        | -0.0322  |\n",
      "| loss/value_loss         | 0.0602   |\n",
      "| misc/explained_variance | 0.27     |\n",
      "| misc/nupdates           | 880      |\n",
      "| misc/serial_timesteps   | 2.82e+04 |\n",
      "| misc/time_elapsed       | 129      |\n",
      "| misc/total_timesteps    | 2.82e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.83     |\n",
      "| fps                     | 309      |\n",
      "| loss/approxkl           | 0.038    |\n",
      "| loss/clipfrac           | 0.148    |\n",
      "| loss/policy_entropy     | 0.31     |\n",
      "| loss/policy_loss        | -0.0463  |\n",
      "| loss/value_loss         | 0.0972   |\n",
      "| misc/explained_variance | -0.286   |\n",
      "| misc/nupdates           | 890      |\n",
      "| misc/serial_timesteps   | 2.85e+04 |\n",
      "| misc/time_elapsed       | 130      |\n",
      "| misc/total_timesteps    | 2.85e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.8      |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0114   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.232    |\n",
      "| loss/policy_loss        | -0.0469  |\n",
      "| loss/value_loss         | 0.0462   |\n",
      "| misc/explained_variance | 0.154    |\n",
      "| misc/nupdates           | 900      |\n",
      "| misc/serial_timesteps   | 2.88e+04 |\n",
      "| misc/time_elapsed       | 131      |\n",
      "| misc/total_timesteps    | 2.88e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.87     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.0347   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.293    |\n",
      "| loss/policy_loss        | -0.025   |\n",
      "| loss/value_loss         | 0.0797   |\n",
      "| misc/explained_variance | 0.00384  |\n",
      "| misc/nupdates           | 910      |\n",
      "| misc/serial_timesteps   | 2.91e+04 |\n",
      "| misc/time_elapsed       | 133      |\n",
      "| misc/total_timesteps    | 2.91e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.81     |\n",
      "| fps                     | 173      |\n",
      "| loss/approxkl           | 0.0107   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.268    |\n",
      "| loss/policy_loss        | -0.0317  |\n",
      "| loss/value_loss         | 0.0598   |\n",
      "| misc/explained_variance | -0.0826  |\n",
      "| misc/nupdates           | 920      |\n",
      "| misc/serial_timesteps   | 2.94e+04 |\n",
      "| misc/time_elapsed       | 135      |\n",
      "| misc/total_timesteps    | 2.94e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.83     |\n",
      "| fps                     | 220      |\n",
      "| loss/approxkl           | 0.0037   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.17     |\n",
      "| loss/policy_loss        | -0.0208  |\n",
      "| loss/value_loss         | 0.033    |\n",
      "| misc/explained_variance | 0.284    |\n",
      "| misc/nupdates           | 930      |\n",
      "| misc/serial_timesteps   | 2.98e+04 |\n",
      "| misc/time_elapsed       | 136      |\n",
      "| misc/total_timesteps    | 2.98e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.86     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0112   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.26     |\n",
      "| loss/policy_loss        | -0.0347  |\n",
      "| loss/value_loss         | 0.0595   |\n",
      "| misc/explained_variance | 0.217    |\n",
      "| misc/nupdates           | 940      |\n",
      "| misc/serial_timesteps   | 3.01e+04 |\n",
      "| misc/time_elapsed       | 138      |\n",
      "| misc/total_timesteps    | 3.01e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 172      |\n",
      "| loss/approxkl           | 0.00433  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.224    |\n",
      "| loss/policy_loss        | -0.0307  |\n",
      "| loss/value_loss         | 0.0406   |\n",
      "| misc/explained_variance | -0.00573 |\n",
      "| misc/nupdates           | 950      |\n",
      "| misc/serial_timesteps   | 3.04e+04 |\n",
      "| misc/time_elapsed       | 140      |\n",
      "| misc/total_timesteps    | 3.04e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.88     |\n",
      "| fps                     | 221      |\n",
      "| loss/approxkl           | 0.00594  |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.201    |\n",
      "| loss/policy_loss        | -0.0253  |\n",
      "| loss/value_loss         | 0.0307   |\n",
      "| misc/explained_variance | 0.362    |\n",
      "| misc/nupdates           | 960      |\n",
      "| misc/serial_timesteps   | 3.07e+04 |\n",
      "| misc/time_elapsed       | 141      |\n",
      "| misc/total_timesteps    | 3.07e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 176      |\n",
      "| loss/approxkl           | 0.0293   |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.202    |\n",
      "| loss/policy_loss        | -0.0444  |\n",
      "| loss/value_loss         | 0.0623   |\n",
      "| misc/explained_variance | -0.108   |\n",
      "| misc/nupdates           | 970      |\n",
      "| misc/serial_timesteps   | 3.1e+04  |\n",
      "| misc/time_elapsed       | 143      |\n",
      "| misc/total_timesteps    | 3.1e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.87     |\n",
      "| fps                     | 303      |\n",
      "| loss/approxkl           | 0.0134   |\n",
      "| loss/clipfrac           | 0.102    |\n",
      "| loss/policy_entropy     | 0.205    |\n",
      "| loss/policy_loss        | -0.025   |\n",
      "| loss/value_loss         | 0.048    |\n",
      "| misc/explained_variance | 0.363    |\n",
      "| misc/nupdates           | 980      |\n",
      "| misc/serial_timesteps   | 3.14e+04 |\n",
      "| misc/time_elapsed       | 144      |\n",
      "| misc/total_timesteps    | 3.14e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.0144   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.214    |\n",
      "| loss/policy_loss        | -0.0309  |\n",
      "| loss/value_loss         | 0.032    |\n",
      "| misc/explained_variance | 0.204    |\n",
      "| misc/nupdates           | 990      |\n",
      "| misc/serial_timesteps   | 3.17e+04 |\n",
      "| misc/time_elapsed       | 146      |\n",
      "| misc/total_timesteps    | 3.17e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 178      |\n",
      "| loss/approxkl           | 0.00675  |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.119    |\n",
      "| loss/policy_loss        | -0.03    |\n",
      "| loss/value_loss         | 0.0225   |\n",
      "| misc/explained_variance | 0.179    |\n",
      "| misc/nupdates           | 1e+03    |\n",
      "| misc/serial_timesteps   | 3.2e+04  |\n",
      "| misc/time_elapsed       | 147      |\n",
      "| misc/total_timesteps    | 3.2e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.86     |\n",
      "| fps                     | 194      |\n",
      "| loss/approxkl           | 0.0149   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.215    |\n",
      "| loss/policy_loss        | -0.0376  |\n",
      "| loss/value_loss         | 0.04     |\n",
      "| misc/explained_variance | 0.194    |\n",
      "| misc/nupdates           | 1.01e+03 |\n",
      "| misc/serial_timesteps   | 3.23e+04 |\n",
      "| misc/time_elapsed       | 149      |\n",
      "| misc/total_timesteps    | 3.23e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 241      |\n",
      "| loss/approxkl           | 0.0134   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.214    |\n",
      "| loss/policy_loss        | -0.0298  |\n",
      "| loss/value_loss         | 0.0265   |\n",
      "| misc/explained_variance | 0.123    |\n",
      "| misc/nupdates           | 1.02e+03 |\n",
      "| misc/serial_timesteps   | 3.26e+04 |\n",
      "| misc/time_elapsed       | 151      |\n",
      "| misc/total_timesteps    | 3.26e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.85     |\n",
      "| fps                     | 173      |\n",
      "| loss/approxkl           | 0.0108   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.151    |\n",
      "| loss/policy_loss        | -0.0217  |\n",
      "| loss/value_loss         | 0.022    |\n",
      "| misc/explained_variance | 0.288    |\n",
      "| misc/nupdates           | 1.03e+03 |\n",
      "| misc/serial_timesteps   | 3.3e+04  |\n",
      "| misc/time_elapsed       | 152      |\n",
      "| misc/total_timesteps    | 3.3e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 0.00823  |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.191    |\n",
      "| loss/policy_loss        | -0.0316  |\n",
      "| loss/value_loss         | 0.0374   |\n",
      "| misc/explained_variance | 0.0434   |\n",
      "| misc/nupdates           | 1.04e+03 |\n",
      "| misc/serial_timesteps   | 3.33e+04 |\n",
      "| misc/time_elapsed       | 154      |\n",
      "| misc/total_timesteps    | 3.33e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 195      |\n",
      "| loss/approxkl           | 0.0221   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.134    |\n",
      "| loss/policy_loss        | -0.022   |\n",
      "| loss/value_loss         | 0.034    |\n",
      "| misc/explained_variance | -0.257   |\n",
      "| misc/nupdates           | 1.05e+03 |\n",
      "| misc/serial_timesteps   | 3.36e+04 |\n",
      "| misc/time_elapsed       | 155      |\n",
      "| misc/total_timesteps    | 3.36e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 193      |\n",
      "| loss/approxkl           | 0.0356   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.187    |\n",
      "| loss/policy_loss        | -0.0331  |\n",
      "| loss/value_loss         | 0.0331   |\n",
      "| misc/explained_variance | 0.459    |\n",
      "| misc/nupdates           | 1.06e+03 |\n",
      "| misc/serial_timesteps   | 3.39e+04 |\n",
      "| misc/time_elapsed       | 157      |\n",
      "| misc/total_timesteps    | 3.39e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.013    |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.193    |\n",
      "| loss/policy_loss        | -0.0408  |\n",
      "| loss/value_loss         | 0.027    |\n",
      "| misc/explained_variance | 0.348    |\n",
      "| misc/nupdates           | 1.07e+03 |\n",
      "| misc/serial_timesteps   | 3.42e+04 |\n",
      "| misc/time_elapsed       | 159      |\n",
      "| misc/total_timesteps    | 3.42e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.0354   |\n",
      "| loss/clipfrac           | 0.102    |\n",
      "| loss/policy_entropy     | 0.206    |\n",
      "| loss/policy_loss        | -0.0352  |\n",
      "| loss/value_loss         | 0.0269   |\n",
      "| misc/explained_variance | -0.576   |\n",
      "| misc/nupdates           | 1.08e+03 |\n",
      "| misc/serial_timesteps   | 3.46e+04 |\n",
      "| misc/time_elapsed       | 160      |\n",
      "| misc/total_timesteps    | 3.46e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.83     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0222   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.159    |\n",
      "| loss/policy_loss        | -0.0357  |\n",
      "| loss/value_loss         | 0.0566   |\n",
      "| misc/explained_variance | 0.182    |\n",
      "| misc/nupdates           | 1.09e+03 |\n",
      "| misc/serial_timesteps   | 3.49e+04 |\n",
      "| misc/time_elapsed       | 162      |\n",
      "| misc/total_timesteps    | 3.49e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 178      |\n",
      "| loss/approxkl           | 0.00307  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.114    |\n",
      "| loss/policy_loss        | -0.0171  |\n",
      "| loss/value_loss         | 0.0195   |\n",
      "| misc/explained_variance | -0.202   |\n",
      "| misc/nupdates           | 1.1e+03  |\n",
      "| misc/serial_timesteps   | 3.52e+04 |\n",
      "| misc/time_elapsed       | 164      |\n",
      "| misc/total_timesteps    | 3.52e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.88     |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.0152   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.174    |\n",
      "| loss/policy_loss        | -0.0291  |\n",
      "| loss/value_loss         | 0.0412   |\n",
      "| misc/explained_variance | 0.177    |\n",
      "| misc/nupdates           | 1.11e+03 |\n",
      "| misc/serial_timesteps   | 3.55e+04 |\n",
      "| misc/time_elapsed       | 165      |\n",
      "| misc/total_timesteps    | 3.55e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 180      |\n",
      "| loss/approxkl           | 0.0221   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.16     |\n",
      "| loss/policy_loss        | -0.0255  |\n",
      "| loss/value_loss         | 0.0467   |\n",
      "| misc/explained_variance | 0.0559   |\n",
      "| misc/nupdates           | 1.12e+03 |\n",
      "| misc/serial_timesteps   | 3.58e+04 |\n",
      "| misc/time_elapsed       | 167      |\n",
      "| misc/total_timesteps    | 3.58e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.00892  |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.119    |\n",
      "| loss/policy_loss        | -0.0216  |\n",
      "| loss/value_loss         | 0.0178   |\n",
      "| misc/explained_variance | 0.304    |\n",
      "| misc/nupdates           | 1.13e+03 |\n",
      "| misc/serial_timesteps   | 3.62e+04 |\n",
      "| misc/time_elapsed       | 168      |\n",
      "| misc/total_timesteps    | 3.62e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.88     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0148   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.143    |\n",
      "| loss/policy_loss        | -0.0318  |\n",
      "| loss/value_loss         | 0.0336   |\n",
      "| misc/explained_variance | 0.211    |\n",
      "| misc/nupdates           | 1.14e+03 |\n",
      "| misc/serial_timesteps   | 3.65e+04 |\n",
      "| misc/time_elapsed       | 170      |\n",
      "| misc/total_timesteps    | 3.65e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.87     |\n",
      "| fps                     | 175      |\n",
      "| loss/approxkl           | 0.0386   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.107    |\n",
      "| loss/policy_loss        | -0.0379  |\n",
      "| loss/value_loss         | 0.0245   |\n",
      "| misc/explained_variance | 0.42     |\n",
      "| misc/nupdates           | 1.15e+03 |\n",
      "| misc/serial_timesteps   | 3.68e+04 |\n",
      "| misc/time_elapsed       | 172      |\n",
      "| misc/total_timesteps    | 3.68e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.027    |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.132    |\n",
      "| loss/policy_loss        | -0.0221  |\n",
      "| loss/value_loss         | 0.0225   |\n",
      "| misc/explained_variance | 0.0907   |\n",
      "| misc/nupdates           | 1.16e+03 |\n",
      "| misc/serial_timesteps   | 3.71e+04 |\n",
      "| misc/time_elapsed       | 173      |\n",
      "| misc/total_timesteps    | 3.71e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.037    |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.168    |\n",
      "| loss/policy_loss        | -0.0318  |\n",
      "| loss/value_loss         | 0.0487   |\n",
      "| misc/explained_variance | 0.274    |\n",
      "| misc/nupdates           | 1.17e+03 |\n",
      "| misc/serial_timesteps   | 3.74e+04 |\n",
      "| misc/time_elapsed       | 175      |\n",
      "| misc/total_timesteps    | 3.74e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0261   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.152    |\n",
      "| loss/policy_loss        | -0.0314  |\n",
      "| loss/value_loss         | 0.0395   |\n",
      "| misc/explained_variance | 0.0664   |\n",
      "| misc/nupdates           | 1.18e+03 |\n",
      "| misc/serial_timesteps   | 3.78e+04 |\n",
      "| misc/time_elapsed       | 177      |\n",
      "| misc/total_timesteps    | 3.78e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 249      |\n",
      "| loss/approxkl           | 0.0265   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.101    |\n",
      "| loss/policy_loss        | -0.0308  |\n",
      "| loss/value_loss         | 0.0318   |\n",
      "| misc/explained_variance | 0.268    |\n",
      "| misc/nupdates           | 1.19e+03 |\n",
      "| misc/serial_timesteps   | 3.81e+04 |\n",
      "| misc/time_elapsed       | 178      |\n",
      "| misc/total_timesteps    | 3.81e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 187      |\n",
      "| loss/approxkl           | 0.00764  |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.144    |\n",
      "| loss/policy_loss        | -0.0264  |\n",
      "| loss/value_loss         | 0.0257   |\n",
      "| misc/explained_variance | -0.637   |\n",
      "| misc/nupdates           | 1.2e+03  |\n",
      "| misc/serial_timesteps   | 3.84e+04 |\n",
      "| misc/time_elapsed       | 180      |\n",
      "| misc/total_timesteps    | 3.84e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.0417   |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0784   |\n",
      "| loss/policy_loss        | -0.0217  |\n",
      "| loss/value_loss         | 0.0213   |\n",
      "| misc/explained_variance | 0.288    |\n",
      "| misc/nupdates           | 1.21e+03 |\n",
      "| misc/serial_timesteps   | 3.87e+04 |\n",
      "| misc/time_elapsed       | 182      |\n",
      "| misc/total_timesteps    | 3.87e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.0122   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.112    |\n",
      "| loss/policy_loss        | -0.0346  |\n",
      "| loss/value_loss         | 0.0533   |\n",
      "| misc/explained_variance | 0.0359   |\n",
      "| misc/nupdates           | 1.22e+03 |\n",
      "| misc/serial_timesteps   | 3.9e+04  |\n",
      "| misc/time_elapsed       | 183      |\n",
      "| misc/total_timesteps    | 3.9e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0196   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.105    |\n",
      "| loss/policy_loss        | -0.0221  |\n",
      "| loss/value_loss         | 0.0586   |\n",
      "| misc/explained_variance | 0.115    |\n",
      "| misc/nupdates           | 1.23e+03 |\n",
      "| misc/serial_timesteps   | 3.94e+04 |\n",
      "| misc/time_elapsed       | 185      |\n",
      "| misc/total_timesteps    | 3.94e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.00224  |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.12     |\n",
      "| loss/policy_loss        | -0.0224  |\n",
      "| loss/value_loss         | 0.0211   |\n",
      "| misc/explained_variance | -0.228   |\n",
      "| misc/nupdates           | 1.24e+03 |\n",
      "| misc/serial_timesteps   | 3.97e+04 |\n",
      "| misc/time_elapsed       | 187      |\n",
      "| misc/total_timesteps    | 3.97e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.0135   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.06     |\n",
      "| loss/policy_loss        | -0.015   |\n",
      "| loss/value_loss         | 0.0209   |\n",
      "| misc/explained_variance | 0.181    |\n",
      "| misc/nupdates           | 1.25e+03 |\n",
      "| misc/serial_timesteps   | 4e+04    |\n",
      "| misc/time_elapsed       | 188      |\n",
      "| misc/total_timesteps    | 4e+04    |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0604   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.145    |\n",
      "| loss/policy_loss        | -0.0363  |\n",
      "| loss/value_loss         | 0.0307   |\n",
      "| misc/explained_variance | -0.0967  |\n",
      "| misc/nupdates           | 1.26e+03 |\n",
      "| misc/serial_timesteps   | 4.03e+04 |\n",
      "| misc/time_elapsed       | 190      |\n",
      "| misc/total_timesteps    | 4.03e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 169      |\n",
      "| loss/approxkl           | 0.00854  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.155    |\n",
      "| loss/policy_loss        | -0.0279  |\n",
      "| loss/value_loss         | 0.0258   |\n",
      "| misc/explained_variance | 0.0609   |\n",
      "| misc/nupdates           | 1.27e+03 |\n",
      "| misc/serial_timesteps   | 4.06e+04 |\n",
      "| misc/time_elapsed       | 192      |\n",
      "| misc/total_timesteps    | 4.06e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.0223   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0679   |\n",
      "| loss/policy_loss        | -0.0223  |\n",
      "| loss/value_loss         | 0.0195   |\n",
      "| misc/explained_variance | 0.268    |\n",
      "| misc/nupdates           | 1.28e+03 |\n",
      "| misc/serial_timesteps   | 4.1e+04  |\n",
      "| misc/time_elapsed       | 193      |\n",
      "| misc/total_timesteps    | 4.1e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.00336  |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0941   |\n",
      "| loss/policy_loss        | -0.0143  |\n",
      "| loss/value_loss         | 0.0218   |\n",
      "| misc/explained_variance | -0.512   |\n",
      "| misc/nupdates           | 1.29e+03 |\n",
      "| misc/serial_timesteps   | 4.13e+04 |\n",
      "| misc/time_elapsed       | 195      |\n",
      "| misc/total_timesteps    | 4.13e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 180      |\n",
      "| loss/approxkl           | 0.0119   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.135    |\n",
      "| loss/policy_loss        | -0.0279  |\n",
      "| loss/value_loss         | 0.035    |\n",
      "| misc/explained_variance | 0.0833   |\n",
      "| misc/nupdates           | 1.3e+03  |\n",
      "| misc/serial_timesteps   | 4.16e+04 |\n",
      "| misc/time_elapsed       | 196      |\n",
      "| misc/total_timesteps    | 4.16e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0179   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.105    |\n",
      "| loss/policy_loss        | -0.0247  |\n",
      "| loss/value_loss         | 0.0367   |\n",
      "| misc/explained_variance | 0.117    |\n",
      "| misc/nupdates           | 1.31e+03 |\n",
      "| misc/serial_timesteps   | 4.19e+04 |\n",
      "| misc/time_elapsed       | 198      |\n",
      "| misc/total_timesteps    | 4.19e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0315   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0586   |\n",
      "| loss/policy_loss        | -0.0214  |\n",
      "| loss/value_loss         | 0.0156   |\n",
      "| misc/explained_variance | -0.184   |\n",
      "| misc/nupdates           | 1.32e+03 |\n",
      "| misc/serial_timesteps   | 4.22e+04 |\n",
      "| misc/time_elapsed       | 200      |\n",
      "| misc/total_timesteps    | 4.22e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 187      |\n",
      "| loss/approxkl           | 0.00511  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0609   |\n",
      "| loss/policy_loss        | -0.0132  |\n",
      "| loss/value_loss         | 0.0228   |\n",
      "| misc/explained_variance | -0.477   |\n",
      "| misc/nupdates           | 1.33e+03 |\n",
      "| misc/serial_timesteps   | 4.26e+04 |\n",
      "| misc/time_elapsed       | 201      |\n",
      "| misc/total_timesteps    | 4.26e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 187      |\n",
      "| loss/approxkl           | 0.0161   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.09     |\n",
      "| loss/policy_loss        | -0.017   |\n",
      "| loss/value_loss         | 0.0193   |\n",
      "| misc/explained_variance | -0.373   |\n",
      "| misc/nupdates           | 1.34e+03 |\n",
      "| misc/serial_timesteps   | 4.29e+04 |\n",
      "| misc/time_elapsed       | 203      |\n",
      "| misc/total_timesteps    | 4.29e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 200      |\n",
      "| loss/approxkl           | 0.00033  |\n",
      "| loss/clipfrac           | 0.00781  |\n",
      "| loss/policy_entropy     | 0.0387   |\n",
      "| loss/policy_loss        | -0.00674 |\n",
      "| loss/value_loss         | 0.00622  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 1.35e+03 |\n",
      "| misc/serial_timesteps   | 4.32e+04 |\n",
      "| misc/time_elapsed       | 205      |\n",
      "| misc/total_timesteps    | 4.32e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.85     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0553   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.15     |\n",
      "| loss/policy_loss        | -0.0361  |\n",
      "| loss/value_loss         | 0.0476   |\n",
      "| misc/explained_variance | 0.393    |\n",
      "| misc/nupdates           | 1.36e+03 |\n",
      "| misc/serial_timesteps   | 4.35e+04 |\n",
      "| misc/time_elapsed       | 206      |\n",
      "| misc/total_timesteps    | 4.35e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 195      |\n",
      "| loss/approxkl           | 0.0065   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0585   |\n",
      "| loss/policy_loss        | -0.0159  |\n",
      "| loss/value_loss         | 0.0094   |\n",
      "| misc/explained_variance | 0.366    |\n",
      "| misc/nupdates           | 1.37e+03 |\n",
      "| misc/serial_timesteps   | 4.38e+04 |\n",
      "| misc/time_elapsed       | 208      |\n",
      "| misc/total_timesteps    | 4.38e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 196      |\n",
      "| loss/approxkl           | 0.00148  |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0457   |\n",
      "| loss/policy_loss        | -0.0188  |\n",
      "| loss/value_loss         | 0.0157   |\n",
      "| misc/explained_variance | -0.109   |\n",
      "| misc/nupdates           | 1.38e+03 |\n",
      "| misc/serial_timesteps   | 4.42e+04 |\n",
      "| misc/time_elapsed       | 210      |\n",
      "| misc/total_timesteps    | 4.42e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.0307   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0562   |\n",
      "| loss/policy_loss        | -0.0169  |\n",
      "| loss/value_loss         | 0.0245   |\n",
      "| misc/explained_variance | 0.157    |\n",
      "| misc/nupdates           | 1.39e+03 |\n",
      "| misc/serial_timesteps   | 4.45e+04 |\n",
      "| misc/time_elapsed       | 211      |\n",
      "| misc/total_timesteps    | 4.45e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0186   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0761   |\n",
      "| loss/policy_loss        | -0.0242  |\n",
      "| loss/value_loss         | 0.0375   |\n",
      "| misc/explained_variance | 0.26     |\n",
      "| misc/nupdates           | 1.4e+03  |\n",
      "| misc/serial_timesteps   | 4.48e+04 |\n",
      "| misc/time_elapsed       | 213      |\n",
      "| misc/total_timesteps    | 4.48e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.00393  |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0563   |\n",
      "| loss/policy_loss        | -0.019   |\n",
      "| loss/value_loss         | 0.00827  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 1.41e+03 |\n",
      "| misc/serial_timesteps   | 4.51e+04 |\n",
      "| misc/time_elapsed       | 214      |\n",
      "| misc/total_timesteps    | 4.51e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.00138  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0478   |\n",
      "| loss/policy_loss        | -0.0114  |\n",
      "| loss/value_loss         | 0.0201   |\n",
      "| misc/explained_variance | -0.436   |\n",
      "| misc/nupdates           | 1.42e+03 |\n",
      "| misc/serial_timesteps   | 4.54e+04 |\n",
      "| misc/time_elapsed       | 216      |\n",
      "| misc/total_timesteps    | 4.54e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 0.00229  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0504   |\n",
      "| loss/policy_loss        | -0.00313 |\n",
      "| loss/value_loss         | 0.00642  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 1.43e+03 |\n",
      "| misc/serial_timesteps   | 4.58e+04 |\n",
      "| misc/time_elapsed       | 218      |\n",
      "| misc/total_timesteps    | 4.58e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.00937  |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0559   |\n",
      "| loss/policy_loss        | -0.0146  |\n",
      "| loss/value_loss         | 0.0275   |\n",
      "| misc/explained_variance | 0.0118   |\n",
      "| misc/nupdates           | 1.44e+03 |\n",
      "| misc/serial_timesteps   | 4.61e+04 |\n",
      "| misc/time_elapsed       | 219      |\n",
      "| misc/total_timesteps    | 4.61e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.0235   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0733   |\n",
      "| loss/policy_loss        | -0.0218  |\n",
      "| loss/value_loss         | 0.0171   |\n",
      "| misc/explained_variance | -0.203   |\n",
      "| misc/nupdates           | 1.45e+03 |\n",
      "| misc/serial_timesteps   | 4.64e+04 |\n",
      "| misc/time_elapsed       | 221      |\n",
      "| misc/total_timesteps    | 4.64e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0585   |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0646   |\n",
      "| loss/policy_loss        | -0.0129  |\n",
      "| loss/value_loss         | 0.0155   |\n",
      "| misc/explained_variance | 0.0856   |\n",
      "| misc/nupdates           | 1.46e+03 |\n",
      "| misc/serial_timesteps   | 4.67e+04 |\n",
      "| misc/time_elapsed       | 223      |\n",
      "| misc/total_timesteps    | 4.67e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.103    |\n",
      "| loss/clipfrac           | 0.133    |\n",
      "| loss/policy_entropy     | 0.115    |\n",
      "| loss/policy_loss        | -0.0468  |\n",
      "| loss/value_loss         | 0.0565   |\n",
      "| misc/explained_variance | 0.173    |\n",
      "| misc/nupdates           | 1.47e+03 |\n",
      "| misc/serial_timesteps   | 4.7e+04  |\n",
      "| misc/time_elapsed       | 224      |\n",
      "| misc/total_timesteps    | 4.7e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0474   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.11     |\n",
      "| loss/policy_loss        | -0.0343  |\n",
      "| loss/value_loss         | 0.0441   |\n",
      "| misc/explained_variance | 0.391    |\n",
      "| misc/nupdates           | 1.48e+03 |\n",
      "| misc/serial_timesteps   | 4.74e+04 |\n",
      "| misc/time_elapsed       | 226      |\n",
      "| misc/total_timesteps    | 4.74e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 5.92e-05 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0205   |\n",
      "| loss/policy_loss        | -0.00317 |\n",
      "| loss/value_loss         | 0.0203   |\n",
      "| misc/explained_variance | -0.452   |\n",
      "| misc/nupdates           | 1.49e+03 |\n",
      "| misc/serial_timesteps   | 4.77e+04 |\n",
      "| misc/time_elapsed       | 228      |\n",
      "| misc/total_timesteps    | 4.77e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0354   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0546   |\n",
      "| loss/policy_loss        | -0.0211  |\n",
      "| loss/value_loss         | 0.0305   |\n",
      "| misc/explained_variance | -0.221   |\n",
      "| misc/nupdates           | 1.5e+03  |\n",
      "| misc/serial_timesteps   | 4.8e+04  |\n",
      "| misc/time_elapsed       | 229      |\n",
      "| misc/total_timesteps    | 4.8e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0105   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.09     |\n",
      "| loss/policy_loss        | -0.0271  |\n",
      "| loss/value_loss         | 0.0357   |\n",
      "| misc/explained_variance | -0.292   |\n",
      "| misc/nupdates           | 1.51e+03 |\n",
      "| misc/serial_timesteps   | 4.83e+04 |\n",
      "| misc/time_elapsed       | 231      |\n",
      "| misc/total_timesteps    | 4.83e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0336   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.127    |\n",
      "| loss/policy_loss        | -0.0278  |\n",
      "| loss/value_loss         | 0.0226   |\n",
      "| misc/explained_variance | 0.421    |\n",
      "| misc/nupdates           | 1.52e+03 |\n",
      "| misc/serial_timesteps   | 4.86e+04 |\n",
      "| misc/time_elapsed       | 233      |\n",
      "| misc/total_timesteps    | 4.86e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 206      |\n",
      "| loss/approxkl           | 0.0109   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.0949   |\n",
      "| loss/policy_loss        | -0.0226  |\n",
      "| loss/value_loss         | 0.0353   |\n",
      "| misc/explained_variance | 0.152    |\n",
      "| misc/nupdates           | 1.53e+03 |\n",
      "| misc/serial_timesteps   | 4.9e+04  |\n",
      "| misc/time_elapsed       | 234      |\n",
      "| misc/total_timesteps    | 4.9e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 174      |\n",
      "| loss/approxkl           | 0.00409  |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0584   |\n",
      "| loss/policy_loss        | -0.0152  |\n",
      "| loss/value_loss         | 0.0291   |\n",
      "| misc/explained_variance | 0.308    |\n",
      "| misc/nupdates           | 1.54e+03 |\n",
      "| misc/serial_timesteps   | 4.93e+04 |\n",
      "| misc/time_elapsed       | 236      |\n",
      "| misc/total_timesteps    | 4.93e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.00286  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0502   |\n",
      "| loss/policy_loss        | -0.0124  |\n",
      "| loss/value_loss         | 0.0132   |\n",
      "| misc/explained_variance | 0.131    |\n",
      "| misc/nupdates           | 1.55e+03 |\n",
      "| misc/serial_timesteps   | 4.96e+04 |\n",
      "| misc/time_elapsed       | 238      |\n",
      "| misc/total_timesteps    | 4.96e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.00431  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0541   |\n",
      "| loss/policy_loss        | -0.015   |\n",
      "| loss/value_loss         | 0.0115   |\n",
      "| misc/explained_variance | 0.208    |\n",
      "| misc/nupdates           | 1.56e+03 |\n",
      "| misc/serial_timesteps   | 4.99e+04 |\n",
      "| misc/time_elapsed       | 239      |\n",
      "| misc/total_timesteps    | 4.99e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.88     |\n",
      "| fps                     | 382      |\n",
      "| loss/approxkl           | 0.0811   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.103    |\n",
      "| loss/policy_loss        | -0.0416  |\n",
      "| loss/value_loss         | 0.0466   |\n",
      "| misc/explained_variance | 0.306    |\n",
      "| misc/nupdates           | 1.57e+03 |\n",
      "| misc/serial_timesteps   | 5.02e+04 |\n",
      "| misc/time_elapsed       | 241      |\n",
      "| misc/total_timesteps    | 5.02e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 196      |\n",
      "| loss/approxkl           | 0.0192   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0612   |\n",
      "| loss/policy_loss        | -0.019   |\n",
      "| loss/value_loss         | 0.0102   |\n",
      "| misc/explained_variance | 0.254    |\n",
      "| misc/nupdates           | 1.58e+03 |\n",
      "| misc/serial_timesteps   | 5.06e+04 |\n",
      "| misc/time_elapsed       | 242      |\n",
      "| misc/total_timesteps    | 5.06e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 298      |\n",
      "| loss/approxkl           | 0.00109  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0314   |\n",
      "| loss/policy_loss        | -0.0107  |\n",
      "| loss/value_loss         | 0.00293  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 1.59e+03 |\n",
      "| misc/serial_timesteps   | 5.09e+04 |\n",
      "| misc/time_elapsed       | 243      |\n",
      "| misc/total_timesteps    | 5.09e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 0.0165   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.046    |\n",
      "| loss/policy_loss        | -0.00989 |\n",
      "| loss/value_loss         | 0.0241   |\n",
      "| misc/explained_variance | 0.134    |\n",
      "| misc/nupdates           | 1.6e+03  |\n",
      "| misc/serial_timesteps   | 5.12e+04 |\n",
      "| misc/time_elapsed       | 245      |\n",
      "| misc/total_timesteps    | 5.12e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 171      |\n",
      "| loss/approxkl           | 6.05e-05 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0202   |\n",
      "| loss/policy_loss        | -0.00275 |\n",
      "| loss/value_loss         | 0.00601  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 1.61e+03 |\n",
      "| misc/serial_timesteps   | 5.15e+04 |\n",
      "| misc/time_elapsed       | 247      |\n",
      "| misc/total_timesteps    | 5.15e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 0.145    |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.0793   |\n",
      "| loss/policy_loss        | -0.0442  |\n",
      "| loss/value_loss         | 0.0481   |\n",
      "| misc/explained_variance | 0.282    |\n",
      "| misc/nupdates           | 1.62e+03 |\n",
      "| misc/serial_timesteps   | 5.18e+04 |\n",
      "| misc/time_elapsed       | 248      |\n",
      "| misc/total_timesteps    | 5.18e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.0263   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0962   |\n",
      "| loss/policy_loss        | -0.0219  |\n",
      "| loss/value_loss         | 0.0339   |\n",
      "| misc/explained_variance | 0.441    |\n",
      "| misc/nupdates           | 1.63e+03 |\n",
      "| misc/serial_timesteps   | 5.22e+04 |\n",
      "| misc/time_elapsed       | 250      |\n",
      "| misc/total_timesteps    | 5.22e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0205   |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0331   |\n",
      "| loss/policy_loss        | -0.0111  |\n",
      "| loss/value_loss         | 0.0178   |\n",
      "| misc/explained_variance | 0.37     |\n",
      "| misc/nupdates           | 1.64e+03 |\n",
      "| misc/serial_timesteps   | 5.25e+04 |\n",
      "| misc/time_elapsed       | 252      |\n",
      "| misc/total_timesteps    | 5.25e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.0229   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0588   |\n",
      "| loss/policy_loss        | -0.0179  |\n",
      "| loss/value_loss         | 0.0245   |\n",
      "| misc/explained_variance | 0.413    |\n",
      "| misc/nupdates           | 1.65e+03 |\n",
      "| misc/serial_timesteps   | 5.28e+04 |\n",
      "| misc/time_elapsed       | 253      |\n",
      "| misc/total_timesteps    | 5.28e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.0602   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0688   |\n",
      "| loss/policy_loss        | -0.0142  |\n",
      "| loss/value_loss         | 0.0221   |\n",
      "| misc/explained_variance | 0.288    |\n",
      "| misc/nupdates           | 1.66e+03 |\n",
      "| misc/serial_timesteps   | 5.31e+04 |\n",
      "| misc/time_elapsed       | 255      |\n",
      "| misc/total_timesteps    | 5.31e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 169      |\n",
      "| loss/approxkl           | 0.0138   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.0692   |\n",
      "| loss/policy_loss        | -0.0335  |\n",
      "| loss/value_loss         | 0.0306   |\n",
      "| misc/explained_variance | 0.242    |\n",
      "| misc/nupdates           | 1.67e+03 |\n",
      "| misc/serial_timesteps   | 5.34e+04 |\n",
      "| misc/time_elapsed       | 257      |\n",
      "| misc/total_timesteps    | 5.34e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 409      |\n",
      "| loss/approxkl           | 0.0358   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0622   |\n",
      "| loss/policy_loss        | -0.0314  |\n",
      "| loss/value_loss         | 0.0269   |\n",
      "| misc/explained_variance | 0.0751   |\n",
      "| misc/nupdates           | 1.68e+03 |\n",
      "| misc/serial_timesteps   | 5.38e+04 |\n",
      "| misc/time_elapsed       | 258      |\n",
      "| misc/total_timesteps    | 5.38e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 379      |\n",
      "| loss/approxkl           | 0.00653  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0462   |\n",
      "| loss/policy_loss        | -0.0125  |\n",
      "| loss/value_loss         | 0.0248   |\n",
      "| misc/explained_variance | 0.0934   |\n",
      "| misc/nupdates           | 1.69e+03 |\n",
      "| misc/serial_timesteps   | 5.41e+04 |\n",
      "| misc/time_elapsed       | 258      |\n",
      "| misc/total_timesteps    | 5.41e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 476      |\n",
      "| loss/approxkl           | 0.0146   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0497   |\n",
      "| loss/policy_loss        | -0.0194  |\n",
      "| loss/value_loss         | 0.0248   |\n",
      "| misc/explained_variance | 0.142    |\n",
      "| misc/nupdates           | 1.7e+03  |\n",
      "| misc/serial_timesteps   | 5.44e+04 |\n",
      "| misc/time_elapsed       | 259      |\n",
      "| misc/total_timesteps    | 5.44e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.98      |\n",
      "| fps                     | 187       |\n",
      "| loss/approxkl           | 4.25e-06  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0182    |\n",
      "| loss/policy_loss        | -0.000351 |\n",
      "| loss/value_loss         | 0.0148    |\n",
      "| misc/explained_variance | 0.0131    |\n",
      "| misc/nupdates           | 1.71e+03  |\n",
      "| misc/serial_timesteps   | 5.47e+04  |\n",
      "| misc/time_elapsed       | 260       |\n",
      "| misc/total_timesteps    | 5.47e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 501      |\n",
      "| loss/approxkl           | 0.00721  |\n",
      "| loss/clipfrac           | 0.00781  |\n",
      "| loss/policy_entropy     | 0.0345   |\n",
      "| loss/policy_loss        | -0.00855 |\n",
      "| loss/value_loss         | 0.0219   |\n",
      "| misc/explained_variance | 0.228    |\n",
      "| misc/nupdates           | 1.72e+03 |\n",
      "| misc/serial_timesteps   | 5.5e+04  |\n",
      "| misc/time_elapsed       | 261      |\n",
      "| misc/total_timesteps    | 5.5e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 498      |\n",
      "| loss/approxkl           | 0.000421 |\n",
      "| loss/clipfrac           | 0.00781  |\n",
      "| loss/policy_entropy     | 0.0289   |\n",
      "| loss/policy_loss        | -0.00395 |\n",
      "| loss/value_loss         | 0.0325   |\n",
      "| misc/explained_variance | -0.214   |\n",
      "| misc/nupdates           | 1.73e+03 |\n",
      "| misc/serial_timesteps   | 5.54e+04 |\n",
      "| misc/time_elapsed       | 262      |\n",
      "| misc/total_timesteps    | 5.54e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.88     |\n",
      "| fps                     | 287      |\n",
      "| loss/approxkl           | 0.0666   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.0869   |\n",
      "| loss/policy_loss        | -0.0195  |\n",
      "| loss/value_loss         | 0.0434   |\n",
      "| misc/explained_variance | 0.22     |\n",
      "| misc/nupdates           | 1.74e+03 |\n",
      "| misc/serial_timesteps   | 5.57e+04 |\n",
      "| misc/time_elapsed       | 263      |\n",
      "| misc/total_timesteps    | 5.57e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 415      |\n",
      "| loss/approxkl           | 0.00861  |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.1      |\n",
      "| loss/policy_loss        | -0.0207  |\n",
      "| loss/value_loss         | 0.0259   |\n",
      "| misc/explained_variance | 0.366    |\n",
      "| misc/nupdates           | 1.75e+03 |\n",
      "| misc/serial_timesteps   | 5.6e+04  |\n",
      "| misc/time_elapsed       | 264      |\n",
      "| misc/total_timesteps    | 5.6e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.88     |\n",
      "| fps                     | 256      |\n",
      "| loss/approxkl           | 0.0287   |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0446   |\n",
      "| loss/policy_loss        | -0.0154  |\n",
      "| loss/value_loss         | 0.0281   |\n",
      "| misc/explained_variance | -0.0106  |\n",
      "| misc/nupdates           | 1.76e+03 |\n",
      "| misc/serial_timesteps   | 5.63e+04 |\n",
      "| misc/time_elapsed       | 265      |\n",
      "| misc/total_timesteps    | 5.63e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 384      |\n",
      "| loss/approxkl           | 0.0972   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0778   |\n",
      "| loss/policy_loss        | -0.0302  |\n",
      "| loss/value_loss         | 0.0176   |\n",
      "| misc/explained_variance | 0.378    |\n",
      "| misc/nupdates           | 1.77e+03 |\n",
      "| misc/serial_timesteps   | 5.66e+04 |\n",
      "| misc/time_elapsed       | 265      |\n",
      "| misc/total_timesteps    | 5.66e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 298      |\n",
      "| loss/approxkl           | 0.0167   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0612   |\n",
      "| loss/policy_loss        | -0.0223  |\n",
      "| loss/value_loss         | 0.0248   |\n",
      "| misc/explained_variance | 0.149    |\n",
      "| misc/nupdates           | 1.78e+03 |\n",
      "| misc/serial_timesteps   | 5.7e+04  |\n",
      "| misc/time_elapsed       | 266      |\n",
      "| misc/total_timesteps    | 5.7e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 421      |\n",
      "| loss/approxkl           | 0.0263   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0814   |\n",
      "| loss/policy_loss        | -0.0289  |\n",
      "| loss/value_loss         | 0.044    |\n",
      "| misc/explained_variance | 0.15     |\n",
      "| misc/nupdates           | 1.79e+03 |\n",
      "| misc/serial_timesteps   | 5.73e+04 |\n",
      "| misc/time_elapsed       | 267      |\n",
      "| misc/total_timesteps    | 5.73e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.97      |\n",
      "| fps                     | 463       |\n",
      "| loss/approxkl           | 5.02e-07  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00703   |\n",
      "| loss/policy_loss        | -0.000398 |\n",
      "| loss/value_loss         | 0.00428   |\n",
      "| misc/explained_variance | nan       |\n",
      "| misc/nupdates           | 1.8e+03   |\n",
      "| misc/serial_timesteps   | 5.76e+04  |\n",
      "| misc/time_elapsed       | 268       |\n",
      "| misc/total_timesteps    | 5.76e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 278      |\n",
      "| loss/approxkl           | 0.0123   |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0229   |\n",
      "| loss/policy_loss        | -0.00982 |\n",
      "| loss/value_loss         | 0.0104   |\n",
      "| misc/explained_variance | 0.254    |\n",
      "| misc/nupdates           | 1.81e+03 |\n",
      "| misc/serial_timesteps   | 5.79e+04 |\n",
      "| misc/time_elapsed       | 269      |\n",
      "| misc/total_timesteps    | 5.79e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 244      |\n",
      "| loss/approxkl           | 0.0164   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.112    |\n",
      "| loss/policy_loss        | -0.0263  |\n",
      "| loss/value_loss         | 0.028    |\n",
      "| misc/explained_variance | 0.315    |\n",
      "| misc/nupdates           | 1.82e+03 |\n",
      "| misc/serial_timesteps   | 5.82e+04 |\n",
      "| misc/time_elapsed       | 270      |\n",
      "| misc/total_timesteps    | 5.82e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 323      |\n",
      "| loss/approxkl           | 0.0211   |\n",
      "| loss/clipfrac           | 0.102    |\n",
      "| loss/policy_entropy     | 0.149    |\n",
      "| loss/policy_loss        | -0.0329  |\n",
      "| loss/value_loss         | 0.0257   |\n",
      "| misc/explained_variance | 0.351    |\n",
      "| misc/nupdates           | 1.83e+03 |\n",
      "| misc/serial_timesteps   | 5.86e+04 |\n",
      "| misc/time_elapsed       | 271      |\n",
      "| misc/total_timesteps    | 5.86e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 366      |\n",
      "| loss/approxkl           | 0.0124   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0503   |\n",
      "| loss/policy_loss        | -0.0163  |\n",
      "| loss/value_loss         | 0.00615  |\n",
      "| misc/explained_variance | 0.59     |\n",
      "| misc/nupdates           | 1.84e+03 |\n",
      "| misc/serial_timesteps   | 5.89e+04 |\n",
      "| misc/time_elapsed       | 272      |\n",
      "| misc/total_timesteps    | 5.89e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 365      |\n",
      "| loss/approxkl           | 0.0255   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.058    |\n",
      "| loss/policy_loss        | -0.0311  |\n",
      "| loss/value_loss         | 0.0378   |\n",
      "| misc/explained_variance | 0.342    |\n",
      "| misc/nupdates           | 1.85e+03 |\n",
      "| misc/serial_timesteps   | 5.92e+04 |\n",
      "| misc/time_elapsed       | 273      |\n",
      "| misc/total_timesteps    | 5.92e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 539      |\n",
      "| loss/approxkl           | 0.0106   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0729   |\n",
      "| loss/policy_loss        | -0.0284  |\n",
      "| loss/value_loss         | 0.0198   |\n",
      "| misc/explained_variance | 0.277    |\n",
      "| misc/nupdates           | 1.86e+03 |\n",
      "| misc/serial_timesteps   | 5.95e+04 |\n",
      "| misc/time_elapsed       | 274      |\n",
      "| misc/total_timesteps    | 5.95e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 435      |\n",
      "| loss/approxkl           | 0.0183   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0383   |\n",
      "| loss/policy_loss        | -0.0186  |\n",
      "| loss/value_loss         | 0.0391   |\n",
      "| misc/explained_variance | 0.0198   |\n",
      "| misc/nupdates           | 1.87e+03 |\n",
      "| misc/serial_timesteps   | 5.98e+04 |\n",
      "| misc/time_elapsed       | 275      |\n",
      "| misc/total_timesteps    | 5.98e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 337      |\n",
      "| loss/approxkl           | 0.0746   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0503   |\n",
      "| loss/policy_loss        | -0.0216  |\n",
      "| loss/value_loss         | 0.0126   |\n",
      "| misc/explained_variance | 0.537    |\n",
      "| misc/nupdates           | 1.88e+03 |\n",
      "| misc/serial_timesteps   | 6.02e+04 |\n",
      "| misc/time_elapsed       | 275      |\n",
      "| misc/total_timesteps    | 6.02e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 566      |\n",
      "| loss/approxkl           | 0.000761 |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0281   |\n",
      "| loss/policy_loss        | -0.0126  |\n",
      "| loss/value_loss         | 0.0174   |\n",
      "| misc/explained_variance | -0.287   |\n",
      "| misc/nupdates           | 1.89e+03 |\n",
      "| misc/serial_timesteps   | 6.05e+04 |\n",
      "| misc/time_elapsed       | 276      |\n",
      "| misc/total_timesteps    | 6.05e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 581      |\n",
      "| loss/approxkl           | 0.000121 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0199   |\n",
      "| loss/policy_loss        | -0.00374 |\n",
      "| loss/value_loss         | 0.00738  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 1.9e+03  |\n",
      "| misc/serial_timesteps   | 6.08e+04 |\n",
      "| misc/time_elapsed       | 276      |\n",
      "| misc/total_timesteps    | 6.08e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 491      |\n",
      "| loss/approxkl           | 0.0533   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0702   |\n",
      "| loss/policy_loss        | -0.0262  |\n",
      "| loss/value_loss         | 0.0467   |\n",
      "| misc/explained_variance | -0.12    |\n",
      "| misc/nupdates           | 1.91e+03 |\n",
      "| misc/serial_timesteps   | 6.11e+04 |\n",
      "| misc/time_elapsed       | 277      |\n",
      "| misc/total_timesteps    | 6.11e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 342      |\n",
      "| loss/approxkl           | 0.0216   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0541   |\n",
      "| loss/policy_loss        | -0.0173  |\n",
      "| loss/value_loss         | 0.0419   |\n",
      "| misc/explained_variance | -0.0332  |\n",
      "| misc/nupdates           | 1.92e+03 |\n",
      "| misc/serial_timesteps   | 6.14e+04 |\n",
      "| misc/time_elapsed       | 278      |\n",
      "| misc/total_timesteps    | 6.14e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 435      |\n",
      "| loss/approxkl           | 0.00289  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0293   |\n",
      "| loss/policy_loss        | -0.00972 |\n",
      "| loss/value_loss         | 0.0201   |\n",
      "| misc/explained_variance | 0.244    |\n",
      "| misc/nupdates           | 1.93e+03 |\n",
      "| misc/serial_timesteps   | 6.18e+04 |\n",
      "| misc/time_elapsed       | 278      |\n",
      "| misc/total_timesteps    | 6.18e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 375      |\n",
      "| loss/approxkl           | 0.0249   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0595   |\n",
      "| loss/policy_loss        | -0.0202  |\n",
      "| loss/value_loss         | 0.014    |\n",
      "| misc/explained_variance | 0.0635   |\n",
      "| misc/nupdates           | 1.94e+03 |\n",
      "| misc/serial_timesteps   | 6.21e+04 |\n",
      "| misc/time_elapsed       | 280      |\n",
      "| misc/total_timesteps    | 6.21e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 307      |\n",
      "| loss/approxkl           | 0.0401   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0751   |\n",
      "| loss/policy_loss        | -0.0222  |\n",
      "| loss/value_loss         | 0.0181   |\n",
      "| misc/explained_variance | 0.367    |\n",
      "| misc/nupdates           | 1.95e+03 |\n",
      "| misc/serial_timesteps   | 6.24e+04 |\n",
      "| misc/time_elapsed       | 281      |\n",
      "| misc/total_timesteps    | 6.24e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.00815  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0565   |\n",
      "| loss/policy_loss        | -0.00424 |\n",
      "| loss/value_loss         | 0.00585  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 1.96e+03 |\n",
      "| misc/serial_timesteps   | 6.27e+04 |\n",
      "| misc/time_elapsed       | 282      |\n",
      "| misc/total_timesteps    | 6.27e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 175      |\n",
      "| loss/approxkl           | 0.00159  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0228   |\n",
      "| loss/policy_loss        | -0.00852 |\n",
      "| loss/value_loss         | 0.00574  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 1.97e+03 |\n",
      "| misc/serial_timesteps   | 6.3e+04  |\n",
      "| misc/time_elapsed       | 284      |\n",
      "| misc/total_timesteps    | 6.3e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 192      |\n",
      "| loss/approxkl           | 0.00653  |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0662   |\n",
      "| loss/policy_loss        | -0.0235  |\n",
      "| loss/value_loss         | 0.00697  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 1.98e+03 |\n",
      "| misc/serial_timesteps   | 6.34e+04 |\n",
      "| misc/time_elapsed       | 285      |\n",
      "| misc/total_timesteps    | 6.34e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0362   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.103    |\n",
      "| loss/policy_loss        | -0.0337  |\n",
      "| loss/value_loss         | 0.0575   |\n",
      "| misc/explained_variance | 0.148    |\n",
      "| misc/nupdates           | 1.99e+03 |\n",
      "| misc/serial_timesteps   | 6.37e+04 |\n",
      "| misc/time_elapsed       | 287      |\n",
      "| misc/total_timesteps    | 6.37e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 175      |\n",
      "| loss/approxkl           | 0.0534   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0646   |\n",
      "| loss/policy_loss        | -0.00499 |\n",
      "| loss/value_loss         | 0.00483  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2e+03    |\n",
      "| misc/serial_timesteps   | 6.4e+04  |\n",
      "| misc/time_elapsed       | 289      |\n",
      "| misc/total_timesteps    | 6.4e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0168   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.084    |\n",
      "| loss/policy_loss        | -0.025   |\n",
      "| loss/value_loss         | 0.0537   |\n",
      "| misc/explained_variance | 0.00405  |\n",
      "| misc/nupdates           | 2.01e+03 |\n",
      "| misc/serial_timesteps   | 6.43e+04 |\n",
      "| misc/time_elapsed       | 290      |\n",
      "| misc/total_timesteps    | 6.43e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 192      |\n",
      "| loss/approxkl           | 0.0709   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.117    |\n",
      "| loss/policy_loss        | -0.0313  |\n",
      "| loss/value_loss         | 0.0354   |\n",
      "| misc/explained_variance | 0.188    |\n",
      "| misc/nupdates           | 2.02e+03 |\n",
      "| misc/serial_timesteps   | 6.46e+04 |\n",
      "| misc/time_elapsed       | 292      |\n",
      "| misc/total_timesteps    | 6.46e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 175      |\n",
      "| loss/approxkl           | 0.0388   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0869   |\n",
      "| loss/policy_loss        | -0.0286  |\n",
      "| loss/value_loss         | 0.0513   |\n",
      "| misc/explained_variance | 0.204    |\n",
      "| misc/nupdates           | 2.03e+03 |\n",
      "| misc/serial_timesteps   | 6.5e+04  |\n",
      "| misc/time_elapsed       | 294      |\n",
      "| misc/total_timesteps    | 6.5e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 169      |\n",
      "| loss/approxkl           | 0.0569   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.112    |\n",
      "| loss/policy_loss        | -0.0408  |\n",
      "| loss/value_loss         | 0.0362   |\n",
      "| misc/explained_variance | 0.144    |\n",
      "| misc/nupdates           | 2.04e+03 |\n",
      "| misc/serial_timesteps   | 6.53e+04 |\n",
      "| misc/time_elapsed       | 296      |\n",
      "| misc/total_timesteps    | 6.53e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 167      |\n",
      "| loss/approxkl           | 0.00428  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0628   |\n",
      "| loss/policy_loss        | -0.00963 |\n",
      "| loss/value_loss         | 0.00963  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2.05e+03 |\n",
      "| misc/serial_timesteps   | 6.56e+04 |\n",
      "| misc/time_elapsed       | 297      |\n",
      "| misc/total_timesteps    | 6.56e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 168      |\n",
      "| loss/approxkl           | 0.00611  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0442   |\n",
      "| loss/policy_loss        | -0.00813 |\n",
      "| loss/value_loss         | 0.0563   |\n",
      "| misc/explained_variance | 0.158    |\n",
      "| misc/nupdates           | 2.06e+03 |\n",
      "| misc/serial_timesteps   | 6.59e+04 |\n",
      "| misc/time_elapsed       | 299      |\n",
      "| misc/total_timesteps    | 6.59e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 175      |\n",
      "| loss/approxkl           | 0.00774  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0629   |\n",
      "| loss/policy_loss        | -0.00983 |\n",
      "| loss/value_loss         | 0.0215   |\n",
      "| misc/explained_variance | 0.192    |\n",
      "| misc/nupdates           | 2.07e+03 |\n",
      "| misc/serial_timesteps   | 6.62e+04 |\n",
      "| misc/time_elapsed       | 301      |\n",
      "| misc/total_timesteps    | 6.62e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 187      |\n",
      "| loss/approxkl           | 0.0372   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.134    |\n",
      "| loss/policy_loss        | -0.0377  |\n",
      "| loss/value_loss         | 0.0366   |\n",
      "| misc/explained_variance | 0.3      |\n",
      "| misc/nupdates           | 2.08e+03 |\n",
      "| misc/serial_timesteps   | 6.66e+04 |\n",
      "| misc/time_elapsed       | 302      |\n",
      "| misc/total_timesteps    | 6.66e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0108   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0633   |\n",
      "| loss/policy_loss        | -0.0221  |\n",
      "| loss/value_loss         | 0.0342   |\n",
      "| misc/explained_variance | 0.126    |\n",
      "| misc/nupdates           | 2.09e+03 |\n",
      "| misc/serial_timesteps   | 6.69e+04 |\n",
      "| misc/time_elapsed       | 304      |\n",
      "| misc/total_timesteps    | 6.69e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 174      |\n",
      "| loss/approxkl           | 0.0637   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.108    |\n",
      "| loss/policy_loss        | -0.0365  |\n",
      "| loss/value_loss         | 0.0293   |\n",
      "| misc/explained_variance | 0.265    |\n",
      "| misc/nupdates           | 2.1e+03  |\n",
      "| misc/serial_timesteps   | 6.72e+04 |\n",
      "| misc/time_elapsed       | 306      |\n",
      "| misc/total_timesteps    | 6.72e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 195      |\n",
      "| loss/approxkl           | 0.0202   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0737   |\n",
      "| loss/policy_loss        | -0.0308  |\n",
      "| loss/value_loss         | 0.0323   |\n",
      "| misc/explained_variance | -0.108   |\n",
      "| misc/nupdates           | 2.11e+03 |\n",
      "| misc/serial_timesteps   | 6.75e+04 |\n",
      "| misc/time_elapsed       | 307      |\n",
      "| misc/total_timesteps    | 6.75e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 172      |\n",
      "| loss/approxkl           | 0.0715   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0223   |\n",
      "| loss/policy_loss        | -0.0134  |\n",
      "| loss/value_loss         | 0.0215   |\n",
      "| misc/explained_variance | 0.273    |\n",
      "| misc/nupdates           | 2.12e+03 |\n",
      "| misc/serial_timesteps   | 6.78e+04 |\n",
      "| misc/time_elapsed       | 309      |\n",
      "| misc/total_timesteps    | 6.78e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 173      |\n",
      "| loss/approxkl           | 0.0112   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0494   |\n",
      "| loss/policy_loss        | -0.0222  |\n",
      "| loss/value_loss         | 0.0109   |\n",
      "| misc/explained_variance | 0.269    |\n",
      "| misc/nupdates           | 2.13e+03 |\n",
      "| misc/serial_timesteps   | 6.82e+04 |\n",
      "| misc/time_elapsed       | 311      |\n",
      "| misc/total_timesteps    | 6.82e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 194      |\n",
      "| loss/approxkl           | 0.0255   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0702   |\n",
      "| loss/policy_loss        | -0.0168  |\n",
      "| loss/value_loss         | 0.0373   |\n",
      "| misc/explained_variance | 0.159    |\n",
      "| misc/nupdates           | 2.14e+03 |\n",
      "| misc/serial_timesteps   | 6.85e+04 |\n",
      "| misc/time_elapsed       | 312      |\n",
      "| misc/total_timesteps    | 6.85e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 172      |\n",
      "| loss/approxkl           | 0.00525  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.033    |\n",
      "| loss/policy_loss        | -0.0131  |\n",
      "| loss/value_loss         | 0.0126   |\n",
      "| misc/explained_variance | 0.146    |\n",
      "| misc/nupdates           | 2.15e+03 |\n",
      "| misc/serial_timesteps   | 6.88e+04 |\n",
      "| misc/time_elapsed       | 314      |\n",
      "| misc/total_timesteps    | 6.88e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.0305   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.083    |\n",
      "| loss/policy_loss        | -0.0273  |\n",
      "| loss/value_loss         | 0.0384   |\n",
      "| misc/explained_variance | 0.0839   |\n",
      "| misc/nupdates           | 2.16e+03 |\n",
      "| misc/serial_timesteps   | 6.91e+04 |\n",
      "| misc/time_elapsed       | 316      |\n",
      "| misc/total_timesteps    | 6.91e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 168      |\n",
      "| loss/approxkl           | 0.00117  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0399   |\n",
      "| loss/policy_loss        | -0.0142  |\n",
      "| loss/value_loss         | 0.0113   |\n",
      "| misc/explained_variance | 0.239    |\n",
      "| misc/nupdates           | 2.17e+03 |\n",
      "| misc/serial_timesteps   | 6.94e+04 |\n",
      "| misc/time_elapsed       | 318      |\n",
      "| misc/total_timesteps    | 6.94e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.88     |\n",
      "| fps                     | 190      |\n",
      "| loss/approxkl           | 0.0288   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0447   |\n",
      "| loss/policy_loss        | -0.0157  |\n",
      "| loss/value_loss         | 0.0213   |\n",
      "| misc/explained_variance | 0.467    |\n",
      "| misc/nupdates           | 2.18e+03 |\n",
      "| misc/serial_timesteps   | 6.98e+04 |\n",
      "| misc/time_elapsed       | 319      |\n",
      "| misc/total_timesteps    | 6.98e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0644   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.047    |\n",
      "| loss/policy_loss        | -0.0223  |\n",
      "| loss/value_loss         | 0.0386   |\n",
      "| misc/explained_variance | 0.0718   |\n",
      "| misc/nupdates           | 2.19e+03 |\n",
      "| misc/serial_timesteps   | 7.01e+04 |\n",
      "| misc/time_elapsed       | 321      |\n",
      "| misc/total_timesteps    | 7.01e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 178      |\n",
      "| loss/approxkl           | 0.0389   |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0362   |\n",
      "| loss/policy_loss        | -0.0103  |\n",
      "| loss/value_loss         | 0.0113   |\n",
      "| misc/explained_variance | 0.167    |\n",
      "| misc/nupdates           | 2.2e+03  |\n",
      "| misc/serial_timesteps   | 7.04e+04 |\n",
      "| misc/time_elapsed       | 323      |\n",
      "| misc/total_timesteps    | 7.04e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 172      |\n",
      "| loss/approxkl           | 0.0247   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.084    |\n",
      "| loss/policy_loss        | -0.0277  |\n",
      "| loss/value_loss         | 0.0215   |\n",
      "| misc/explained_variance | 0.478    |\n",
      "| misc/nupdates           | 2.21e+03 |\n",
      "| misc/serial_timesteps   | 7.07e+04 |\n",
      "| misc/time_elapsed       | 324      |\n",
      "| misc/total_timesteps    | 7.07e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 174      |\n",
      "| loss/approxkl           | 0.0017   |\n",
      "| loss/clipfrac           | 0.00781  |\n",
      "| loss/policy_entropy     | 0.0246   |\n",
      "| loss/policy_loss        | -0.00979 |\n",
      "| loss/value_loss         | 0.0218   |\n",
      "| misc/explained_variance | 0.144    |\n",
      "| misc/nupdates           | 2.22e+03 |\n",
      "| misc/serial_timesteps   | 7.1e+04  |\n",
      "| misc/time_elapsed       | 326      |\n",
      "| misc/total_timesteps    | 7.1e+04  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 1.4e-05  |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.017    |\n",
      "| loss/policy_loss        | -0.00118 |\n",
      "| loss/value_loss         | 0.0138   |\n",
      "| misc/explained_variance | 0.000618 |\n",
      "| misc/nupdates           | 2.23e+03 |\n",
      "| misc/serial_timesteps   | 7.14e+04 |\n",
      "| misc/time_elapsed       | 328      |\n",
      "| misc/total_timesteps    | 7.14e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 196      |\n",
      "| loss/approxkl           | 0.0108   |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0346   |\n",
      "| loss/policy_loss        | -0.0183  |\n",
      "| loss/value_loss         | 0.0167   |\n",
      "| misc/explained_variance | -0.129   |\n",
      "| misc/nupdates           | 2.24e+03 |\n",
      "| misc/serial_timesteps   | 7.17e+04 |\n",
      "| misc/time_elapsed       | 329      |\n",
      "| misc/total_timesteps    | 7.17e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 173      |\n",
      "| loss/approxkl           | 0.011    |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0778   |\n",
      "| loss/policy_loss        | -0.0244  |\n",
      "| loss/value_loss         | 0.0291   |\n",
      "| misc/explained_variance | -0.0524  |\n",
      "| misc/nupdates           | 2.25e+03 |\n",
      "| misc/serial_timesteps   | 7.2e+04  |\n",
      "| misc/time_elapsed       | 331      |\n",
      "| misc/total_timesteps    | 7.2e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 196      |\n",
      "| loss/approxkl           | 0.0264   |\n",
      "| loss/clipfrac           | 0.102    |\n",
      "| loss/policy_entropy     | 0.118    |\n",
      "| loss/policy_loss        | -0.0482  |\n",
      "| loss/value_loss         | 0.0334   |\n",
      "| misc/explained_variance | 0.172    |\n",
      "| misc/nupdates           | 2.26e+03 |\n",
      "| misc/serial_timesteps   | 7.23e+04 |\n",
      "| misc/time_elapsed       | 333      |\n",
      "| misc/total_timesteps    | 7.23e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.95      |\n",
      "| fps                     | 189       |\n",
      "| loss/approxkl           | 4.27e-07  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00697   |\n",
      "| loss/policy_loss        | -6.46e-05 |\n",
      "| loss/value_loss         | 0.00329   |\n",
      "| misc/explained_variance | nan       |\n",
      "| misc/nupdates           | 2.27e+03  |\n",
      "| misc/serial_timesteps   | 7.26e+04  |\n",
      "| misc/time_elapsed       | 334       |\n",
      "| misc/total_timesteps    | 7.26e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.0328   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0736   |\n",
      "| loss/policy_loss        | -0.0348  |\n",
      "| loss/value_loss         | 0.0376   |\n",
      "| misc/explained_variance | 0.31     |\n",
      "| misc/nupdates           | 2.28e+03 |\n",
      "| misc/serial_timesteps   | 7.3e+04  |\n",
      "| misc/time_elapsed       | 336      |\n",
      "| misc/total_timesteps    | 7.3e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 314      |\n",
      "| loss/approxkl           | 0.0662   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0468   |\n",
      "| loss/policy_loss        | -0.0243  |\n",
      "| loss/value_loss         | 0.0189   |\n",
      "| misc/explained_variance | 0.374    |\n",
      "| misc/nupdates           | 2.29e+03 |\n",
      "| misc/serial_timesteps   | 7.33e+04 |\n",
      "| misc/time_elapsed       | 337      |\n",
      "| misc/total_timesteps    | 7.33e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 305      |\n",
      "| loss/approxkl           | 0.0474   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0753   |\n",
      "| loss/policy_loss        | -0.0165  |\n",
      "| loss/value_loss         | 0.0234   |\n",
      "| misc/explained_variance | 0.141    |\n",
      "| misc/nupdates           | 2.3e+03  |\n",
      "| misc/serial_timesteps   | 7.36e+04 |\n",
      "| misc/time_elapsed       | 338      |\n",
      "| misc/total_timesteps    | 7.36e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.000868 |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0281   |\n",
      "| loss/policy_loss        | -0.00485 |\n",
      "| loss/value_loss         | 0.00348  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2.31e+03 |\n",
      "| misc/serial_timesteps   | 7.39e+04 |\n",
      "| misc/time_elapsed       | 340      |\n",
      "| misc/total_timesteps    | 7.39e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.000188 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0218   |\n",
      "| loss/policy_loss        | -0.00556 |\n",
      "| loss/value_loss         | 0.00529  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2.32e+03 |\n",
      "| misc/serial_timesteps   | 7.42e+04 |\n",
      "| misc/time_elapsed       | 342      |\n",
      "| misc/total_timesteps    | 7.42e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 168      |\n",
      "| loss/approxkl           | 0.00576  |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0457   |\n",
      "| loss/policy_loss        | -0.00818 |\n",
      "| loss/value_loss         | 0.0155   |\n",
      "| misc/explained_variance | -0.0573  |\n",
      "| misc/nupdates           | 2.33e+03 |\n",
      "| misc/serial_timesteps   | 7.46e+04 |\n",
      "| misc/time_elapsed       | 343      |\n",
      "| misc/total_timesteps    | 7.46e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.00377  |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0379   |\n",
      "| loss/policy_loss        | -0.0139  |\n",
      "| loss/value_loss         | 0.0173   |\n",
      "| misc/explained_variance | -0.273   |\n",
      "| misc/nupdates           | 2.34e+03 |\n",
      "| misc/serial_timesteps   | 7.49e+04 |\n",
      "| misc/time_elapsed       | 345      |\n",
      "| misc/total_timesteps    | 7.49e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 180      |\n",
      "| loss/approxkl           | 0.0476   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0965   |\n",
      "| loss/policy_loss        | -0.0299  |\n",
      "| loss/value_loss         | 0.0366   |\n",
      "| misc/explained_variance | 0.0913   |\n",
      "| misc/nupdates           | 2.35e+03 |\n",
      "| misc/serial_timesteps   | 7.52e+04 |\n",
      "| misc/time_elapsed       | 346      |\n",
      "| misc/total_timesteps    | 7.52e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.00345  |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0426   |\n",
      "| loss/policy_loss        | -0.0185  |\n",
      "| loss/value_loss         | 0.0147   |\n",
      "| misc/explained_variance | -0.0242  |\n",
      "| misc/nupdates           | 2.36e+03 |\n",
      "| misc/serial_timesteps   | 7.55e+04 |\n",
      "| misc/time_elapsed       | 348      |\n",
      "| misc/total_timesteps    | 7.55e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.0811   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.0891   |\n",
      "| loss/policy_loss        | -0.0348  |\n",
      "| loss/value_loss         | 0.0497   |\n",
      "| misc/explained_variance | 0.263    |\n",
      "| misc/nupdates           | 2.37e+03 |\n",
      "| misc/serial_timesteps   | 7.58e+04 |\n",
      "| misc/time_elapsed       | 350      |\n",
      "| misc/total_timesteps    | 7.58e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 178      |\n",
      "| loss/approxkl           | 0.0413   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.121    |\n",
      "| loss/policy_loss        | -0.0411  |\n",
      "| loss/value_loss         | 0.0445   |\n",
      "| misc/explained_variance | 0.168    |\n",
      "| misc/nupdates           | 2.38e+03 |\n",
      "| misc/serial_timesteps   | 7.62e+04 |\n",
      "| misc/time_elapsed       | 352      |\n",
      "| misc/total_timesteps    | 7.62e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.0519   |\n",
      "| loss/clipfrac           | 0.102    |\n",
      "| loss/policy_entropy     | 0.096    |\n",
      "| loss/policy_loss        | -0.0273  |\n",
      "| loss/value_loss         | 0.042    |\n",
      "| misc/explained_variance | 0.251    |\n",
      "| misc/nupdates           | 2.39e+03 |\n",
      "| misc/serial_timesteps   | 7.65e+04 |\n",
      "| misc/time_elapsed       | 353      |\n",
      "| misc/total_timesteps    | 7.65e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.0472   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.0515   |\n",
      "| loss/policy_loss        | -0.0184  |\n",
      "| loss/value_loss         | 0.0169   |\n",
      "| misc/explained_variance | -0.173   |\n",
      "| misc/nupdates           | 2.4e+03  |\n",
      "| misc/serial_timesteps   | 7.68e+04 |\n",
      "| misc/time_elapsed       | 355      |\n",
      "| misc/total_timesteps    | 7.68e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 173      |\n",
      "| loss/approxkl           | 0.0489   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.107    |\n",
      "| loss/policy_loss        | -0.0307  |\n",
      "| loss/value_loss         | 0.028    |\n",
      "| misc/explained_variance | 0.306    |\n",
      "| misc/nupdates           | 2.41e+03 |\n",
      "| misc/serial_timesteps   | 7.71e+04 |\n",
      "| misc/time_elapsed       | 357      |\n",
      "| misc/total_timesteps    | 7.71e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 187      |\n",
      "| loss/approxkl           | 0.0439   |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.055    |\n",
      "| loss/policy_loss        | -0.0212  |\n",
      "| loss/value_loss         | 0.0224   |\n",
      "| misc/explained_variance | 0.184    |\n",
      "| misc/nupdates           | 2.42e+03 |\n",
      "| misc/serial_timesteps   | 7.74e+04 |\n",
      "| misc/time_elapsed       | 358      |\n",
      "| misc/total_timesteps    | 7.74e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 200      |\n",
      "| loss/approxkl           | 0.00668  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0264   |\n",
      "| loss/policy_loss        | -0.0123  |\n",
      "| loss/value_loss         | 0.00739  |\n",
      "| misc/explained_variance | 0.549    |\n",
      "| misc/nupdates           | 2.43e+03 |\n",
      "| misc/serial_timesteps   | 7.78e+04 |\n",
      "| misc/time_elapsed       | 360      |\n",
      "| misc/total_timesteps    | 7.78e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 175      |\n",
      "| loss/approxkl           | 0.0261   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0347   |\n",
      "| loss/policy_loss        | -0.0125  |\n",
      "| loss/value_loss         | 0.0449   |\n",
      "| misc/explained_variance | 0.225    |\n",
      "| misc/nupdates           | 2.44e+03 |\n",
      "| misc/serial_timesteps   | 7.81e+04 |\n",
      "| misc/time_elapsed       | 362      |\n",
      "| misc/total_timesteps    | 7.81e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0827   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0304   |\n",
      "| loss/policy_loss        | -0.0236  |\n",
      "| loss/value_loss         | 0.0301   |\n",
      "| misc/explained_variance | 0.301    |\n",
      "| misc/nupdates           | 2.45e+03 |\n",
      "| misc/serial_timesteps   | 7.84e+04 |\n",
      "| misc/time_elapsed       | 363      |\n",
      "| misc/total_timesteps    | 7.84e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 177      |\n",
      "| loss/approxkl           | 0.0417   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0488   |\n",
      "| loss/policy_loss        | -0.025   |\n",
      "| loss/value_loss         | 0.0165   |\n",
      "| misc/explained_variance | 0.425    |\n",
      "| misc/nupdates           | 2.46e+03 |\n",
      "| misc/serial_timesteps   | 7.87e+04 |\n",
      "| misc/time_elapsed       | 365      |\n",
      "| misc/total_timesteps    | 7.87e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 175      |\n",
      "| loss/approxkl           | 0.00508  |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.061    |\n",
      "| loss/policy_loss        | -0.0193  |\n",
      "| loss/value_loss         | 0.0165   |\n",
      "| misc/explained_variance | 0.409    |\n",
      "| misc/nupdates           | 2.47e+03 |\n",
      "| misc/serial_timesteps   | 7.9e+04  |\n",
      "| misc/time_elapsed       | 367      |\n",
      "| misc/total_timesteps    | 7.9e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.0223   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0487   |\n",
      "| loss/policy_loss        | -0.0138  |\n",
      "| loss/value_loss         | 0.0124   |\n",
      "| misc/explained_variance | 0.167    |\n",
      "| misc/nupdates           | 2.48e+03 |\n",
      "| misc/serial_timesteps   | 7.94e+04 |\n",
      "| misc/time_elapsed       | 369      |\n",
      "| misc/total_timesteps    | 7.94e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 198      |\n",
      "| loss/approxkl           | 0.0149   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0581   |\n",
      "| loss/policy_loss        | -0.0225  |\n",
      "| loss/value_loss         | 0.0202   |\n",
      "| misc/explained_variance | 0.252    |\n",
      "| misc/nupdates           | 2.49e+03 |\n",
      "| misc/serial_timesteps   | 7.97e+04 |\n",
      "| misc/time_elapsed       | 370      |\n",
      "| misc/total_timesteps    | 7.97e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0293   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.0654   |\n",
      "| loss/policy_loss        | -0.0195  |\n",
      "| loss/value_loss         | 0.025    |\n",
      "| misc/explained_variance | 0.127    |\n",
      "| misc/nupdates           | 2.5e+03  |\n",
      "| misc/serial_timesteps   | 8e+04    |\n",
      "| misc/time_elapsed       | 372      |\n",
      "| misc/total_timesteps    | 8e+04    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 368      |\n",
      "| loss/approxkl           | 0.0516   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0706   |\n",
      "| loss/policy_loss        | -0.0205  |\n",
      "| loss/value_loss         | 0.0625   |\n",
      "| misc/explained_variance | 0.105    |\n",
      "| misc/nupdates           | 2.51e+03 |\n",
      "| misc/serial_timesteps   | 8.03e+04 |\n",
      "| misc/time_elapsed       | 373      |\n",
      "| misc/total_timesteps    | 8.03e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 173      |\n",
      "| loss/approxkl           | 0.00605  |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.044    |\n",
      "| loss/policy_loss        | -0.0121  |\n",
      "| loss/value_loss         | 0.0255   |\n",
      "| misc/explained_variance | 0.105    |\n",
      "| misc/nupdates           | 2.52e+03 |\n",
      "| misc/serial_timesteps   | 8.06e+04 |\n",
      "| misc/time_elapsed       | 375      |\n",
      "| misc/total_timesteps    | 8.06e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 307      |\n",
      "| loss/approxkl           | 0.0467   |\n",
      "| loss/clipfrac           | 0.117    |\n",
      "| loss/policy_entropy     | 0.126    |\n",
      "| loss/policy_loss        | -0.0446  |\n",
      "| loss/value_loss         | 0.0538   |\n",
      "| misc/explained_variance | 0.348    |\n",
      "| misc/nupdates           | 2.53e+03 |\n",
      "| misc/serial_timesteps   | 8.1e+04  |\n",
      "| misc/time_elapsed       | 376      |\n",
      "| misc/total_timesteps    | 8.1e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.99     |\n",
      "| fps                     | 294      |\n",
      "| loss/approxkl           | 0.0298   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0378   |\n",
      "| loss/policy_loss        | -0.0115  |\n",
      "| loss/value_loss         | 0.0183   |\n",
      "| misc/explained_variance | -0.171   |\n",
      "| misc/nupdates           | 2.54e+03 |\n",
      "| misc/serial_timesteps   | 8.13e+04 |\n",
      "| misc/time_elapsed       | 377      |\n",
      "| misc/total_timesteps    | 8.13e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 176      |\n",
      "| loss/approxkl           | 0.114    |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0728   |\n",
      "| loss/policy_loss        | -0.0279  |\n",
      "| loss/value_loss         | 0.0369   |\n",
      "| misc/explained_variance | 0.135    |\n",
      "| misc/nupdates           | 2.55e+03 |\n",
      "| misc/serial_timesteps   | 8.16e+04 |\n",
      "| misc/time_elapsed       | 379      |\n",
      "| misc/total_timesteps    | 8.16e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 303      |\n",
      "| loss/approxkl           | 2.13e-05 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0108   |\n",
      "| loss/policy_loss        | -0.00167 |\n",
      "| loss/value_loss         | 0.0125   |\n",
      "| misc/explained_variance | 0.0621   |\n",
      "| misc/nupdates           | 2.56e+03 |\n",
      "| misc/serial_timesteps   | 8.19e+04 |\n",
      "| misc/time_elapsed       | 380      |\n",
      "| misc/total_timesteps    | 8.19e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 303      |\n",
      "| loss/approxkl           | 0.147    |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0137   |\n",
      "| loss/policy_loss        | -0.0122  |\n",
      "| loss/value_loss         | 0.0114   |\n",
      "| misc/explained_variance | 0.252    |\n",
      "| misc/nupdates           | 2.57e+03 |\n",
      "| misc/serial_timesteps   | 8.22e+04 |\n",
      "| misc/time_elapsed       | 381      |\n",
      "| misc/total_timesteps    | 8.22e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 177      |\n",
      "| loss/approxkl           | 0.0144   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0437   |\n",
      "| loss/policy_loss        | -0.0174  |\n",
      "| loss/value_loss         | 0.0156   |\n",
      "| misc/explained_variance | -0.0444  |\n",
      "| misc/nupdates           | 2.58e+03 |\n",
      "| misc/serial_timesteps   | 8.26e+04 |\n",
      "| misc/time_elapsed       | 383      |\n",
      "| misc/total_timesteps    | 8.26e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 171      |\n",
      "| loss/approxkl           | 0.0428   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0426   |\n",
      "| loss/policy_loss        | -0.0217  |\n",
      "| loss/value_loss         | 0.0133   |\n",
      "| misc/explained_variance | 0.0613   |\n",
      "| misc/nupdates           | 2.59e+03 |\n",
      "| misc/serial_timesteps   | 8.29e+04 |\n",
      "| misc/time_elapsed       | 385      |\n",
      "| misc/total_timesteps    | 8.29e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 255      |\n",
      "| loss/approxkl           | 0.0124   |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0309   |\n",
      "| loss/policy_loss        | -0.00886 |\n",
      "| loss/value_loss         | 0.0132   |\n",
      "| misc/explained_variance | 0.0172   |\n",
      "| misc/nupdates           | 2.6e+03  |\n",
      "| misc/serial_timesteps   | 8.32e+04 |\n",
      "| misc/time_elapsed       | 386      |\n",
      "| misc/total_timesteps    | 8.32e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 294      |\n",
      "| loss/approxkl           | 0.00993  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0316   |\n",
      "| loss/policy_loss        | -0.0127  |\n",
      "| loss/value_loss         | 0.0169   |\n",
      "| misc/explained_variance | -0.16    |\n",
      "| misc/nupdates           | 2.61e+03 |\n",
      "| misc/serial_timesteps   | 8.35e+04 |\n",
      "| misc/time_elapsed       | 387      |\n",
      "| misc/total_timesteps    | 8.35e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 176      |\n",
      "| loss/approxkl           | 0.11     |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.0507   |\n",
      "| loss/policy_loss        | -0.0303  |\n",
      "| loss/value_loss         | 0.0519   |\n",
      "| misc/explained_variance | 0.117    |\n",
      "| misc/nupdates           | 2.62e+03 |\n",
      "| misc/serial_timesteps   | 8.38e+04 |\n",
      "| misc/time_elapsed       | 389      |\n",
      "| misc/total_timesteps    | 8.38e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 277      |\n",
      "| loss/approxkl           | 0.0138   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0479   |\n",
      "| loss/policy_loss        | -0.0151  |\n",
      "| loss/value_loss         | 0.00935  |\n",
      "| misc/explained_variance | 0.363    |\n",
      "| misc/nupdates           | 2.63e+03 |\n",
      "| misc/serial_timesteps   | 8.42e+04 |\n",
      "| misc/time_elapsed       | 390      |\n",
      "| misc/total_timesteps    | 8.42e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 293      |\n",
      "| loss/approxkl           | 0.103    |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.0742   |\n",
      "| loss/policy_loss        | -0.0314  |\n",
      "| loss/value_loss         | 0.0489   |\n",
      "| misc/explained_variance | 0.0905   |\n",
      "| misc/nupdates           | 2.64e+03 |\n",
      "| misc/serial_timesteps   | 8.45e+04 |\n",
      "| misc/time_elapsed       | 391      |\n",
      "| misc/total_timesteps    | 8.45e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.98      |\n",
      "| fps                     | 189       |\n",
      "| loss/approxkl           | 3.04e-07  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00458   |\n",
      "| loss/policy_loss        | -2.43e-05 |\n",
      "| loss/value_loss         | 0.00316   |\n",
      "| misc/explained_variance | nan       |\n",
      "| misc/nupdates           | 2.65e+03  |\n",
      "| misc/serial_timesteps   | 8.48e+04  |\n",
      "| misc/time_elapsed       | 392       |\n",
      "| misc/total_timesteps    | 8.48e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.0733   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.133    |\n",
      "| loss/policy_loss        | -0.0373  |\n",
      "| loss/value_loss         | 0.0405   |\n",
      "| misc/explained_variance | 0.278    |\n",
      "| misc/nupdates           | 2.66e+03 |\n",
      "| misc/serial_timesteps   | 8.51e+04 |\n",
      "| misc/time_elapsed       | 394      |\n",
      "| misc/total_timesteps    | 8.51e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 8.95e-05 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0127   |\n",
      "| loss/policy_loss        | -0.00389 |\n",
      "| loss/value_loss         | 0.0154   |\n",
      "| misc/explained_variance | -0.152   |\n",
      "| misc/nupdates           | 2.67e+03 |\n",
      "| misc/serial_timesteps   | 8.54e+04 |\n",
      "| misc/time_elapsed       | 396      |\n",
      "| misc/total_timesteps    | 8.54e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 187      |\n",
      "| loss/approxkl           | 0.00801  |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0632   |\n",
      "| loss/policy_loss        | -0.0186  |\n",
      "| loss/value_loss         | 0.00957  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2.68e+03 |\n",
      "| misc/serial_timesteps   | 8.58e+04 |\n",
      "| misc/time_elapsed       | 397      |\n",
      "| misc/total_timesteps    | 8.58e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 248      |\n",
      "| loss/approxkl           | 0.16     |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.0761   |\n",
      "| loss/policy_loss        | -0.0375  |\n",
      "| loss/value_loss         | 0.031    |\n",
      "| misc/explained_variance | 0.403    |\n",
      "| misc/nupdates           | 2.69e+03 |\n",
      "| misc/serial_timesteps   | 8.61e+04 |\n",
      "| misc/time_elapsed       | 399      |\n",
      "| misc/total_timesteps    | 8.61e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 213      |\n",
      "| loss/approxkl           | 0.0124   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0896   |\n",
      "| loss/policy_loss        | -0.0234  |\n",
      "| loss/value_loss         | 0.0126   |\n",
      "| misc/explained_variance | 0.168    |\n",
      "| misc/nupdates           | 2.7e+03  |\n",
      "| misc/serial_timesteps   | 8.64e+04 |\n",
      "| misc/time_elapsed       | 400      |\n",
      "| misc/total_timesteps    | 8.64e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.0273   |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0565   |\n",
      "| loss/policy_loss        | -0.0219  |\n",
      "| loss/value_loss         | 0.0268   |\n",
      "| misc/explained_variance | 0.0935   |\n",
      "| misc/nupdates           | 2.71e+03 |\n",
      "| misc/serial_timesteps   | 8.67e+04 |\n",
      "| misc/time_elapsed       | 401      |\n",
      "| misc/total_timesteps    | 8.67e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 157      |\n",
      "| loss/approxkl           | 4e-06    |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0123   |\n",
      "| loss/policy_loss        | -0.00064 |\n",
      "| loss/value_loss         | 0.0074   |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2.72e+03 |\n",
      "| misc/serial_timesteps   | 8.7e+04  |\n",
      "| misc/time_elapsed       | 403      |\n",
      "| misc/total_timesteps    | 8.7e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 352      |\n",
      "| loss/approxkl           | 0.00355  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0212   |\n",
      "| loss/policy_loss        | -0.00705 |\n",
      "| loss/value_loss         | 0.0244   |\n",
      "| misc/explained_variance | 0.379    |\n",
      "| misc/nupdates           | 2.73e+03 |\n",
      "| misc/serial_timesteps   | 8.74e+04 |\n",
      "| misc/time_elapsed       | 404      |\n",
      "| misc/total_timesteps    | 8.74e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 298      |\n",
      "| loss/approxkl           | 0.00421  |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0528   |\n",
      "| loss/policy_loss        | -0.0162  |\n",
      "| loss/value_loss         | 0.0118   |\n",
      "| misc/explained_variance | 0.187    |\n",
      "| misc/nupdates           | 2.74e+03 |\n",
      "| misc/serial_timesteps   | 8.77e+04 |\n",
      "| misc/time_elapsed       | 405      |\n",
      "| misc/total_timesteps    | 8.77e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 295      |\n",
      "| loss/approxkl           | 0.0765   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.032    |\n",
      "| loss/policy_loss        | -0.0149  |\n",
      "| loss/value_loss         | 0.0104   |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2.75e+03 |\n",
      "| misc/serial_timesteps   | 8.8e+04  |\n",
      "| misc/time_elapsed       | 406      |\n",
      "| misc/total_timesteps    | 8.8e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 174      |\n",
      "| loss/approxkl           | 0.105    |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0165   |\n",
      "| loss/policy_loss        | -0.00944 |\n",
      "| loss/value_loss         | 0.0281   |\n",
      "| misc/explained_variance | -0.0498  |\n",
      "| misc/nupdates           | 2.76e+03 |\n",
      "| misc/serial_timesteps   | 8.83e+04 |\n",
      "| misc/time_elapsed       | 408      |\n",
      "| misc/total_timesteps    | 8.83e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.0991   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0395   |\n",
      "| loss/policy_loss        | -0.0266  |\n",
      "| loss/value_loss         | 0.0466   |\n",
      "| misc/explained_variance | 0.168    |\n",
      "| misc/nupdates           | 2.77e+03 |\n",
      "| misc/serial_timesteps   | 8.86e+04 |\n",
      "| misc/time_elapsed       | 410      |\n",
      "| misc/total_timesteps    | 8.86e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 173      |\n",
      "| loss/approxkl           | 0.0867   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0443   |\n",
      "| loss/policy_loss        | -0.021   |\n",
      "| loss/value_loss         | 0.0378   |\n",
      "| misc/explained_variance | 0.0749   |\n",
      "| misc/nupdates           | 2.78e+03 |\n",
      "| misc/serial_timesteps   | 8.9e+04  |\n",
      "| misc/time_elapsed       | 411      |\n",
      "| misc/total_timesteps    | 8.9e+04  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.0246   |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.125    |\n",
      "| loss/policy_loss        | -0.0394  |\n",
      "| loss/value_loss         | 0.0305   |\n",
      "| misc/explained_variance | -0.0842  |\n",
      "| misc/nupdates           | 2.79e+03 |\n",
      "| misc/serial_timesteps   | 8.93e+04 |\n",
      "| misc/time_elapsed       | 413      |\n",
      "| misc/total_timesteps    | 8.93e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.00996  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0448   |\n",
      "| loss/policy_loss        | -0.0154  |\n",
      "| loss/value_loss         | 0.014    |\n",
      "| misc/explained_variance | 0.0394   |\n",
      "| misc/nupdates           | 2.8e+03  |\n",
      "| misc/serial_timesteps   | 8.96e+04 |\n",
      "| misc/time_elapsed       | 415      |\n",
      "| misc/total_timesteps    | 8.96e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.0344   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.064    |\n",
      "| loss/policy_loss        | -0.0251  |\n",
      "| loss/value_loss         | 0.0167   |\n",
      "| misc/explained_variance | 0.39     |\n",
      "| misc/nupdates           | 2.81e+03 |\n",
      "| misc/serial_timesteps   | 8.99e+04 |\n",
      "| misc/time_elapsed       | 416      |\n",
      "| misc/total_timesteps    | 8.99e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0703   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.05     |\n",
      "| loss/policy_loss        | -0.0191  |\n",
      "| loss/value_loss         | 0.033    |\n",
      "| misc/explained_variance | -0.252   |\n",
      "| misc/nupdates           | 2.82e+03 |\n",
      "| misc/serial_timesteps   | 9.02e+04 |\n",
      "| misc/time_elapsed       | 418      |\n",
      "| misc/total_timesteps    | 9.02e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.96      |\n",
      "| fps                     | 221       |\n",
      "| loss/approxkl           | 0.00129   |\n",
      "| loss/clipfrac           | 0.0234    |\n",
      "| loss/policy_entropy     | 0.0252    |\n",
      "| loss/policy_loss        | -0.000757 |\n",
      "| loss/value_loss         | 0.0212    |\n",
      "| misc/explained_variance | -0.497    |\n",
      "| misc/nupdates           | 2.83e+03  |\n",
      "| misc/serial_timesteps   | 9.06e+04  |\n",
      "| misc/time_elapsed       | 419       |\n",
      "| misc/total_timesteps    | 9.06e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 180      |\n",
      "| loss/approxkl           | 0.0708   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.0756   |\n",
      "| loss/policy_loss        | -0.0271  |\n",
      "| loss/value_loss         | 0.0251   |\n",
      "| misc/explained_variance | 0.12     |\n",
      "| misc/nupdates           | 2.84e+03 |\n",
      "| misc/serial_timesteps   | 9.09e+04 |\n",
      "| misc/time_elapsed       | 421      |\n",
      "| misc/total_timesteps    | 9.09e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 170      |\n",
      "| loss/approxkl           | 0.000921 |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0229   |\n",
      "| loss/policy_loss        | -0.0108  |\n",
      "| loss/value_loss         | 0.00157  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2.85e+03 |\n",
      "| misc/serial_timesteps   | 9.12e+04 |\n",
      "| misc/time_elapsed       | 423      |\n",
      "| misc/total_timesteps    | 9.12e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 303      |\n",
      "| loss/approxkl           | 0.0228   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0671   |\n",
      "| loss/policy_loss        | -0.0172  |\n",
      "| loss/value_loss         | 0.0319   |\n",
      "| misc/explained_variance | 0.225    |\n",
      "| misc/nupdates           | 2.86e+03 |\n",
      "| misc/serial_timesteps   | 9.15e+04 |\n",
      "| misc/time_elapsed       | 424      |\n",
      "| misc/total_timesteps    | 9.15e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 311      |\n",
      "| loss/approxkl           | 0.00131  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0195   |\n",
      "| loss/policy_loss        | -0.00982 |\n",
      "| loss/value_loss         | 0.0124   |\n",
      "| misc/explained_variance | 0.0986   |\n",
      "| misc/nupdates           | 2.87e+03 |\n",
      "| misc/serial_timesteps   | 9.18e+04 |\n",
      "| misc/time_elapsed       | 425      |\n",
      "| misc/total_timesteps    | 9.18e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 295      |\n",
      "| loss/approxkl           | 3.81e-09 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0022   |\n",
      "| loss/policy_loss        | -2.3e-05 |\n",
      "| loss/value_loss         | 0.0136   |\n",
      "| misc/explained_variance | 0.067    |\n",
      "| misc/nupdates           | 2.88e+03 |\n",
      "| misc/serial_timesteps   | 9.22e+04 |\n",
      "| misc/time_elapsed       | 426      |\n",
      "| misc/total_timesteps    | 9.22e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 295      |\n",
      "| loss/approxkl           | 0.000837 |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0165   |\n",
      "| loss/policy_loss        | -0.00944 |\n",
      "| loss/value_loss         | 0.00614  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2.89e+03 |\n",
      "| misc/serial_timesteps   | 9.25e+04 |\n",
      "| misc/time_elapsed       | 427      |\n",
      "| misc/total_timesteps    | 9.25e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.0198   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0157   |\n",
      "| loss/policy_loss        | -0.0125  |\n",
      "| loss/value_loss         | 0.00808  |\n",
      "| misc/explained_variance | 0.393    |\n",
      "| misc/nupdates           | 2.9e+03  |\n",
      "| misc/serial_timesteps   | 9.28e+04 |\n",
      "| misc/time_elapsed       | 428      |\n",
      "| misc/total_timesteps    | 9.28e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 387      |\n",
      "| loss/approxkl           | 0.0999   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0539   |\n",
      "| loss/policy_loss        | -0.0312  |\n",
      "| loss/value_loss         | 0.0271   |\n",
      "| misc/explained_variance | 0.0618   |\n",
      "| misc/nupdates           | 2.91e+03 |\n",
      "| misc/serial_timesteps   | 9.31e+04 |\n",
      "| misc/time_elapsed       | 430      |\n",
      "| misc/total_timesteps    | 9.31e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 169      |\n",
      "| loss/approxkl           | 0.0373   |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0185   |\n",
      "| loss/policy_loss        | -0.0112  |\n",
      "| loss/value_loss         | 0.0113   |\n",
      "| misc/explained_variance | 0.205    |\n",
      "| misc/nupdates           | 2.92e+03 |\n",
      "| misc/serial_timesteps   | 9.34e+04 |\n",
      "| misc/time_elapsed       | 431      |\n",
      "| misc/total_timesteps    | 9.34e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 224      |\n",
      "| loss/approxkl           | 0.0127   |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0431   |\n",
      "| loss/policy_loss        | -0.00694 |\n",
      "| loss/value_loss         | 0.00934  |\n",
      "| misc/explained_variance | 0.305    |\n",
      "| misc/nupdates           | 2.93e+03 |\n",
      "| misc/serial_timesteps   | 9.38e+04 |\n",
      "| misc/time_elapsed       | 433      |\n",
      "| misc/total_timesteps    | 9.38e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 172      |\n",
      "| loss/approxkl           | 0.000874 |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.042    |\n",
      "| loss/policy_loss        | -0.0165  |\n",
      "| loss/value_loss         | 0.028    |\n",
      "| misc/explained_variance | 0.0216   |\n",
      "| misc/nupdates           | 2.94e+03 |\n",
      "| misc/serial_timesteps   | 9.41e+04 |\n",
      "| misc/time_elapsed       | 434      |\n",
      "| misc/total_timesteps    | 9.41e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 191      |\n",
      "| loss/approxkl           | 0.00233  |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0321   |\n",
      "| loss/policy_loss        | -0.00753 |\n",
      "| loss/value_loss         | 0.00423  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 2.95e+03 |\n",
      "| misc/serial_timesteps   | 9.44e+04 |\n",
      "| misc/time_elapsed       | 436      |\n",
      "| misc/total_timesteps    | 9.44e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 172      |\n",
      "| loss/approxkl           | 7.76e-05 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0124   |\n",
      "| loss/policy_loss        | -0.00299 |\n",
      "| loss/value_loss         | 0.0325   |\n",
      "| misc/explained_variance | -0.161   |\n",
      "| misc/nupdates           | 2.96e+03 |\n",
      "| misc/serial_timesteps   | 9.47e+04 |\n",
      "| misc/time_elapsed       | 437      |\n",
      "| misc/total_timesteps    | 9.47e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 284      |\n",
      "| loss/approxkl           | 0.0211   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0403   |\n",
      "| loss/policy_loss        | -0.0123  |\n",
      "| loss/value_loss         | 0.014    |\n",
      "| misc/explained_variance | 0.0146   |\n",
      "| misc/nupdates           | 2.97e+03 |\n",
      "| misc/serial_timesteps   | 9.5e+04  |\n",
      "| misc/time_elapsed       | 439      |\n",
      "| misc/total_timesteps    | 9.5e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 180      |\n",
      "| loss/approxkl           | 0.0947   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0157   |\n",
      "| loss/policy_loss        | -0.0131  |\n",
      "| loss/value_loss         | 0.0153   |\n",
      "| misc/explained_variance | -0.0441  |\n",
      "| misc/nupdates           | 2.98e+03 |\n",
      "| misc/serial_timesteps   | 9.54e+04 |\n",
      "| misc/time_elapsed       | 440      |\n",
      "| misc/total_timesteps    | 9.54e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 158      |\n",
      "| loss/approxkl           | 0.0293   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0469   |\n",
      "| loss/policy_loss        | -0.021   |\n",
      "| loss/value_loss         | 0.0503   |\n",
      "| misc/explained_variance | 0.276    |\n",
      "| misc/nupdates           | 2.99e+03 |\n",
      "| misc/serial_timesteps   | 9.57e+04 |\n",
      "| misc/time_elapsed       | 442      |\n",
      "| misc/total_timesteps    | 9.57e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 274      |\n",
      "| loss/approxkl           | 0.0305   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0356   |\n",
      "| loss/policy_loss        | -0.013   |\n",
      "| loss/value_loss         | 0.015    |\n",
      "| misc/explained_variance | 0.0213   |\n",
      "| misc/nupdates           | 3e+03    |\n",
      "| misc/serial_timesteps   | 9.6e+04  |\n",
      "| misc/time_elapsed       | 443      |\n",
      "| misc/total_timesteps    | 9.6e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 191      |\n",
      "| loss/approxkl           | 0.0167   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0566   |\n",
      "| loss/policy_loss        | -0.031   |\n",
      "| loss/value_loss         | 0.054    |\n",
      "| misc/explained_variance | 0.0156   |\n",
      "| misc/nupdates           | 3.01e+03 |\n",
      "| misc/serial_timesteps   | 9.63e+04 |\n",
      "| misc/time_elapsed       | 444      |\n",
      "| misc/total_timesteps    | 9.63e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 200      |\n",
      "| loss/approxkl           | 0.0188   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0215   |\n",
      "| loss/policy_loss        | -0.011   |\n",
      "| loss/value_loss         | 0.029    |\n",
      "| misc/explained_variance | 0.304    |\n",
      "| misc/nupdates           | 3.02e+03 |\n",
      "| misc/serial_timesteps   | 9.66e+04 |\n",
      "| misc/time_elapsed       | 446      |\n",
      "| misc/total_timesteps    | 9.66e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 269      |\n",
      "| loss/approxkl           | 0.0132   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0269   |\n",
      "| loss/policy_loss        | -0.016   |\n",
      "| loss/value_loss         | 0.0184   |\n",
      "| misc/explained_variance | -0.228   |\n",
      "| misc/nupdates           | 3.03e+03 |\n",
      "| misc/serial_timesteps   | 9.7e+04  |\n",
      "| misc/time_elapsed       | 448      |\n",
      "| misc/total_timesteps    | 9.7e+04  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 169      |\n",
      "| loss/approxkl           | 0.0344   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0274   |\n",
      "| loss/policy_loss        | -0.0145  |\n",
      "| loss/value_loss         | 0.0124   |\n",
      "| misc/explained_variance | 0.111    |\n",
      "| misc/nupdates           | 3.04e+03 |\n",
      "| misc/serial_timesteps   | 9.73e+04 |\n",
      "| misc/time_elapsed       | 449      |\n",
      "| misc/total_timesteps    | 9.73e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.193    |\n",
      "| loss/clipfrac           | 0.109    |\n",
      "| loss/policy_entropy     | 0.0823   |\n",
      "| loss/policy_loss        | -0.0474  |\n",
      "| loss/value_loss         | 0.0271   |\n",
      "| misc/explained_variance | 0.325    |\n",
      "| misc/nupdates           | 3.05e+03 |\n",
      "| misc/serial_timesteps   | 9.76e+04 |\n",
      "| misc/time_elapsed       | 451      |\n",
      "| misc/total_timesteps    | 9.76e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.013    |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0346   |\n",
      "| loss/policy_loss        | -0.014   |\n",
      "| loss/value_loss         | 0.0209   |\n",
      "| misc/explained_variance | -0.429   |\n",
      "| misc/nupdates           | 3.06e+03 |\n",
      "| misc/serial_timesteps   | 9.79e+04 |\n",
      "| misc/time_elapsed       | 452      |\n",
      "| misc/total_timesteps    | 9.79e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 176      |\n",
      "| loss/approxkl           | 0.000444 |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0142   |\n",
      "| loss/policy_loss        | -0.00567 |\n",
      "| loss/value_loss         | 0.0154   |\n",
      "| misc/explained_variance | -0.0441  |\n",
      "| misc/nupdates           | 3.07e+03 |\n",
      "| misc/serial_timesteps   | 9.82e+04 |\n",
      "| misc/time_elapsed       | 454      |\n",
      "| misc/total_timesteps    | 9.82e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 0.0114   |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0184   |\n",
      "| loss/policy_loss        | -0.00398 |\n",
      "| loss/value_loss         | 0.00175  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.08e+03 |\n",
      "| misc/serial_timesteps   | 9.86e+04 |\n",
      "| misc/time_elapsed       | 455      |\n",
      "| misc/total_timesteps    | 9.86e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.000236 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0141   |\n",
      "| loss/policy_loss        | -0.00801 |\n",
      "| loss/value_loss         | 0.00342  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.09e+03 |\n",
      "| misc/serial_timesteps   | 9.89e+04 |\n",
      "| misc/time_elapsed       | 457      |\n",
      "| misc/total_timesteps    | 9.89e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.99     |\n",
      "| fps                     | 177      |\n",
      "| loss/approxkl           | 0.0055   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0322   |\n",
      "| loss/policy_loss        | -0.0115  |\n",
      "| loss/value_loss         | 0.00246  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.1e+03  |\n",
      "| misc/serial_timesteps   | 9.92e+04 |\n",
      "| misc/time_elapsed       | 459      |\n",
      "| misc/total_timesteps    | 9.92e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 187      |\n",
      "| loss/approxkl           | 0.0842   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0555   |\n",
      "| loss/policy_loss        | -0.0145  |\n",
      "| loss/value_loss         | 0.0161   |\n",
      "| misc/explained_variance | 0.431    |\n",
      "| misc/nupdates           | 3.11e+03 |\n",
      "| misc/serial_timesteps   | 9.95e+04 |\n",
      "| misc/time_elapsed       | 460      |\n",
      "| misc/total_timesteps    | 9.95e+04 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.93      |\n",
      "| fps                     | 185       |\n",
      "| loss/approxkl           | 8.75e-07  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00901   |\n",
      "| loss/policy_loss        | -0.000273 |\n",
      "| loss/value_loss         | 0.0259    |\n",
      "| misc/explained_variance | 0.0829    |\n",
      "| misc/nupdates           | 3.12e+03  |\n",
      "| misc/serial_timesteps   | 9.98e+04  |\n",
      "| misc/time_elapsed       | 462       |\n",
      "| misc/total_timesteps    | 9.98e+04  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 180      |\n",
      "| loss/approxkl           | 0.019    |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0292   |\n",
      "| loss/policy_loss        | -0.0143  |\n",
      "| loss/value_loss         | 0.00396  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.13e+03 |\n",
      "| misc/serial_timesteps   | 1e+05    |\n",
      "| misc/time_elapsed       | 464      |\n",
      "| misc/total_timesteps    | 1e+05    |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0659   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0352   |\n",
      "| loss/policy_loss        | -0.0205  |\n",
      "| loss/value_loss         | 0.0147   |\n",
      "| misc/explained_variance | -0.0495  |\n",
      "| misc/nupdates           | 3.14e+03 |\n",
      "| misc/serial_timesteps   | 1e+05    |\n",
      "| misc/time_elapsed       | 465      |\n",
      "| misc/total_timesteps    | 1e+05    |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 0.000609 |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0128   |\n",
      "| loss/policy_loss        | -0.00616 |\n",
      "| loss/value_loss         | 0.00242  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.15e+03 |\n",
      "| misc/serial_timesteps   | 1.01e+05 |\n",
      "| misc/time_elapsed       | 467      |\n",
      "| misc/total_timesteps    | 1.01e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.119    |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0596   |\n",
      "| loss/policy_loss        | -0.0232  |\n",
      "| loss/value_loss         | 0.0331   |\n",
      "| misc/explained_variance | -0.21    |\n",
      "| misc/nupdates           | 3.16e+03 |\n",
      "| misc/serial_timesteps   | 1.01e+05 |\n",
      "| misc/time_elapsed       | 469      |\n",
      "| misc/total_timesteps    | 1.01e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.97      |\n",
      "| fps                     | 188       |\n",
      "| loss/approxkl           | 3.77e-08  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00375   |\n",
      "| loss/policy_loss        | -2.05e-05 |\n",
      "| loss/value_loss         | 0.00153   |\n",
      "| misc/explained_variance | nan       |\n",
      "| misc/nupdates           | 3.17e+03  |\n",
      "| misc/serial_timesteps   | 1.01e+05  |\n",
      "| misc/time_elapsed       | 470       |\n",
      "| misc/total_timesteps    | 1.01e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 1.86e-05 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.00762  |\n",
      "| loss/policy_loss        | -0.00238 |\n",
      "| loss/value_loss         | 0.00979  |\n",
      "| misc/explained_variance | 0.27     |\n",
      "| misc/nupdates           | 3.18e+03 |\n",
      "| misc/serial_timesteps   | 1.02e+05 |\n",
      "| misc/time_elapsed       | 472      |\n",
      "| misc/total_timesteps    | 1.02e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 178      |\n",
      "| loss/approxkl           | 0.195    |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.0553   |\n",
      "| loss/policy_loss        | -0.0364  |\n",
      "| loss/value_loss         | 0.0199   |\n",
      "| misc/explained_variance | 0.277    |\n",
      "| misc/nupdates           | 3.19e+03 |\n",
      "| misc/serial_timesteps   | 1.02e+05 |\n",
      "| misc/time_elapsed       | 474      |\n",
      "| misc/total_timesteps    | 1.02e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.96      |\n",
      "| fps                     | 194       |\n",
      "| loss/approxkl           | 4.71e-07  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.008     |\n",
      "| loss/policy_loss        | -0.000184 |\n",
      "| loss/value_loss         | 0.00457   |\n",
      "| misc/explained_variance | nan       |\n",
      "| misc/nupdates           | 3.2e+03   |\n",
      "| misc/serial_timesteps   | 1.02e+05  |\n",
      "| misc/time_elapsed       | 475       |\n",
      "| misc/total_timesteps    | 1.02e+05  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 204      |\n",
      "| loss/approxkl           | 0.00247  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0194   |\n",
      "| loss/policy_loss        | -0.00675 |\n",
      "| loss/value_loss         | 0.00562  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.21e+03 |\n",
      "| misc/serial_timesteps   | 1.03e+05 |\n",
      "| misc/time_elapsed       | 477      |\n",
      "| misc/total_timesteps    | 1.03e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.134    |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0871   |\n",
      "| loss/policy_loss        | -0.0367  |\n",
      "| loss/value_loss         | 0.0203   |\n",
      "| misc/explained_variance | 0.497    |\n",
      "| misc/nupdates           | 3.22e+03 |\n",
      "| misc/serial_timesteps   | 1.03e+05 |\n",
      "| misc/time_elapsed       | 479      |\n",
      "| misc/total_timesteps    | 1.03e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.00144  |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0309   |\n",
      "| loss/policy_loss        | -0.0149  |\n",
      "| loss/value_loss         | 0.00667  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.23e+03 |\n",
      "| misc/serial_timesteps   | 1.03e+05 |\n",
      "| misc/time_elapsed       | 480      |\n",
      "| misc/total_timesteps    | 1.03e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 195      |\n",
      "| loss/approxkl           | 0.163    |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0542   |\n",
      "| loss/policy_loss        | -0.0269  |\n",
      "| loss/value_loss         | 0.0446   |\n",
      "| misc/explained_variance | 0.243    |\n",
      "| misc/nupdates           | 3.24e+03 |\n",
      "| misc/serial_timesteps   | 1.04e+05 |\n",
      "| misc/time_elapsed       | 482      |\n",
      "| misc/total_timesteps    | 1.04e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 187      |\n",
      "| loss/approxkl           | 0.076    |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.036    |\n",
      "| loss/policy_loss        | -0.0258  |\n",
      "| loss/value_loss         | 0.0322   |\n",
      "| misc/explained_variance | -0.119   |\n",
      "| misc/nupdates           | 3.25e+03 |\n",
      "| misc/serial_timesteps   | 1.04e+05 |\n",
      "| misc/time_elapsed       | 483      |\n",
      "| misc/total_timesteps    | 1.04e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 0.0293   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0331   |\n",
      "| loss/policy_loss        | -0.0141  |\n",
      "| loss/value_loss         | 0.0211   |\n",
      "| misc/explained_variance | 0.197    |\n",
      "| misc/nupdates           | 3.26e+03 |\n",
      "| misc/serial_timesteps   | 1.04e+05 |\n",
      "| misc/time_elapsed       | 485      |\n",
      "| misc/total_timesteps    | 1.04e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 202      |\n",
      "| loss/approxkl           | 0.0901   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0418   |\n",
      "| loss/policy_loss        | -0.0246  |\n",
      "| loss/value_loss         | 0.0209   |\n",
      "| misc/explained_variance | 0.233    |\n",
      "| misc/nupdates           | 3.27e+03 |\n",
      "| misc/serial_timesteps   | 1.05e+05 |\n",
      "| misc/time_elapsed       | 487      |\n",
      "| misc/total_timesteps    | 1.05e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.05     |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0341   |\n",
      "| loss/policy_loss        | -0.012   |\n",
      "| loss/value_loss         | 0.00751  |\n",
      "| misc/explained_variance | 0.479    |\n",
      "| misc/nupdates           | 3.28e+03 |\n",
      "| misc/serial_timesteps   | 1.05e+05 |\n",
      "| misc/time_elapsed       | 488      |\n",
      "| misc/total_timesteps    | 1.05e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0953   |\n",
      "| loss/clipfrac           | 0.0859   |\n",
      "| loss/policy_entropy     | 0.122    |\n",
      "| loss/policy_loss        | -0.0375  |\n",
      "| loss/value_loss         | 0.0354   |\n",
      "| misc/explained_variance | 0.331    |\n",
      "| misc/nupdates           | 3.29e+03 |\n",
      "| misc/serial_timesteps   | 1.05e+05 |\n",
      "| misc/time_elapsed       | 490      |\n",
      "| misc/total_timesteps    | 1.05e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.00172  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0128   |\n",
      "| loss/policy_loss        | -0.00278 |\n",
      "| loss/value_loss         | 0.00491  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.3e+03  |\n",
      "| misc/serial_timesteps   | 1.06e+05 |\n",
      "| misc/time_elapsed       | 491      |\n",
      "| misc/total_timesteps    | 1.06e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.0525   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0309   |\n",
      "| loss/policy_loss        | -0.0118  |\n",
      "| loss/value_loss         | 0.0302   |\n",
      "| misc/explained_variance | 0.255    |\n",
      "| misc/nupdates           | 3.31e+03 |\n",
      "| misc/serial_timesteps   | 1.06e+05 |\n",
      "| misc/time_elapsed       | 493      |\n",
      "| misc/total_timesteps    | 1.06e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.00382  |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0237   |\n",
      "| loss/policy_loss        | -0.0115  |\n",
      "| loss/value_loss         | 0.0112   |\n",
      "| misc/explained_variance | 0.249    |\n",
      "| misc/nupdates           | 3.32e+03 |\n",
      "| misc/serial_timesteps   | 1.06e+05 |\n",
      "| misc/time_elapsed       | 495      |\n",
      "| misc/total_timesteps    | 1.06e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 197      |\n",
      "| loss/approxkl           | 0.0491   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0293   |\n",
      "| loss/policy_loss        | -0.017   |\n",
      "| loss/value_loss         | 0.0144   |\n",
      "| misc/explained_variance | -0.0171  |\n",
      "| misc/nupdates           | 3.33e+03 |\n",
      "| misc/serial_timesteps   | 1.07e+05 |\n",
      "| misc/time_elapsed       | 496      |\n",
      "| misc/total_timesteps    | 1.07e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 0.0425   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0235   |\n",
      "| loss/policy_loss        | -0.0122  |\n",
      "| loss/value_loss         | 0.00356  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.34e+03 |\n",
      "| misc/serial_timesteps   | 1.07e+05 |\n",
      "| misc/time_elapsed       | 498      |\n",
      "| misc/total_timesteps    | 1.07e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.0637   |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.051    |\n",
      "| loss/policy_loss        | -0.0205  |\n",
      "| loss/value_loss         | 0.0288   |\n",
      "| misc/explained_variance | -0.00267 |\n",
      "| misc/nupdates           | 3.35e+03 |\n",
      "| misc/serial_timesteps   | 1.07e+05 |\n",
      "| misc/time_elapsed       | 500      |\n",
      "| misc/total_timesteps    | 1.07e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.0362   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0651   |\n",
      "| loss/policy_loss        | -0.0307  |\n",
      "| loss/value_loss         | 0.0293   |\n",
      "| misc/explained_variance | 0.289    |\n",
      "| misc/nupdates           | 3.36e+03 |\n",
      "| misc/serial_timesteps   | 1.08e+05 |\n",
      "| misc/time_elapsed       | 501      |\n",
      "| misc/total_timesteps    | 1.08e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0984   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.048    |\n",
      "| loss/policy_loss        | -0.0174  |\n",
      "| loss/value_loss         | 0.0269   |\n",
      "| misc/explained_variance | 0.0563   |\n",
      "| misc/nupdates           | 3.37e+03 |\n",
      "| misc/serial_timesteps   | 1.08e+05 |\n",
      "| misc/time_elapsed       | 503      |\n",
      "| misc/total_timesteps    | 1.08e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 186      |\n",
      "| loss/approxkl           | 0.0209   |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0335   |\n",
      "| loss/policy_loss        | -0.0128  |\n",
      "| loss/value_loss         | 0.0109   |\n",
      "| misc/explained_variance | 0.25     |\n",
      "| misc/nupdates           | 3.38e+03 |\n",
      "| misc/serial_timesteps   | 1.08e+05 |\n",
      "| misc/time_elapsed       | 504      |\n",
      "| misc/total_timesteps    | 1.08e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.000157 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0141   |\n",
      "| loss/policy_loss        | -0.00798 |\n",
      "| loss/value_loss         | 0.00616  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.39e+03 |\n",
      "| misc/serial_timesteps   | 1.08e+05 |\n",
      "| misc/time_elapsed       | 506      |\n",
      "| misc/total_timesteps    | 1.08e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 197      |\n",
      "| loss/approxkl           | 0.122    |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0264   |\n",
      "| loss/policy_loss        | -0.0159  |\n",
      "| loss/value_loss         | 0.036    |\n",
      "| misc/explained_variance | 0.152    |\n",
      "| misc/nupdates           | 3.4e+03  |\n",
      "| misc/serial_timesteps   | 1.09e+05 |\n",
      "| misc/time_elapsed       | 508      |\n",
      "| misc/total_timesteps    | 1.09e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 193      |\n",
      "| loss/approxkl           | 0.147    |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0404   |\n",
      "| loss/policy_loss        | -0.0171  |\n",
      "| loss/value_loss         | 0.0214   |\n",
      "| misc/explained_variance | 0.215    |\n",
      "| misc/nupdates           | 3.41e+03 |\n",
      "| misc/serial_timesteps   | 1.09e+05 |\n",
      "| misc/time_elapsed       | 509      |\n",
      "| misc/total_timesteps    | 1.09e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.126    |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0644   |\n",
      "| loss/policy_loss        | -0.0239  |\n",
      "| loss/value_loss         | 0.0156   |\n",
      "| misc/explained_variance | 0.463    |\n",
      "| misc/nupdates           | 3.42e+03 |\n",
      "| misc/serial_timesteps   | 1.09e+05 |\n",
      "| misc/time_elapsed       | 511      |\n",
      "| misc/total_timesteps    | 1.09e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 206      |\n",
      "| loss/approxkl           | 0.0221   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0317   |\n",
      "| loss/policy_loss        | -0.0115  |\n",
      "| loss/value_loss         | 0.0252   |\n",
      "| misc/explained_variance | 0.138    |\n",
      "| misc/nupdates           | 3.43e+03 |\n",
      "| misc/serial_timesteps   | 1.1e+05  |\n",
      "| misc/time_elapsed       | 513      |\n",
      "| misc/total_timesteps    | 1.1e+05  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 187      |\n",
      "| loss/approxkl           | 0.0431   |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0811   |\n",
      "| loss/policy_loss        | -0.0269  |\n",
      "| loss/value_loss         | 0.0272   |\n",
      "| misc/explained_variance | 0.0193   |\n",
      "| misc/nupdates           | 3.44e+03 |\n",
      "| misc/serial_timesteps   | 1.1e+05  |\n",
      "| misc/time_elapsed       | 514      |\n",
      "| misc/total_timesteps    | 1.1e+05  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 202      |\n",
      "| loss/approxkl           | 0.00388  |\n",
      "| loss/clipfrac           | 0.0156   |\n",
      "| loss/policy_entropy     | 0.0259   |\n",
      "| loss/policy_loss        | -0.0106  |\n",
      "| loss/value_loss         | 0.0131   |\n",
      "| misc/explained_variance | 0.00843  |\n",
      "| misc/nupdates           | 3.45e+03 |\n",
      "| misc/serial_timesteps   | 1.1e+05  |\n",
      "| misc/time_elapsed       | 516      |\n",
      "| misc/total_timesteps    | 1.1e+05  |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 175      |\n",
      "| loss/approxkl           | 0.0273   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0169   |\n",
      "| loss/policy_loss        | -0.0102  |\n",
      "| loss/value_loss         | 0.0229   |\n",
      "| misc/explained_variance | 0.145    |\n",
      "| misc/nupdates           | 3.46e+03 |\n",
      "| misc/serial_timesteps   | 1.11e+05 |\n",
      "| misc/time_elapsed       | 517      |\n",
      "| misc/total_timesteps    | 1.11e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.95      |\n",
      "| fps                     | 164       |\n",
      "| loss/approxkl           | 6.9e-08   |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.0039    |\n",
      "| loss/policy_loss        | -8.06e-06 |\n",
      "| loss/value_loss         | 0.00339   |\n",
      "| misc/explained_variance | nan       |\n",
      "| misc/nupdates           | 3.47e+03  |\n",
      "| misc/serial_timesteps   | 1.11e+05  |\n",
      "| misc/time_elapsed       | 519       |\n",
      "| misc/total_timesteps    | 1.11e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.152    |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0194   |\n",
      "| loss/policy_loss        | -0.0173  |\n",
      "| loss/value_loss         | 0.0294   |\n",
      "| misc/explained_variance | 0.332    |\n",
      "| misc/nupdates           | 3.48e+03 |\n",
      "| misc/serial_timesteps   | 1.11e+05 |\n",
      "| misc/time_elapsed       | 521      |\n",
      "| misc/total_timesteps    | 1.11e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 182      |\n",
      "| loss/approxkl           | 0.0585   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0237   |\n",
      "| loss/policy_loss        | -0.012   |\n",
      "| loss/value_loss         | 0.0127   |\n",
      "| misc/explained_variance | 0.13     |\n",
      "| misc/nupdates           | 3.49e+03 |\n",
      "| misc/serial_timesteps   | 1.12e+05 |\n",
      "| misc/time_elapsed       | 522      |\n",
      "| misc/total_timesteps    | 1.12e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 285      |\n",
      "| loss/approxkl           | 0.281    |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.0599   |\n",
      "| loss/policy_loss        | -0.0397  |\n",
      "| loss/value_loss         | 0.0461   |\n",
      "| misc/explained_variance | 0.327    |\n",
      "| misc/nupdates           | 3.5e+03  |\n",
      "| misc/serial_timesteps   | 1.12e+05 |\n",
      "| misc/time_elapsed       | 524      |\n",
      "| misc/total_timesteps    | 1.12e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 0.029    |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0852   |\n",
      "| loss/policy_loss        | -0.0259  |\n",
      "| loss/value_loss         | 0.0133   |\n",
      "| misc/explained_variance | 0.502    |\n",
      "| misc/nupdates           | 3.51e+03 |\n",
      "| misc/serial_timesteps   | 1.12e+05 |\n",
      "| misc/time_elapsed       | 525      |\n",
      "| misc/total_timesteps    | 1.12e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.0975   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0382   |\n",
      "| loss/policy_loss        | -0.0246  |\n",
      "| loss/value_loss         | 0.0333   |\n",
      "| misc/explained_variance | 0.181    |\n",
      "| misc/nupdates           | 3.52e+03 |\n",
      "| misc/serial_timesteps   | 1.13e+05 |\n",
      "| misc/time_elapsed       | 527      |\n",
      "| misc/total_timesteps    | 1.13e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.98     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.0145   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0361   |\n",
      "| loss/policy_loss        | -0.0104  |\n",
      "| loss/value_loss         | 0.00424  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.53e+03 |\n",
      "| misc/serial_timesteps   | 1.13e+05 |\n",
      "| misc/time_elapsed       | 529      |\n",
      "| misc/total_timesteps    | 1.13e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 0.000169 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0148   |\n",
      "| loss/policy_loss        | -0.00661 |\n",
      "| loss/value_loss         | 0.00694  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.54e+03 |\n",
      "| misc/serial_timesteps   | 1.13e+05 |\n",
      "| misc/time_elapsed       | 530      |\n",
      "| misc/total_timesteps    | 1.13e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.9      |\n",
      "| fps                     | 199      |\n",
      "| loss/approxkl           | 0.0849   |\n",
      "| loss/clipfrac           | 0.0781   |\n",
      "| loss/policy_entropy     | 0.0792   |\n",
      "| loss/policy_loss        | -0.0338  |\n",
      "| loss/value_loss         | 0.0394   |\n",
      "| misc/explained_variance | 0.244    |\n",
      "| misc/nupdates           | 3.55e+03 |\n",
      "| misc/serial_timesteps   | 1.14e+05 |\n",
      "| misc/time_elapsed       | 532      |\n",
      "| misc/total_timesteps    | 1.14e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.88     |\n",
      "| fps                     | 196      |\n",
      "| loss/approxkl           | 0.171    |\n",
      "| loss/clipfrac           | 0.0938   |\n",
      "| loss/policy_entropy     | 0.0548   |\n",
      "| loss/policy_loss        | -0.0329  |\n",
      "| loss/value_loss         | 0.0443   |\n",
      "| misc/explained_variance | -0.0755  |\n",
      "| misc/nupdates           | 3.56e+03 |\n",
      "| misc/serial_timesteps   | 1.14e+05 |\n",
      "| misc/time_elapsed       | 533      |\n",
      "| misc/total_timesteps    | 1.14e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.91     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.00701  |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0735   |\n",
      "| loss/policy_loss        | -0.027   |\n",
      "| loss/value_loss         | 0.0281   |\n",
      "| misc/explained_variance | 0.0112   |\n",
      "| misc/nupdates           | 3.57e+03 |\n",
      "| misc/serial_timesteps   | 1.14e+05 |\n",
      "| misc/time_elapsed       | 535      |\n",
      "| misc/total_timesteps    | 1.14e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.95      |\n",
      "| fps                     | 184       |\n",
      "| loss/approxkl           | 7.21e-06  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00754   |\n",
      "| loss/policy_loss        | -0.000644 |\n",
      "| loss/value_loss         | 0.0067    |\n",
      "| misc/explained_variance | nan       |\n",
      "| misc/nupdates           | 3.58e+03  |\n",
      "| misc/serial_timesteps   | 1.15e+05  |\n",
      "| misc/time_elapsed       | 537       |\n",
      "| misc/total_timesteps    | 1.15e+05  |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 1        |\n",
      "| fps                     | 183      |\n",
      "| loss/approxkl           | 9.85e-05 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0157   |\n",
      "| loss/policy_loss        | -0.00602 |\n",
      "| loss/value_loss         | 0.00314  |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.59e+03 |\n",
      "| misc/serial_timesteps   | 1.15e+05 |\n",
      "| misc/time_elapsed       | 538      |\n",
      "| misc/total_timesteps    | 1.15e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 197      |\n",
      "| loss/approxkl           | 0.0076   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.047    |\n",
      "| loss/policy_loss        | -0.0179  |\n",
      "| loss/value_loss         | 0.0157   |\n",
      "| misc/explained_variance | -0.168   |\n",
      "| misc/nupdates           | 3.6e+03  |\n",
      "| misc/serial_timesteps   | 1.15e+05 |\n",
      "| misc/time_elapsed       | 540      |\n",
      "| misc/total_timesteps    | 1.15e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 202      |\n",
      "| loss/approxkl           | 0.00386  |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0262   |\n",
      "| loss/policy_loss        | -0.0166  |\n",
      "| loss/value_loss         | 0.0147   |\n",
      "| misc/explained_variance | 0.0172   |\n",
      "| misc/nupdates           | 3.61e+03 |\n",
      "| misc/serial_timesteps   | 1.16e+05 |\n",
      "| misc/time_elapsed       | 542      |\n",
      "| misc/total_timesteps    | 1.16e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 185      |\n",
      "| loss/approxkl           | 0.132    |\n",
      "| loss/clipfrac           | 0.0703   |\n",
      "| loss/policy_entropy     | 0.0413   |\n",
      "| loss/policy_loss        | -0.0345  |\n",
      "| loss/value_loss         | 0.0192   |\n",
      "| misc/explained_variance | 0.346    |\n",
      "| misc/nupdates           | 3.62e+03 |\n",
      "| misc/serial_timesteps   | 1.16e+05 |\n",
      "| misc/time_elapsed       | 543      |\n",
      "| misc/total_timesteps    | 1.16e+05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.96     |\n",
      "| fps                     | 192      |\n",
      "| loss/approxkl           | 0.104    |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.00681  |\n",
      "| loss/policy_loss        | -0.0126  |\n",
      "| loss/value_loss         | 0.0235   |\n",
      "| misc/explained_variance | 0.171    |\n",
      "| misc/nupdates           | 3.63e+03 |\n",
      "| misc/serial_timesteps   | 1.16e+05 |\n",
      "| misc/time_elapsed       | 545      |\n",
      "| misc/total_timesteps    | 1.16e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 205      |\n",
      "| loss/approxkl           | 0.0113   |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0375   |\n",
      "| loss/policy_loss        | -0.0172  |\n",
      "| loss/value_loss         | 0.0254   |\n",
      "| misc/explained_variance | 0.381    |\n",
      "| misc/nupdates           | 3.64e+03 |\n",
      "| misc/serial_timesteps   | 1.16e+05 |\n",
      "| misc/time_elapsed       | 546      |\n",
      "| misc/total_timesteps    | 1.16e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 178      |\n",
      "| loss/approxkl           | 0.0918   |\n",
      "| loss/clipfrac           | 0.0469   |\n",
      "| loss/policy_entropy     | 0.0274   |\n",
      "| loss/policy_loss        | -0.022   |\n",
      "| loss/value_loss         | 0.00932  |\n",
      "| misc/explained_variance | 0.384    |\n",
      "| misc/nupdates           | 3.65e+03 |\n",
      "| misc/serial_timesteps   | 1.17e+05 |\n",
      "| misc/time_elapsed       | 548      |\n",
      "| misc/total_timesteps    | 1.17e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 194      |\n",
      "| loss/approxkl           | 0.032    |\n",
      "| loss/clipfrac           | 0.0625   |\n",
      "| loss/policy_entropy     | 0.0496   |\n",
      "| loss/policy_loss        | -0.0207  |\n",
      "| loss/value_loss         | 0.0245   |\n",
      "| misc/explained_variance | 0.156    |\n",
      "| misc/nupdates           | 3.66e+03 |\n",
      "| misc/serial_timesteps   | 1.17e+05 |\n",
      "| misc/time_elapsed       | 550      |\n",
      "| misc/total_timesteps    | 1.17e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.92     |\n",
      "| fps                     | 179      |\n",
      "| loss/approxkl           | 0.00779  |\n",
      "| loss/clipfrac           | 0.0391   |\n",
      "| loss/policy_entropy     | 0.0346   |\n",
      "| loss/policy_loss        | -0.023   |\n",
      "| loss/value_loss         | 0.0245   |\n",
      "| misc/explained_variance | 0.0824   |\n",
      "| misc/nupdates           | 3.67e+03 |\n",
      "| misc/serial_timesteps   | 1.17e+05 |\n",
      "| misc/time_elapsed       | 551      |\n",
      "| misc/total_timesteps    | 1.17e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.93     |\n",
      "| fps                     | 189      |\n",
      "| loss/approxkl           | 0.0409   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0215   |\n",
      "| loss/policy_loss        | -0.0122  |\n",
      "| loss/value_loss         | 0.0176   |\n",
      "| misc/explained_variance | 0.358    |\n",
      "| misc/nupdates           | 3.68e+03 |\n",
      "| misc/serial_timesteps   | 1.18e+05 |\n",
      "| misc/time_elapsed       | 553      |\n",
      "| misc/total_timesteps    | 1.18e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.94     |\n",
      "| fps                     | 201      |\n",
      "| loss/approxkl           | 0.0708   |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0513   |\n",
      "| loss/policy_loss        | -0.00811 |\n",
      "| loss/value_loss         | 0.0242   |\n",
      "| misc/explained_variance | -0.656   |\n",
      "| misc/nupdates           | 3.69e+03 |\n",
      "| misc/serial_timesteps   | 1.18e+05 |\n",
      "| misc/time_elapsed       | 554      |\n",
      "| misc/total_timesteps    | 1.18e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.99     |\n",
      "| fps                     | 206      |\n",
      "| loss/approxkl           | 0.000383 |\n",
      "| loss/clipfrac           | 0        |\n",
      "| loss/policy_entropy     | 0.0219   |\n",
      "| loss/policy_loss        | -0.0126  |\n",
      "| loss/value_loss         | 0.0047   |\n",
      "| misc/explained_variance | nan      |\n",
      "| misc/nupdates           | 3.7e+03  |\n",
      "| misc/serial_timesteps   | 1.18e+05 |\n",
      "| misc/time_elapsed       | 556      |\n",
      "| misc/total_timesteps    | 1.18e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 188      |\n",
      "| loss/approxkl           | 0.0595   |\n",
      "| loss/clipfrac           | 0.0547   |\n",
      "| loss/policy_entropy     | 0.0366   |\n",
      "| loss/policy_loss        | -0.0259  |\n",
      "| loss/value_loss         | 0.0219   |\n",
      "| misc/explained_variance | 0.162    |\n",
      "| misc/nupdates           | 3.71e+03 |\n",
      "| misc/serial_timesteps   | 1.19e+05 |\n",
      "| misc/time_elapsed       | 558      |\n",
      "| misc/total_timesteps    | 1.19e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.95     |\n",
      "| fps                     | 181      |\n",
      "| loss/approxkl           | 0.00766  |\n",
      "| loss/clipfrac           | 0.0312   |\n",
      "| loss/policy_entropy     | 0.0457   |\n",
      "| loss/policy_loss        | -0.0231  |\n",
      "| loss/value_loss         | 0.0274   |\n",
      "| misc/explained_variance | 0.0235   |\n",
      "| misc/nupdates           | 3.72e+03 |\n",
      "| misc/serial_timesteps   | 1.19e+05 |\n",
      "| misc/time_elapsed       | 559      |\n",
      "| misc/total_timesteps    | 1.19e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.89     |\n",
      "| fps                     | 190      |\n",
      "| loss/approxkl           | 0.057    |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0241   |\n",
      "| loss/policy_loss        | -0.0174  |\n",
      "| loss/value_loss         | 0.0149   |\n",
      "| misc/explained_variance | 0.0643   |\n",
      "| misc/nupdates           | 3.73e+03 |\n",
      "| misc/serial_timesteps   | 1.19e+05 |\n",
      "| misc/time_elapsed       | 561      |\n",
      "| misc/total_timesteps    | 1.19e+05 |\n",
      "--------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "---------------------------------------\n",
      "| eplenmean               | 1         |\n",
      "| eprewmean               | 0.97      |\n",
      "| fps                     | 203       |\n",
      "| loss/approxkl           | 3.42e-07  |\n",
      "| loss/clipfrac           | 0         |\n",
      "| loss/policy_entropy     | 0.00673   |\n",
      "| loss/policy_loss        | -0.000153 |\n",
      "| loss/value_loss         | 0.00334   |\n",
      "| misc/explained_variance | nan       |\n",
      "| misc/nupdates           | 3.74e+03  |\n",
      "| misc/serial_timesteps   | 1.2e+05   |\n",
      "| misc/time_elapsed       | 563       |\n",
      "| misc/total_timesteps    | 1.2e+05   |\n",
      "---------------------------------------\n",
      "Stepping environment...\n",
      "Done.\n",
      "--------------------------------------\n",
      "| eplenmean               | 1        |\n",
      "| eprewmean               | 0.97     |\n",
      "| fps                     | 184      |\n",
      "| loss/approxkl           | 0.032    |\n",
      "| loss/clipfrac           | 0.0234   |\n",
      "| loss/policy_entropy     | 0.0154   |\n",
      "| loss/policy_loss        | -0.0119  |\n",
      "| loss/value_loss         | 0.00962  |\n",
      "| misc/explained_variance | 0.311    |\n",
      "| misc/nupdates           | 3.75e+03 |\n",
      "| misc/serial_timesteps   | 1.2e+05  |\n",
      "| misc/time_elapsed       | 564      |\n",
      "| misc/total_timesteps    | 1.2e+05  |\n",
      "--------------------------------------\n",
      "PPO Training Time: 566.9714050292969\n"
     ]
    }
   ],
   "source": [
    "def mnist_ppo():\n",
    "    logger.configure(dir='./logs/mnist_ppo', format_strs=['stdout', 'tensorboard'])\n",
    "    env = DummyVecEnv([lambda: bench.Monitor(MnistEnv(images_per_episode=1), logger.get_dir())])\n",
    "\n",
    "    model = ppo2.learn(\n",
    "        env=env,\n",
    "        network='mlp',\n",
    "        num_layers=2,\n",
    "        num_hidden=64,\n",
    "        nsteps=32,\n",
    "        total_timesteps=int(1.2e5),\n",
    "        seed=int(time.time()))\n",
    "\n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "ppo_model = mnist_ppo()\n",
    "print('PPO Training Time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0c86860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 94.71947194719472%\n"
     ]
    }
   ],
   "source": [
    "def mnist_ppo_eval(ppo_model):\n",
    "    attempts, correct = 0,0\n",
    "\n",
    "    env = DummyVecEnv([lambda: MnistEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)])\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), [False]\n",
    "            while not done[0]:\n",
    "                obs, rew, done, _ = env.step(ppo_model.step(obs[None])[0])\n",
    "\n",
    "                attempts += 1\n",
    "                if rew[0] > 0:\n",
    "                    correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "mnist_ppo_eval(ppo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec5c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
