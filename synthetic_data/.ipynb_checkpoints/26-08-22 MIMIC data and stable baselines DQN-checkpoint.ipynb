{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1677aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484dae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tensorflow.set_random_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d5dc7",
   "metadata": {},
   "source": [
    "#### The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3296e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aplastic anemia': 0,\n",
       " 'Hemolytic anemia': 1,\n",
       " 'No anemia': 2,\n",
       " 'Anemia of chronic disease': 3,\n",
       " 'Vitamin B12/Folate deficiency anemia': 4,\n",
       " 'Iron deficiency anemia': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('data/anemia_synth_dataset_hb_some_nans.csv') #my real dataset i think\n",
    "#df = pd.read_csv('data/anemia_synth_dataset_hb.csv')\n",
    "df = pd.read_csv('data/noisy_dataset.csv')\n",
    "df = df.fillna(0)\n",
    "classes = list(df.label.unique())\n",
    "nums = [i for i in range(len(classes))]\n",
    "class_dict = dict(zip(classes, nums))\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cde9b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26868, 6), (11515, 6), (26868,), (11515,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].replace(class_dict)\n",
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4901dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list = list(class_dict.keys()) + [col  for col in df.columns if col!='label']\n",
    "len(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6dbefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aplastic anemia',\n",
       " 'Hemolytic anemia',\n",
       " 'No anemia',\n",
       " 'Anemia of chronic disease',\n",
       " 'Vitamin B12/Folate deficiency anemia',\n",
       " 'Iron deficiency anemia',\n",
       " 'hemoglobin',\n",
       " 'ferritin',\n",
       " 'ret_count',\n",
       " 'segmented_neutrophils',\n",
       " 'tibc',\n",
       " 'mcv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16438584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 15.10043914,   0.        ,   0.        ,   0.        ,\n",
       "         433.96215048,  97.75210851],\n",
       "        [ 14.22862796,  19.77782161,   0.        ,   0.        ,\n",
       "         393.33905326,   0.        ]]),\n",
       " array([[  8.48592864,   0.        ,   3.18460851,   0.        ,\n",
       "         334.12660186,  93.77167177],\n",
       "        [ 12.69219637,  46.65726226,   0.        ,   0.        ,\n",
       "         297.36947041,  98.80306661]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2], X_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714feb3d",
   "metadata": {},
   "source": [
    "#### The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f836162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs import SyntheticComplexHbEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fe115",
   "metadata": {},
   "source": [
    "#### The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcdf434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines import bench, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7da20e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\stable_baselines\\deepq\\policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tf_v1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 97       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 20310    |\n",
      "| success rate            | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 94       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 41139    |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 91       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 62419    |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 88       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 84181    |\n",
      "| success rate            | 0.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 84       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 107209   |\n",
      "| success rate            | 0.12     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 130702   |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 154986   |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 74       |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 180959   |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 207458   |\n",
      "| success rate            | 0.16     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 66       |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 235769   |\n",
      "| success rate            | 0.22     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 265086   |\n",
      "| success rate            | 0.1      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | -0.3     |\n",
      "| steps                   | 296279   |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 329155   |\n",
      "| success rate            | 0.14     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 364026   |\n",
      "| success rate            | 0.18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | 0        |\n",
      "| steps                   | 401113   |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 439860   |\n",
      "| success rate            | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 481310   |\n",
      "| success rate            | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 524049   |\n",
      "| success rate            | 0.26     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | 1.5      |\n",
      "| steps                   | 568100   |\n",
      "| success rate            | 0.45     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | 2        |\n",
      "| steps                   | 613096   |\n",
      "| success rate            | 0.52     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | 2        |\n",
      "| steps                   | 657716   |\n",
      "| success rate            | 0.56     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 702918   |\n",
      "| success rate            | 0.61     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | 2        |\n",
      "| steps                   | 746451   |\n",
      "| success rate            | 0.58     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 787127   |\n",
      "| success rate            | 0.68     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 828087   |\n",
      "| success rate            | 0.69     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 867414   |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 907011   |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 946869   |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 986875   |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | 1.9      |\n",
      "| steps                   | 1027005  |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1067458  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1107642  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1147255  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1186593  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1226291  |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 1265819  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1306056  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 1345973  |\n",
      "| success rate            | 0.6      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1385154  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 1424302  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 410000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 1463509  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 420000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1503193  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 430000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1542296  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 440000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1582087  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 450000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 1621603  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 460000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 1660333  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 470000   |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 1699366  |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 480000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 1738864  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 490000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1777905  |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 1817018  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 510000   |\n",
      "| mean 100 episode reward | 1.9      |\n",
      "| steps                   | 1857455  |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 520000   |\n",
      "| mean 100 episode reward | 1.9      |\n",
      "| steps                   | 1896741  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 530000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 1936563  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 540000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 1975364  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 550000   |\n",
      "| mean 100 episode reward | 1.8      |\n",
      "| steps                   | 2014593  |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 560000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 2053465  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 570000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 2092500  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 580000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 2131473  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 590000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 2170794  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| steps                   | 2210279  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 610000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 2249877  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 620000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 2289502  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 630000   |\n",
      "| mean 100 episode reward | 1.8      |\n",
      "| steps                   | 2329752  |\n",
      "| success rate            | 0.65     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 640000   |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 2369229  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 650000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 2408451  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 660000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 2447993  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 670000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 2487347  |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 680000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 2526314  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 690000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 2565456  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 2604082  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 710000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 2643178  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 720000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 2682002  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 730000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 2721536  |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 740000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 2760448  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 750000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 2799912  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 760000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 2838639  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 770000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 2877637  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 780000   |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 2916525  |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 790000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 2954642  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 2993293  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 810000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 3032730  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 820000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 3071954  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 830000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 3111543  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 840000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 3150288  |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 850000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 3189521  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 860000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 3228727  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 870000   |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 3269611  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 880000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 3309301  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 890000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 3349631  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 3389525  |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 910000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 3428464  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 920000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 3467304  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 930000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 3506856  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 940000   |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 3546909  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 950000   |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 3587295  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 960000   |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 3627336  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 970000   |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 3668559  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 980000   |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 3708014  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 990000   |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 3747783  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 3788930  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1010000  |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 3829993  |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1020000  |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 3870909  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1030000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 3911692  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1040000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 3951598  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1050000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 3992044  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1060000  |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 4032084  |\n",
      "| success rate            | 0.73     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1070000  |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 4072315  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1080000  |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 4112611  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1090000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 4152929  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1100000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 4193625  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1110000  |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 4234310  |\n",
      "| success rate            | 0.89     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1120000  |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 4272934  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1130000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 4313289  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1140000  |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 4354652  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1150000  |\n",
      "| mean 100 episode reward | 2        |\n",
      "| steps                   | 4394299  |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1160000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 4433603  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1170000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 4473114  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1180000  |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 4512508  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1190000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 4552394  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1200000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 4592269  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1210000  |\n",
      "| mean 100 episode reward | 1.9      |\n",
      "| steps                   | 4631499  |\n",
      "| success rate            | 0.72     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1220000  |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 4671475  |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1230000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 4711053  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1240000  |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 4750279  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1250000  |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 4790262  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1260000  |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 4829926  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1270000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 4871214  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1280000  |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 4911625  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1290000  |\n",
      "| mean 100 episode reward | 1.9      |\n",
      "| steps                   | 4951926  |\n",
      "| success rate            | 0.7      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1300000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 4991893  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1310000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 5031887  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1320000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 5072135  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1330000  |\n",
      "| mean 100 episode reward | 2.1      |\n",
      "| steps                   | 5112798  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1340000  |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 5152631  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1350000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 5194023  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1360000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 5234005  |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1370000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 5274350  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1380000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 5314080  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1390000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 5353403  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1400000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 5393514  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1410000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 5433247  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1420000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 5472698  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1430000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 5511862  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1440000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 5551272  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1450000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 5591761  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1460000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 5631729  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1470000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 5670992  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1480000  |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 5710123  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1490000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 5749625  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1500000  |\n",
      "| mean 100 episode reward | 1.9      |\n",
      "| steps                   | 5788652  |\n",
      "| success rate            | 0.71     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1510000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 5827930  |\n",
      "| success rate            | 0.77     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1520000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 5866689  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1530000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 5906101  |\n",
      "| success rate            | 0.85     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1540000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 5945653  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1550000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 5984617  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1560000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 6025339  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1570000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 6065623  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1580000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 6105120  |\n",
      "| success rate            | 0.8      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1590000  |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 6145196  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1600000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 6185338  |\n",
      "| success rate            | 0.81     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1610000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 6225505  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1620000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 6264625  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1630000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 6304668  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1640000  |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 6343953  |\n",
      "| success rate            | 0.88     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1650000  |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| steps                   | 6382868  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1660000  |\n",
      "| mean 100 episode reward | 3        |\n",
      "| steps                   | 6422333  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1670000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 6461670  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1680000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 6500428  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1690000  |\n",
      "| mean 100 episode reward | 2.5      |\n",
      "| steps                   | 6539783  |\n",
      "| success rate            | 0.82     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1700000  |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 6579083  |\n",
      "| success rate            | 0.67     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1710000  |\n",
      "| mean 100 episode reward | 2.2      |\n",
      "| steps                   | 6619279  |\n",
      "| success rate            | 0.76     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1720000  |\n",
      "| mean 100 episode reward | 2.4      |\n",
      "| steps                   | 6659491  |\n",
      "| success rate            | 0.78     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1730000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 6698847  |\n",
      "| success rate            | 0.87     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1740000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 6738361  |\n",
      "| success rate            | 0.83     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1750000  |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 6777851  |\n",
      "| success rate            | 0.75     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1760000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 6817013  |\n",
      "| success rate            | 0.84     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1770000  |\n",
      "| mean 100 episode reward | 2.3      |\n",
      "| steps                   | 6856474  |\n",
      "| success rate            | 0.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1780000  |\n",
      "| mean 100 episode reward | 2.9      |\n",
      "| steps                   | 6897258  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1790000  |\n",
      "| mean 100 episode reward | 2.7      |\n",
      "| steps                   | 6936975  |\n",
      "| success rate            | 0.79     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1800000  |\n",
      "| mean 100 episode reward | 2.6      |\n",
      "| steps                   | 6977120  |\n",
      "| success rate            | 0.86     |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def stable_dqn():\n",
    "    training_env = SyntheticComplexHbEnv(X_train, y_train)\n",
    "    env = bench.Monitor(training_env, logger.get_dir())\n",
    "    model = DQN('MlpPolicy', training_env, verbose=1, seed=SEED, n_cpu_tf_sess=1)\n",
    "    model.learn(total_timesteps=int(7e6), log_interval=10000)\n",
    "    #model.learn(total_timesteps=int(1.2e5), log_interval=10000)\n",
    "    #model.save('models/synthetic_stable_dqn_1.8.pkl')\n",
    "    model.save('models/noisy/dqn_7e6.pkl')\n",
    "    env.close()\n",
    "    return model\n",
    "\n",
    "dqn_model = stable_dqn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e1a11",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a6322eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dqn_model = DQN.load('models/synthentic_with_hb_some_nans_stable_dqn2e6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e0418bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c64b2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass(actual_class, pred_class, average = 'macro'):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    avg = sum(roc_auc_dict.values()) / len(roc_auc_dict)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18f408d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ytest, ypred):\n",
    "    acc = accuracy_score(ytest, ypred)\n",
    "    f1 = f1_score(ytest, ypred, average ='macro', labels=np.unique(ytest))\n",
    "    try:\n",
    "        roc_auc = multiclass(ytest, ypred)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    return acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a95c5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_length_reward(df):\n",
    "    length = np.mean(df.episode_length)\n",
    "    reward = np.mean(df.reward)\n",
    "    return length, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5140150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 5000\n",
      "Count: 10000\n",
      "Testing done.....\n"
     ]
    }
   ],
   "source": [
    "def synthetic_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    env = SyntheticComplexHbEnv(X_test, y_test, random=False)\n",
    "    #env = SyntheticComplexHbEnv(X_train, y_train, random=False)\n",
    "    count=0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            count+=1\n",
    "            if count%5000==0:\n",
    "                print(f'Count: {count}')\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                action, _states = dqn_model.predict(obs, deterministic=True)\n",
    "                obs, rew, done,info = env.step(action)\n",
    "                #if (done==True) & (np.isfinite(info['y_pred'])):\n",
    "                if done == True:\n",
    "                    test_df = test_df.append(info, ignore_index=True)\n",
    "                #print('....................TEST DF ....................')\n",
    "                #if len(test_df) != 0:\n",
    "                #    print(test_df.head())\n",
    "\n",
    "    except StopIteration:\n",
    "        print('Testing done.....')\n",
    "    return test_df\n",
    "\n",
    "test_df = synthetic_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dafb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26868, 26868)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c20c4695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11515, 11515)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78ccf0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9427"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = test_df[test_df['y_pred'].notna()]\n",
    "success_df = y_pred_df[y_pred_df['y_pred']== y_pred_df['y_actual']]\n",
    "len(success_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41dccb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv('test_dfs/train_test_df_with_hb_some_nans_2e6.csv', index=False)\n",
    "# y_pred_df.to_csv('test_dfs/train_y_pred_df_with_hb_some_nans_2e6.csv', index=False)\n",
    "# success_df.to_csv('test_dfs/train_success_df_with_hb_some_nans_2e6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a059464e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 0., 4., 5., 3.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.y_pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7b94d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4043\n",
       "0.0    2956\n",
       "2.0    2758\n",
       "4.0     145\n",
       "5.0     125\n",
       "3.0      89\n",
       "Name: y_pred, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d824df37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4180\n",
       "0.0    2800\n",
       "2.0    2709\n",
       "3.0     170\n",
       "4.0     139\n",
       "5.0     118\n",
       "Name: y_actual, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.y_actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae641e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.86712983065567"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_rate = len(success_df)/len(test_df)*100\n",
    "success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "860cb1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.120885801128963, 2.579070777247069)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#avg length and return \n",
    "avg_length, avg_return = get_avg_length_reward(test_df)\n",
    "avg_length, avg_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e885cbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9318900751285093, 0.735203257436147, 0.8497941696220433)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, f1, roc_auc = test(y_pred_df['y_actual'], y_pred_df['y_pred'])\n",
    "acc, f1, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f03ed",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7981d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, save=False, filename=False):\n",
    "    cm_df = pd.DataFrame(cm, index = [0, 1, 2, 3, 4, 5], columns = [0, 1, 2, 3, 4, 5])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Anemia')\n",
    "    plt.xlabel('Predicted Anemia')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_pred_df['y_actual'], y_pred_df['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539cbabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    inch = 2.54\n",
    "    if type(tupl[0]) == tuple:\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56198e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values(pc, fmt=\"%.2f\", **kw):    \n",
    "    pc.update_scalarmappable()\n",
    "    ax = pc.axes\n",
    "    for p, color, value in zip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.all(color[:3] > 0.5):\n",
    "            color = (0.0, 0.0, 0.0)\n",
    "        else:\n",
    "            color = (1.0, 1.0, 1.0)\n",
    "        ax.text(x, y, fmt % value, ha=\"center\", va=\"center\", color=color, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0264db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(AUC, title, xlabel, ylabel, xticklabels, yticklabels, figure_width=40, figure_height=20, correct_orientation=False, cmap='RdBu'):\n",
    "    fig, ax = plt.subplots()    \n",
    "    c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap=cmap)\n",
    "    ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_xticklabels(xticklabels, minor=False)\n",
    "    ax.set_yticklabels(yticklabels, minor=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)      \n",
    "\n",
    "    # Remove last blank column\n",
    "    plt.xlim( (0, AUC.shape[1]) )\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()    \n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    # Add color bar\n",
    "    plt.colorbar(c)\n",
    "\n",
    "    # Add text in each cell \n",
    "    show_values(c)\n",
    "\n",
    "    # Proper orientation (origin at the top left instead of bottom left)\n",
    "    if correct_orientation:\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.tick_top()       \n",
    "\n",
    "    # resize \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(cm2inch(figure_width, figure_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb007fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(classification_report, save=False, filename=False, cmap='RdBu'):\n",
    "    lines = classification_report.split('\\n')\n",
    "    class_names = list(class_dict.keys())\n",
    "    plotMat = []\n",
    "    support = []\n",
    "    #class_names = []\n",
    "    #count = 0\n",
    "    for line in lines[2 : (len(lines) - 5)]:\n",
    "        t = line.strip().split()\n",
    "        if len(t) < 2: continue\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        support.append(int(t[-1]))\n",
    "        plotMat.append(v)\n",
    "\n",
    "    xlabel = 'Metrics'\n",
    "    ylabel = 'Classes'\n",
    "    xticklabels = ['Precision', 'Recall', 'F1-score']\n",
    "    ytick_labels = [f'{class_names[i]}({sup})' for i, sup in enumerate(support) ]\n",
    "    \n",
    "    #print(len(support))\n",
    "    yticklabels = ['{0} ({1})'.format(class_names[idx], sup) for idx, sup  in enumerate(support)]\n",
    "    figure_width = 25\n",
    "    figure_height = len(class_names) + 7\n",
    "    correct_orientation = False\n",
    "    heatmap(np.array(plotMat), 'classification report', xlabel, ylabel, xticklabels, yticklabels, figure_width, figure_height, correct_orientation, cmap=cmap)\n",
    "    #plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(filename, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_pred_df['y_actual'], y_pred_df['y_pred'])\n",
    "plot_classification_report(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c8627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
